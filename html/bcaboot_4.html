<div class="container">

<table style="width: 100%;"><tr>
<td>bcapar</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute parametric bootstrap confidence intervals</h2>

<h3>Description</h3>

<p>bcapar computes parametric bootstrap confidence
intervals for a real-valued parameter theta in a p-parameter
exponential family. It is described in Section 4 of the
reference below.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bcapar(
  t0,
  tt,
  bb,
  alpha = c(0.025, 0.05, 0.1, 0.16),
  J = 10,
  K = 6,
  trun = 0.001,
  pct = 0.333,
  cd = 0,
  func
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>t0</code></td>
<td>
<p>Observed estimate of theta, usually by maximum
likelihood.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tt</code></td>
<td>
<p>A vector of parametric bootstrap replications of theta of
length <code>B</code>, usually large, say <code>B = 2000</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bb</code></td>
<td>
<p>A <code>B</code> by <code>p</code> matrix of natural sufficient vectors, where
<code>p</code> is the dimension of the exponential family.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>percentiles desired for the bca confidence limits. One
only needs to provide <code>alpha</code> values below 0.5; the upper
limits are automatically computed</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>J, K</code></td>
<td>
<p>Parameters controlling the jackknife estimates of Monte
Carlo error: <code>J</code> jackknife folds, with the jackknife standard
errors averaged over <code>K</code> random divisions of <code>bb</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trun</code></td>
<td>
<p>Truncation parameter used in the calculation of the
acceleration <code>a</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pct</code></td>
<td>
<p>Proportion of "nearby" b vectors used in the calculation
of <code>t.</code>, the gradient vector of theta.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cd</code></td>
<td>
<p>If cd is 1 the bca confidence density is also returned;
see Section 11.6 in reference Efron and Hastie (2016) below</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>func</code></td>
<td>
<p>Function <code class="reqn">\hat{\theta} = func(b)</code>. If this is not missing then
output includes <em>abc</em> estimates; see reference DiCiccio and Efron (1992) below</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>a named list of several items:
</p>

<ul>
<li> <p><strong>lims</strong> : Bca confidence limits (first column) and the standard
limits (fourth column). Also the abc limits (fifth column) if
<code>func</code> is provided. The second column, <code>jacksd</code>, are the
jackknife estimates of Monte Carlo error; <code>pct</code>, the third
column are the proportion of the replicates <code>tt</code> less than each
<code>bcalim</code> value
</p>
</li>
<li> <p><strong>stats</strong> : Estimates and their jackknife Monte Carlo errors:
<code>theta</code> = <code class="reqn">\hat{\theta}</code>; <code>sd</code>, the bootstrap standard deviation
for <code class="reqn">\hat{\theta}</code>; <code>a</code> the acceleration estimate; <code>az</code> another
acceleration estimate that depends less on extreme values of <code>tt</code>;
<code>z0</code> the bias-correction estimate; <code>A</code> the big-A measure of raw
acceleration; <code>sdd</code> delta method estimate for standard deviation of
<code class="reqn">\hat{\theta}</code>; <code>mean</code> the average of <code>tt</code>
</p>
</li>
<li> <p><strong>abcstats</strong> : The abc estimates of <code>a</code> and <code>z0</code>, returned if <code>func</code> was provided
</p>
</li>
<li> <p><strong>ustats</strong> : The bias-corrected estimator <code>2 * t0 - mean(tt)</code>. <code>ustats</code>
gives <code>ustat</code>, an estimate <code>sdu</code> of its sampling error, and jackknife
estimates of monte carlo error for both <code>ustat</code> and <code>sdu</code>. Also given
is <code>B</code>, the number of bootstrap replications
</p>
</li>
<li> <p><strong>seed</strong> : The random number state for reproducibility
</p>
</li>
</ul>
<h3>References</h3>

<p>DiCiccio T and Efron B (1996). Bootstrap confidence
intervals. Statistical Science 11, 189-228
</p>
<p>T. DiCiccio and B. Efron. More accurate confidence intervals in exponential families.
Biometrika (1992) p231-245.
</p>
<p>Efron B (1987). Better bootstrap confidence intervals. JASA 82, 171-200
</p>
<p>B. Efron and T. Hastie. Computer Age Statistical Inference. Cambridge University Press, 2016.
</p>
<p>B. Efron and B. Narasimhan. Automatic Construction of Bootstrap Confidence Intervals, 2018.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(diabetes, package = "bcaboot")
X &lt;- diabetes$x
y &lt;- scale(diabetes$y, center = TRUE, scale = FALSE)
lm.model &lt;- lm(y ~ X - 1)
mu.hat &lt;- lm.model$fitted.values
sigma.hat &lt;- stats::sd(lm.model$residuals)
t0 &lt;- summary(lm.model)$adj.r.squared
y.star &lt;- sapply(mu.hat, rnorm, n = 1000, sd = sigma.hat)
tt &lt;- apply(y.star, 1, function(y) summary(lm(y ~ X - 1))$adj.r.squared)
b.star &lt;- y.star %*% X
set.seed(1234)
bcapar(t0 = t0, tt = tt, bb = b.star)
</code></pre>


</div>