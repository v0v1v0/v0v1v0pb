<div class="container">

<table style="width: 100%;"><tr>
<td>PYdensity</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MCMC for Pitman-Yor mixtures of Gaussians</h2>

<h3>Description</h3>

<p>The <code>PYdensity</code> function generates a posterior density sample for a selection of univariate and multivariate Pitman-Yor
process mixture models with Gaussian kernels. See details below for the description of the different specifications of the implemented models.
</p>


<h3>Usage</h3>

<pre><code class="language-R">PYdensity(y, mcmc = list(), prior = list(), output = list())
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a  vector or matrix giving the data based on which the density is to be estimated;</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mcmc</code></td>
<td>
<p>a list of MCMC arguments:
</p>

<ul>
<li> <p><code>niter</code> (mandatory), number of iterations.
</p>
</li>
<li> <p><code>nburn</code> (mandatory), number of iterations to discard as burn-in.
</p>
</li>
<li> <p><code>method</code>, the MCMC sampling method to be used, options are <code>'ICS'</code>, <code>'MAR'</code> and <code>'SLI'</code> (default is <code>'ICS'</code>). See details.
</p>
</li>
<li> <p><code>model</code>, the type of model to be fitted (default is <code>'LS'</code>). See details.
</p>
</li>
<li> <p><code>nupd</code>, argument controlling the number of iterations to be displayed on screen: the function reports
on standard output every time <code>nupd</code> new iterations have been carried out (default is <code>niter/10</code>).
</p>
</li>
<li> <p><code>print_message</code>, control option. If equal to <code>TRUE</code>, the status is printed
to standard output every <code>nupd</code> iterations (default is <code>TRUE</code>).
</p>
</li>
<li> <p><code>m_imp</code>, number of generated values for the importance sampling step of <code>method = 'ICS'</code> (default is 10). See details.
</p>
</li>
<li> <p><code>slice_type</code>, when <code>method = 'SLI'</code> it specifies the type of slice sampler. Options are <code>'DEP'</code> for dependent slice-efficient, and <code>'INDEP'</code> for independent slice-efficient (default is <code>'DEP'</code>). See details.
</p>
</li>
<li> <p><code>hyper</code>, if equal to <code>TRUE</code>, hyperprior distributions on the base measure's
parameters are added, as specified in <code>prior</code> and explained in <code>details</code> (default is <code>TRUE</code>).
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>a list giving the prior information. The list includes <code>strength</code> and <code>discount</code>,
the strength and discount parameters of the Pitman-Yor process
(default are <code>strength = 1</code> and <code>discount = 0</code>, the latter leading to the Dirichlet process).
The remaining parameters depend on the model choice.
</p>

<ul>
<li>
<p> If <code>model = 'L'</code> (location mixture) and <code>y</code> is univariate:
</p>
<p><code>m0</code> and <code>s20</code> are
mean and variance of the base measure on the location parameter (default are sample mean and sample variance of the data);
<code>a0</code> and <code>b0</code> are shape and scale parameters of the inverse gamma prior on the common scale parameter
(default are 2 and the sample variance of the data).
If <code>hyper = TRUE</code>,  optional hyperpriors on the base measure's parameters are added:
specifically, <code>m1</code> and <code>k1</code> are the mean parameter and the scale factor defining the
normal hyperprior on <code>m0</code> (default are the sample mean of the data and 1), and
<code>a1</code> and <code>b1</code> are shape and rate parameters of the inverse gamma hyperprior on <code>b0</code>
(default are 2 and the sample variance of the data). See details.
</p>
</li>
<li>
<p> If <code>model = 'LS'</code> (location-scale mixture) and <code>y</code> is univariate:
</p>
<p><code>m0</code> and <code>k0</code> are the mean parameter and the scale factor defining the normal base measure
on the location parameter (default are the sample mean of the data and 1), and <code>a0</code> and <code>b0</code> are
shape and scale parameters of the inverse gamma base measure on the scale parameter (default are 2 and the sample variance of the data).
If <code>hyper = TRUE</code>,  optional hyperpriors on the base measure's parameters are added:
specifically, <code>m1</code> and <code>s21</code> are mean and variance parameters of the normal hyperprior on
<code>m0</code> (default are the sample mean and the sample variance of the data);
<code>tau1</code> and <code>zeta1</code> are shape and rate parameters of the gamma hyperprior on
<code>k0</code> (default is 1 for both);
<code>a1</code> and <code>b1</code> are shape and rate parameters of the gamma hyperprior on
<code>b0</code>  (default are the sample variance of the data and 1). See details.
</p>
</li>
<li>
<p> If <code>model = 'L'</code> (location mixture) and <code>y</code> is multivariate (<code>p</code>-variate):
</p>
<p><code>m0</code> and <code>S20</code> are
mean and covariance of the base measure on the location parameter (default are the sample mean and the sample covariance of the data);
<code>Sigma0</code> and <code>n0</code> are the parameters of the inverse Whishart prior on
the common scale matrix (default are the sample covariance of the data and <code>p</code>+2).
If <code>hyper = TRUE</code>, optional hyperpriors on the base measure's parameters are added:
specifically, <code>m1</code> and <code>k1</code> are the mean parameter and the scale factor defining the
normal hyperprior on <code>m0</code> (default are the sample mean of the data and 1), and
<code>lambda</code> and <code>Lambda1</code> are the parameters (degrees of freedom and scale) of the inverse Wishart prior on <code>S20</code>
(default are <code>p</code>+2 and the sample covariance of the data). See details.
</p>
</li>
<li>
<p> If <code>model = 'LS'</code> (location-scale mixture) and <code>y</code> is multivariate (<code>p</code>-variate):
</p>
<p><code>m0</code> and <code>k0</code> are the mean parameter and the scale factor defining the normal base measure on the
location parameter (default are the sample mean of the data and 1), and
<code>n0</code> and <code>Sigma0</code> are the parameters (degrees of freedom and scale) of the inverse Wishart base measure on the location parameter
(default are <code>p</code>+2 and the sample covariance of the data).
If <code>hyper = TRUE</code>, optional hyperpriors on the base measure's parameters are added:
specifically, <code>m1</code> and <code>S1</code> are mean and covariance matrix parameters of the normal hyperprior on
<code>m0</code> (default are the sample mean and the sample covariance of the data);
<code>tau1</code> and <code>zeta1</code> are shape and rate parameters of the gamma hyperprior on
<code>k0</code> (default is 1 for both);
<code>n1</code> and <code>Sigma1</code> are the parameters (degrees of freedom and scale) of the Wishart prior for <code>Sigma0</code>
(default are <code>p</code>+2 and the sample covariance of the data divided <code>p</code>+2). See details.
</p>
</li>
<li>
<p> If <code>model = 'DLS'</code> (diagonal location-scale mixture):
</p>
<p><code>m0</code> and <code>k0</code> are the mean vector parameter and the vector of scale factors defining the normal base measure
on the location parameter (default are the sample mean and a vector of ones),
and <code>a0</code> and <code>b0</code> are vectors of
shape and scale parameters defining the base measure on the scale parameters (default are a vector of twos and the diagonal
of the sample covariance of the data).
If <code>hyper = TRUE</code>, optional hyperpriors on the base measure's parameters are added:
specifically, <code>m1</code> and <code>s21</code> are vectors of mean and variance parameters for the normal hyperpriors on the components of
<code>m0</code> (default are the sample mean and the diagonal of the sample covariance of the data);
<code>tau1</code> and <code>zeta1</code> are vectors of shape and rate parameters of the gamma hyperpriors on the components of
<code>k0</code> (default is a vector of ones for both);
<code>a1</code> and <code>b1</code> are vectors of shape and rate parameters of the gamma hyperpriors on the components of
<code>b0</code>  (default is the diagonal of the sample covariance of the data and a vector of ones). See details.
</p>
</li>
</ul>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>output</code></td>
<td>
<p>a list of arguments for generating posterior output. It contains:
</p>

<ul>
<li> <p><code>grid</code>, a grid of points at which to evaluate the estimated posterior mean density; a data frame
obtained with the <code>expand.grid</code> function.
</p>
</li>
<li> <p><code>out_param</code>, if equal to <code>TRUE</code>, the function returns the draws of the kernel's
parameters for each MCMC iteration, default is <code>FALSE</code>. See <code>value</code> for details.
</p>
</li>
<li> <p><code>out_type</code>, if <code>out_type = "FULL"</code>, the function returns the visited
partitions and the realizations of the posterior density for each iterations.
If <code>out_type = "MEAN"</code>, the function returns the estimated partitions and the mean of the densities sampled at each iterations.
If <code>out_type = "CLUST"</code>, the function returns the estimated partition.
Default <code>"FULL"</code>.
</p>
</li>
</ul>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This generic function fits a Pitman-Yor process mixture model for density estimation and clustering. The general model is
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(y) = \int K(y; \theta) \tilde p (d \theta),</code>
</p>
<p> where <code class="reqn">K(y; \theta)</code> is a kernel density with parameter
<code class="reqn">\theta\in\Theta</code>. Univariate and multivariate Gaussian kernels are implemented with different specifications for the parametric space
<code class="reqn">\Theta</code>, as described below.
The mixing measure <code class="reqn">\tilde p</code> has a Pitman-Yor process prior with strength parameter <code class="reqn">\vartheta</code>,
discount parameter <code class="reqn">\alpha</code>, and base measure <code class="reqn">P_0</code> admitting the specifications presented below. For posterior sampling,
three MCMC approaches are implemented. See details below.
</p>
<p><strong>Univariate data</strong>
</p>
<p>For univariate <code class="reqn">y</code> the function implements both a location and location-scale mixture model. The former assumes
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(y) = \int \phi(y; \mu, \sigma^2) \tilde p (d \mu) \pi(\sigma^2),</code>
</p>
<p> where
<code class="reqn">\phi(y; \mu, \sigma^2)</code> is a univariate Gaussian kernel function with mean <code class="reqn">\mu</code> and variance <code class="reqn">\sigma^2</code>,
and <code class="reqn">\pi(\sigma^2)</code> is an inverse gamma prior. The base measure is specified as
</p>
<p style="text-align: center;"><code class="reqn">P_0(d \mu) = N(d \mu; m_0, \sigma^2_0),</code>
</p>

<p>and <code class="reqn">\sigma^2 \sim IGa(a_0, b_0)</code>.
Optional hyperpriors for the base measure's parameters are
</p>
<p style="text-align: center;"><code class="reqn">(m_0,\sigma^2_0) \sim N(m_1, \sigma^2_0 / k_1) \times IGa(a_1, b_1).</code>
</p>

<p>The location-scale mixture model, instead, assumes
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(y) = \int \phi(y; \mu, \sigma^2) \tilde p (d \mu, d \sigma^2)</code>
</p>
<p> with normal-inverse gamma base measure
</p>
<p style="text-align: center;"><code class="reqn">P_0 (d \mu, d \sigma^2) = N(d \mu; m_0, \sigma^2 / k_0) \times IGa(d \sigma^2; a_0, b_0).</code>
</p>
<p> and (optional) hyperpriors
</p>
<p style="text-align: center;"><code class="reqn">m_0 \sim N(m_1, \sigma_1^2 ),\quad k_0 \sim Ga(\tau_1, \zeta_1),\quad b_0 \sim Ga(a_1, b_1).</code>
</p>

<p><strong>Multivariate data</strong>
</p>
<p>For multivariate <code class="reqn">y</code> (<code class="reqn">p</code>-variate) the function implements a location mixture model (with full covariance matrix) and two
different location-scale mixture models, with either full or diagonal covariance matrix. The location mixture model assumes
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(y) = \int \phi_p(y; \mu, \Sigma) \tilde p (d \mu) \pi(\Sigma)</code>
</p>
<p> where
<code class="reqn">\phi_p(y; \mu, \Sigma)</code> is a <code class="reqn">p</code>-dimensional Gaussian kernel function with mean vector <code class="reqn">\mu</code> and covariance matrix
<code class="reqn">\Sigma</code>. The prior on <code class="reqn">\Sigma</code> is inverse Whishart with parameters <code class="reqn">\Sigma_0</code> and <code class="reqn">\nu_0</code>, while the
base measure is
</p>
<p style="text-align: center;"><code class="reqn">P_0(d \mu) = N(d \mu;  m_0, S_0),</code>
</p>

<p>with optional hyperpriors
</p>
<p style="text-align: center;"><code class="reqn">m_0 \sim N(m_1, S_0 / k_1),\quad S_0 \sim IW(\lambda_1, \Lambda_1).</code>
</p>

<p>The location-scale mixture model assumes
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(x) = \int \phi_p(y;  \mu, \Sigma) \tilde p (d  \mu, d \Sigma).</code>
</p>
<p> Two possible structures for <code class="reqn">\Sigma</code>
are implemented, namely full and diagonal covariance. For the full covariance mixture model, the base measure is
the normal-inverse Wishart
</p>
<p style="text-align: center;"><code class="reqn">P_0 (d \mu, d \Sigma) = N(d \mu;  m_0, \Sigma / k_0) \times IW(d \Sigma; \nu_0, \Sigma_0),</code>
</p>

<p>with optional hyperpriors
</p>
<p style="text-align: center;"><code class="reqn">m_0 \sim N(m_1, S_1),\quad k_0 \sim Ga(\tau_1, \zeta_1),\quad b_0 \sim W(\nu_1, \Sigma_1).</code>
</p>

<p>The second location-scale mixture model assumes a diagonal covariance structure. This is equivalent to write the
mixture model as a mixture of products of univariate normal kernels, i.e.
</p>
<p style="text-align: center;"><code class="reqn">\tilde f(y) = \int \prod_{r=1}^p \phi(y_r;  \mu_r, \sigma^2_r) \tilde p (d  \mu_1,\ldots,d \mu_p, d \sigma_1^2,\ldots,d \sigma_p^2).</code>
</p>

<p>For this specification, the base measure is assumed defined as the product of <code class="reqn">p</code> independent normal-inverse gamma distributions, that is
</p>
<p style="text-align: center;"><code class="reqn">P_0 = \prod_{r=1}^p P_{0r}</code>
</p>
<p> where
</p>
<p style="text-align: center;"><code class="reqn">P_{0r}(d \mu_r,d \sigma_r^2) = N(d \mu_r; m_{0r}, \sigma^2_r / k_{0r}) \times Ga(d \sigma^2_r; a_{0r}, b_{0r}).</code>
</p>

<p>Optional hyperpriors can be added, and, for each component, correspond to the set of hyperpriors considered
for the univariate location-scale mixture model.
</p>
<p><strong>Posterior simulation methods</strong>
</p>
<p>This generic function implements three types of MCMC algorithms for posterior simulation.
The default method is the importance conditional sampler <code>'ICS'</code> (Canale et al. 2019). Other options are
the marginal sampler <code>'MAR'</code> (Neal, 2000) and the slice sampler <code>'SLI'</code> (Kalli et al. 2011).
The importance conditional sampler performs an importance sampling step when updating the values of
individual parameters <code class="reqn">\theta</code>, which requires to sample <code>m_imp</code> values from a suitable
proposal. Large values of <code>m_imp</code> are known to improve the mixing of the chain
at the cost of increased running time (Canale et al. 2019). Two options are available for the slice sampler,
namely the dependent slice-efficient sampler (<code>slice_type = 'DEP'</code>), which is set as default, and the
independent slice-efficient sampler (<code>slice_type = 'INDEP'</code>) (Kalli et al. 2011). See Corradin et al. (to appear)
for more details.
</p>


<h3>Value</h3>

<p>A <code>BNPdens</code> class object containing the estimated density and
the cluster allocations for each iterations. If <code>out_param = TRUE</code> the output
contains also the kernel specific parameters for each iteration. If <code>mcmc_dens = TRUE</code> the output
contains also a realization from the posterior density for each iteration. IF <code>mean_dens = TRUE</code>
the output contains just the mean of the realizations from the posterior density. The output contains
also informations as the number of iterations, the number of burn-in iterations, the used
computational time and the type of estimated model (<code>univariate = TRUE</code> or <code>FALSE</code>).
</p>


<h3>References</h3>

<p>Canale, A., Corradin, R., Nipoti, B. (2019), Importance conditional sampling for Bayesian nonparametric mixtures,
arXiv preprint, arXiv:1906.08147
</p>
<p>Corradin, R., Canale, A., Nipoti, B. (2021), BNPmix: An R Package for Bayesian Nonparametric Modeling via Pitman-Yor Mixtures,
Journal of Statistical Software, 100, doi:10.18637/jss.v100.i15
</p>
<p>Kalli, M., Griffin, J. E., and Walker, S. G. (2011), Slice sampling mixture models.
Statistics and Computing 21, 93-105, doi:10.1007/s11222-009-9150-y
</p>
<p>Neal, R. M. (2000), Markov Chain Sampling Methods for Dirichlet Process Mixture Models,
Journal of Computational and Graphical Statistics 9, 249-265, doi:10.2307/1390653
</p>


<h3>Examples</h3>

<pre><code class="language-R">data_toy &lt;- cbind(c(rnorm(100, -3, 1), rnorm(100, 3, 1)),
                  c(rnorm(100, -3, 1), rnorm(100, 3, 1)))
grid &lt;- expand.grid(seq(-7, 7, length.out = 50),
                    seq(-7, 7, length.out = 50))
est_model &lt;- PYdensity(y = data_toy, mcmc = list(niter = 200, nburn = 100),
output = list(grid = grid))
summary(est_model)
plot(est_model)

</code></pre>


</div>