<div class="container">

<table style="width: 100%;"><tr>
<td>ddnn</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Deep Distributional Neural Network</h2>

<h3>Description</h3>

<p>This function interfaces <span class="pkg">keras</span> infrastructures for high-level neural networks. The function
can be used as a standalone model fitting engine such as <code>bamlss</code> or as an on top
model engine to capture special features in the data that could not be captures by other
model fitting engines.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## Deep distributional neural net.
ddnn(object, optimizer = "adam",
  learning_rate = 0.01,
  epochs = 100, batch_size = NULL,
  nlayers = 2, units = 100, activation = "relu",
  l1 = NULL, l2 = NULL,
  validation_split = 0.2, early_stopping = TRUE, patience = 50,
  verbose = TRUE, ...)

## Predict method.
## S3 method for class 'ddnn'
predict(object, newdata,
  model = NULL, type = c("link", "parameter"),
  drop = TRUE, ...)

## CV method for optimizing
## the number of epochs using
## the CRPS.
cv_ddnn(formula, data, folds = 10,
  min_epochs = 300, max_epochs = 400,
  interval = c(-Inf, Inf), ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>An object of class <code>"bamlss"</code> or a <code>bamlss.formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>optimizer</code></td>
<td>
<p>Character or call to optimizer functions to be used within <code>fit</code>.
For character, options are: <code>"adam"</code> <code>"sgd"</code>, <code>"rmsprop"</code>, <code>"adagrad"</code>,
<code>"adadelta"</code>, <code>"adamax"</code>, <code>"adam"</code>. The default is
<code>optimizer_rmsprop</code> with learning rate set to <code>1e-04</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learning_rate</code></td>
<td>
<p>The learning rate of the optimizer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epochs</code></td>
<td>
<p>Number of times to iterate over the training data arrays, see
<code>fit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>batch_size</code></td>
<td>
<p>Number of samples per gradient update, see <code>fit</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nlayers</code></td>
<td>
<p>Number of hidden layers.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>units</code></td>
<td>
<p>Number of nodes per hidden layer, can be a vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>activation</code></td>
<td>
<p>Activation functions used for the hidden layers, can be a vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l1</code></td>
<td>
<p>Shrinkage parameter for L1 penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>l2</code></td>
<td>
<p>Shrinkage parameter for L2 penalty.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation_split</code></td>
<td>
<p>Proportion of data that should be used for validation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stopping</code></td>
<td>
<p>Logical, should early stopping of the optimizer be applied?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>patience</code></td>
<td>
<p>Integer, number of iterations the optimizer waits until early stopping is applied
after changes get small in validation data set.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Print information during runtime of the algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newdata</code></td>
<td>
<p>A <code>list</code> or <code>data.frame</code> that should
be used for prediction.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Character or integer specifying for which distributional parameter predictions should
be computed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>If <code>type = "link"</code> the predictor of the corresponding <code>model</code>
is returned. If <code>type = "parameter"</code> predictions on the distributional parameter scale
are returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>drop</code></td>
<td>
<p>If predictions for only one <code>model</code> are returned, the list structure is dropped.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>The model formula.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>The data used for estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>The number of folds that should be generated.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_epochs, max_epochs</code></td>
<td>
<p>Defines the minimum and maximum epochs thet should be used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>interval</code></td>
<td>
<p>Response interval, see function <code>CRPS</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Arguments passed to <code>bamlss.frame</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The default <span class="pkg">keras</span> model is a sequential model with two hidden layers with <code>"relu"</code>
activation function and 100 units in each layer. Between each layer is a dropout layer with
0.1 dropout rate.
</p>


<h3>Value</h3>

<p>For function <code>ddnn()</code> an object of class <code>"ddnn"</code>. Note that extractor
functions <code>fitted</code> and <code>residuals.bamlss</code> can be applied.
For function <code>predict.ddnn()</code> a list or vector of predicted values.
</p>


<h3>WARNINGS</h3>

<p>The deep learning infrastructure is experimental!
</p>


<h3>See Also</h3>

<p><code>bamlss.frame</code>, <code>bamlss</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: ## Simulate data.
set.seed(123)
n &lt;- 300
x &lt;- runif(n, -3, 3)
fsigma &lt;- -2 + cos(x)
y &lt;- sin(x) + rnorm(n, sd = exp(fsigma))

## Setup model formula.
f &lt;- list(
  y ~ x,
  sigma ~ x
)

## Fit neural network.
library("keras")
b &lt;- ddnn(f, epochs = 2000)

## Plot estimated functions.
par(mfrow = c(1, 2))
plot(x, y)
plot2d(fitted(b)$mu ~ x, add = TRUE)
plot2d(fitted(b)$sigma ~ x,
  ylim = range(c(fitted(b)$sigma, fsigma)))
plot2d(fsigma ~ x, add = TRUE, col.lines = "red")

## Predict with newdata.
nd &lt;- data.frame(x = seq(-6, 6, length = 100))
nd$p &lt;- predict(b, newdata = nd, type = "link")

par(mfrow = c(1, 2))
plot(x, y, xlim = c(-6, 6), ylim = range(c(nd$p$mu, y)))
plot2d(p$mu ~ x, data = nd, add = TRUE)
plot2d(p$sigma ~ x, data = nd,
  ylim = range(c(nd$p$sigma, fsigma)))
plot2d(fsigma ~ x, add = TRUE, col.lines = "red")

## Plot quantile residuals.
e &lt;- residuals(b)
plot(e)

## End(Not run)
</code></pre>


</div>