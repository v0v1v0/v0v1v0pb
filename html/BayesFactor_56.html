<div class="container">

<table style="width: 100%;"><tr>
<td>linearReg.R2stat</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Use R^2 statistic to compute Bayes factor for regression designs</h2>

<h3>Description</h3>

<p>Using the classical R^2 test statistic for (linear) regression designs, this
function computes the corresponding Bayes factor test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">linearReg.R2stat(N, p, R2, rscale = "medium", simple = FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>number of predictors in model, excluding intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R2</code></td>
<td>
<p>proportion of variance accounted for by the predictors, excluding
intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rscale</code></td>
<td>
<p>numeric prior scale</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>simple</code></td>
<td>
<p>if <code>TRUE</code>, return only the Bayes factor</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function can be used to compute the Bayes factor corresponding to a
multiple regression, using the classical R^2 (coefficient of determination)
statistic.  It can be used when you don't have access to the full data set
for analysis by <code>lmBF</code>, but you do have the test statistic.
</p>
<p>For details about the model, see the help for <code>regressionBF</code>,
and the references therein.
</p>
<p>The Bayes factor is computed via Gaussian quadrature.
</p>


<h3>Value</h3>

<p>If <code>simple</code> is <code>TRUE</code>, returns the Bayes factor (against the
intercept-only null). If <code>FALSE</code>, the function returns a
vector of length 3 containing the computed log(e) Bayes factor,
along with a proportional error estimate on the Bayes factor and the method used to compute it.
</p>


<h3>Author(s)</h3>

<p>Richard D. Morey (<a href="mailto:richarddmorey@gmail.com">richarddmorey@gmail.com</a>) and Jeffrey N.
Rouder (<a href="mailto:rouderj@missouri.edu">rouderj@missouri.edu</a>)
</p>


<h3>References</h3>

<p>Liang, F. and Paulo, R. and Molina, G. and Clyde, M. A. and
Berger, J. O. (2008). Mixtures of g-priors for Bayesian Variable
Selection. Journal of the American Statistical Association, 103, pp.
410-423
</p>
<p>Rouder, J. N.  and Morey, R. D. (in press, Multivariate Behavioral Research). Bayesian testing in
regression.
</p>


<h3>See Also</h3>

<p><code>integrate</code>, <code>lm</code>; see
<code>lmBF</code> for the intended interface to this function, using
the full data set.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Use attitude data set
data(attitude)
## Scatterplot
lm1 = lm(rating~complaints,data=attitude)
plot(attitude$complaints,attitude$rating)
abline(lm1)
## Traditional analysis
## p value is highly significant
summary(lm1)

## Bayes factor
## The Bayes factor is over 400,000;
## the data strongly favor hypothesis that
## the slope is not 0.
result = linearReg.R2stat(30,1,0.6813)
exp(result[['bf']])
</code></pre>


</div>