<div class="container">

<table style="width: 100%;"><tr>
<td>eplogprob.marg</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>eplogprob.marg - Compute approximate marginal inclusion probabilities from
pvalues</h2>

<h3>Description</h3>

<p><code>eplogprob.marg</code> calculates approximate marginal posterior inclusion
probabilities from p-values computed from a series of simple linear
regression models using a lower bound approximation to Bayes factors.  Used
to order variables and if appropriate obtain initial inclusion probabilities
for sampling using Bayesian Adaptive Sampling <code>bas.lm</code>
</p>


<h3>Usage</h3>

<pre><code class="language-R">eplogprob.marg(Y, X, thresh = 0.5, max = 0.99, int = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p>response variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>design matrix with a column of ones for the intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thresh</code></td>
<td>
<p>the value of the inclusion probability when if the p-value &gt;
1/exp(1), where the lower bound approximation is not valid.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max</code></td>
<td>
<p>maximum value of the inclusion probability; used for the
<code>bas.lm</code> function to keep initial inclusion probabilities away from 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>int</code></td>
<td>
<p>If the Intercept is included in the linear model, set the
marginal inclusion probability corresponding to the intercept to 1</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Sellke, Bayarri and Berger (2001) provide a simple calibration of p-values
</p>
<p>BF(p) = -e p log(p)
</p>
<p>which provide a lower bound to a Bayes factor for comparing H0: beta = 0
versus H1: beta not equal to 0, when the p-value p is less than 1/e.  Using
equal prior odds on the hypotheses H0 and H1, the approximate marginal
posterior inclusion probability
</p>
<p>p(beta != 0 | data ) = 1/(1 + BF(p))
</p>
<p>When p &gt; 1/e, we set the marginal inclusion probability to 0.5 or the value
given by <code>thresh</code>. For the eplogprob.marg the marginal p-values are
obtained using statistics from the p simple linear regressions
</p>
<p>P(F &gt; (n-2) R2/(1 - R2)) where F ~ F(1, n-2) where R2 is the square of the
correlation coefficient between y and X_j.
</p>


<h3>Value</h3>

<p><code>eplogprob.prob</code> returns a vector of marginal posterior
inclusion probabilities for each of the variables in the linear model. If
int = TRUE, then the inclusion probability for the intercept is set to 1.
</p>


<h3>Author(s)</h3>

<p>Merlise Clyde <a href="mailto:clyde@stat.duke.edu">clyde@stat.duke.edu</a>
</p>


<h3>References</h3>

<p>Sellke, Thomas, Bayarri, M. J., and Berger, James O.  (2001),
“Calibration of p-values for testing precise null hypotheses”, The
American Statistician, 55, 62-71.
</p>


<h3>See Also</h3>

<p><code>bas</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">
library(MASS)
data(UScrime)
UScrime[,-2] = log(UScrime[,-2])
eplogprob(lm(y ~ ., data=UScrime))
</code></pre>


</div>