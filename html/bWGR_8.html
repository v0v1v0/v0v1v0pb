<div class="container">

<table style="width: 100%;"><tr>
<td>WGR1 (MC)</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
MCMC Whole-genome Regression
</h2>

<h3>Description</h3>

<p>Univariate model to find breeding values through regression with optional resampling techniques (Xavier et al. 2017) and polygenic term (Kernel). See "Details" for additional standalone functions written in C++.
</p>


<h3>Usage</h3>

<pre><code class="language-R">wgr(y,X,it=1500,bi=500,th=1,bag=1,rp=FALSE,iv=FALSE,de=FALSE,
    pi=0,df=5,R2=0.5,eigK=NULL,VarK=0.95,verb=FALSE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>Numeric vector of observations (<code class="reqn">n</code>) describing the trait to be analyzed. <code>NA</code> is allowed.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>Numeric matrix containing the genotypic data. A matrix with <code class="reqn">n</code>
rows of observations and (<code class="reqn">m</code>) columns of molecular markers.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>it</code></td>
<td>

<p>Integer. Number of iterations or samples to be generated.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bi</code></td>
<td>

<p>Integer. Burn-in, the number of iterations or samples to be discarted.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>th</code></td>
<td>

<p>Integer. Thinning parameter, used to save memory by storing only one every 'th' samples.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bag</code></td>
<td>

<p>If different than one, it indicates the proportion of data to be subsampled in each Markov chain. For datasets with moderate number of observations, values of bag from 0.30 to 0.60 may speed up computation without losses in predicion properties. This argument enable users to enhance MCMC through subsampling (Xavier et al. 2017).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rp</code></td>
<td>

<p>Logical. Use replacement for bootstrap samples when bag is different than one.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iv</code></td>
<td>

<p>Logical. Assign markers independent variance, a T prior from a mixture of normals. If true, turns the default model BLUP into BayesA.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>de</code></td>
<td>

<p>Logical. Assign markers independent variance through double-exponential prior. If true, turns the default model BLUP into Bayesian LASSO. This argument overides iv.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pi</code></td>
<td>

<p>Value between 0 and 1. If greater than zero it activates variable selection, where markers have expected probability pi of having null effect.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>

<p>Prior degrees of freedom of variance components.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>R2</code></td>
<td>

<p>Expected R2, used to calculate the prior shape.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eigK</code></td>
<td>

<p>Output of function <code>eigen</code>. Spectral decomposition of the kernel used as a second random effect (eg. pedigree matrix).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>VarK</code></td>
<td>

<p>Numeric between 0 and 1. For reduction of dimensionality. Indicates the proportion of variance explained by Eigenpairs used to fit second random effect.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verb</code></td>
<td>

<p>Logical. If verbose is TRUE, function displays MCMC progress bar.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The model for the whole-genome regression is as follows:
</p>
<p style="text-align: center;"><code class="reqn">y = mu + Xb + u + e</code>
</p>

<p>where <code class="reqn">y</code> is the response variable, <code class="reqn">mu</code> is the intercept, <code class="reqn">X</code> is the genotypic matrix, <code class="reqn">b</code> is the regression coefficient or effect of an allele substitution, with <code class="reqn">d</code> probability of being included into the model, <code class="reqn">u</code> is the polygenic term if a kernel is used, and <code class="reqn">e</code> is the residual term.
</p>
<p>Users can obtain four WGR methods out of this function: BRR (pi=0,iv=F), BayesA (pi=0,iv=T), BayesB (pi=0.95,iv=T), BayesC (pi=0.95,iv=F) and Bayesian LASSO or BayesL (pi=0,de=T). Theoretical basis of each model is described by de los Campos et al. (2013).
</p>
<p>Gibbs sampler that updates regression coefficients is adapted from GSRU algorithm (Legarra and Misztal 2008). The variable selection of functions <code class="reqn">wgr</code>, <code class="reqn">BayesB</code> and <code class="reqn">BayesC</code> works through the unconditional prior algorithm proposed by Kuo and Mallick (1998), whereas <code class="reqn">BayesCpi</code> and <code class="reqn">BayesDpi</code> are based on Metropolis-Hastings. Prior shape estimates are computed as Sb = R2*df*var(y)/MSx and Se = (1-R2)*df*var(y), with an exception for <code class="reqn">BayesC</code> and <code class="reqn">BayesCpi</code> where the prior shape is Sb = R2*df*var(y)/MSx/(1-pi). The polygenic term is solved by Bayesian algorithm of reproducing kernel Hilbert Spaces proposed by de los Campos et al. (2010).
</p>
<p>In addition to <code>wgr</code>, standalone C++ functions available include:
</p>
<p>01) <code>BayesA(y,X,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>02) <code>BayesB(y,X,it=1500,bi=500,pi=0.95,df=5,R2=0.5)</code>
</p>
<p>03) <code>BayesC(y,X,it=1500,bi=500,pi=0.95,df=5,R2=0.5)</code>
</p>
<p>04) <code>BayesCpi(y,X,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>05) <code>BayesDpi(y,X,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>06) <code>BayesL(y,X,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>07) <code>BayesRR(y,X,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>The implementations that support two random effects include:
</p>
<p>08) <code>BayesA2(y,X1,X2,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>09) <code>BayesB2(y,X1,X2,it=1500,bi=500,pi=0.95,df=5,R2=0.5)</code>
</p>
<p>10) <code>BayesRR2(y,X1,X2,it=1500,bi=500,df=5,R2=0.5)</code>
</p>
<p>And the cross-validation for the C++ implementations, with arguments analogous to <code>emCV</code>.
</p>
<p><code>mcmcCV(y,gen,k=5,n=5,it=1500,bi=500,pi=0.95,df=5,R2=0.5,avg=T,llo=NULL,tbv=NULL,ReturnGebv=FALSE)</code>    
</p>


<h3>Value</h3>

<p>The function wgr returns a list with expected value from the marker effect (<code class="reqn">b</code>), probability of marker being in the model (<code class="reqn">d</code>), regression coefficient (<code class="reqn">g</code>), variance of each marker (<code class="reqn">Vb</code>), the intercept (<code class="reqn">mu</code>), the polygene (<code class="reqn">u</code>) and polygenic variance (<code class="reqn">Vk</code>), residual variance (<code class="reqn">Ve</code>) and the fitted value (<code class="reqn">hat</code>).
</p>


<h3>Author(s)</h3>

<p>Alencar Xavier
</p>


<h3>References</h3>

<p>de los Campos, G., Hickey, J. M., Pong-Wong, R., Daetwyler, H. D., and Calus, M. P. (2013). Whole-genome regression and prediction methods applied to plant and animal breeding. Genetics, 193(2), 327-345.
</p>
<p>de los Campos, G., Gianola, D., Rosa, G. J., Weigel, K. A., &amp; Crossa, J. (2010). Semi-parametric genomic-enabled prediction of genetic values using reproducing kernel Hilbert spaces methods. Genetics Research, 92(04), 295-308.
</p>
<p>Kuo, L., &amp; Mallick, B. (1998). Variable selection for regression models. Sankhya: The Indian Journal of Statistics, Series B, 65-81.
</p>
<p>Legarra, A., &amp; Misztal, I. (2008). Technical note: Computing strategies in genome-wide selection. Journal of dairy science, 91(1), 360-366.
</p>
<p>Xavier, A., Xu, S., Muir, W., &amp; Rainey, K. M. (2017). Genomic prediction using subsampling. BMC bioinformatics, 18(1), 191.
</p>


<h3>Examples</h3>

<pre><code class="language-R">    ## Not run: 
        
# Load data
data(tpod)

# BLUP
fit_BRR = wgr(y,gen,iv=FALSE,pi=0)
cor(y,fit_BRR$hat)

# BayesA
fit_BayesA = wgr(y,gen,iv=TRUE,pi=0)
cor(y,fit_BayesA$hat)

# BayesB
fit_BayesB = wgr(y,gen,iv=TRUE,pi=.95)
cor(y,fit_BayesB$hat)

# BayesC
fit_BayesC = wgr(y,gen,iv=FALSE,pi=.95)
cor(y,fit_BayesC$hat)

# BayesCpi
fit_BayesCpi = BayesCpi(y,gen)
cor(y,fit_BayesCpi$hat)        

# BayesDpi
fit_BayesDpi = BayesDpi(y,gen)
cor(y,fit_BayesDpi$hat)        
        
# BayesL
fit_BayesL = wgr(y,gen,de=TRUE)
cor(y,fit_BayesL$hat)

# Bagging BLUP
fit_Bag = wgr(y,gen,bag=0.5)
cor(y,fit_Bag$hat)
    
    
## End(Not run)
</code></pre>


</div>