<div class="container">

<table style="width: 100%;"><tr>
<td>bergmC</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calibrating misspecified Bayesian ERGMs</h2>

<h3>Description</h3>

<p>Function to transform a sample from the pseudo-posterior 
to one that is approximately sampled from the intractable 
posterior distribution.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bergmC(
  formula,
  prior.mean = NULL,
  prior.sigma = NULL,
  burn.in = 10000,
  main.iters = 40000,
  aux.iters = 3000,
  V.proposal = 1.5,
  thin = 1,
  rm.iters = 500,
  rm.a = 0.001,
  rm.alpha = 0,
  n.aux.draws = 400,
  aux.thin = 50,
  estimate = c("MLE", "CD"),
  seed = 1,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>formula; an <code>ergm</code> formula object,
of the form  &lt;network&gt; ~ &lt;model terms&gt;
where &lt;network&gt; is a <code>network</code> object
and &lt;model terms&gt; are <code>ergm-terms</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.mean</code></td>
<td>
<p>vector; mean vector of the multivariate Normal prior.
By default set to a vector of 0's.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.sigma</code></td>
<td>
<p>square matrix; variance/covariance matrix for the multivariate Normal prior.
By default set to a diagonal matrix with every diagonal entry equal to 100.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burn.in</code></td>
<td>
<p>count; number of burn-in iterations at the beginning of an MCMC run for the pseudo-posterior estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>main.iters</code></td>
<td>
<p>count; number of MCMC iterations after burn-in for the pseudo-posterior estimation.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aux.iters</code></td>
<td>
<p>count; number of auxiliary iterations used for drawing the first network from the ERGM likelihood (Robbins-Monro). See <code>control.simulate.formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>V.proposal</code></td>
<td>
<p>count; diagonal entry for the multivariate Normal proposal.
By default set to 1.5.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thin</code></td>
<td>
<p>count; thinning interval used in the simulation for the pseudo-posterior estimation. The number of MCMC iterations must be divisible by this value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rm.iters</code></td>
<td>
<p>count; number of iterations for the Robbins-Monro stochastic approximation algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rm.a</code></td>
<td>
<p>scalar; constant for sequence alpha_n (Robbins-Monro).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rm.alpha</code></td>
<td>
<p>scalar; noise added to gradient (Robbins-Monro).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.aux.draws</code></td>
<td>
<p>count; number of auxiliary networks drawn from the ERGM likelihood (Robbins-Monro). See <code>control.simulate.formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aux.thin</code></td>
<td>
<p>count; number of auxiliary iterations between network draws after the first network is drawn (Robbins-Monro). See <code>control.simulate.formula</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>estimate</code></td>
<td>
<p>If "MLE" (the default), then an approximate maximum likelihood estimator is used as a starting point in the Robbins-Monro algorithm. If "CD" , the Monte-Carlo contrastive divergence estimate is returned. See <code>ergm</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>integer; seed for the random number generator. See <code>set.seed</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Additional arguments, to be passed to the ergm function. See <code>ergm</code>.</p>
</td>
</tr>
</table>
<h3>References</h3>

<p>Bouranis, L., Friel, N., &amp; Maire, F. (2017). Efficient Bayesian inference for exponential 
random graph models by correcting the pseudo-posterior distribution. 
Social Networks, 50, 98-108. <a href="https://arxiv.org/abs/1510.00934">https://arxiv.org/abs/1510.00934</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
# Load the florentine marriage network
data(florentine)
                                 
# Calibrated pseudo-posterior:
cpp.flo &lt;- bergmC(flomarriage ~ edges + kstar(2),
                  aux.iters  = 500,
                  burn.in    = 500,
                  main.iters = 10000,
                  V.proposal = 2.5)

# Posterior summaries:
summary(cpp.flo)

## End(Not run)

</code></pre>


</div>