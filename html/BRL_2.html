<div class="container">

<table style="width: 100%;"><tr>
<td>BRL</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Beta Record Linkage</h2>

<h3>Description</h3>

<p>Beta record linkage methodology for probabilistic bipartite record linkage: the task of merging two duplicate-free 
datafiles that lack unique identifiers.  
This function runs all the steps of beta record linkage: creates comparisons of the records, runs Gibbs sampler on bipartite matchings,
and derives point estimate of bipartite matching (this determines the final linkage).  The parameters of <code>BRL</code> consist of 
all the parameters needed to run <code>compareRecords</code>, <code>bipartiteGibbs</code> and <code>linkRecords</code>,
except for intermediate input/output, and in addition to a parameter <code>burn</code> for the burn-in period of the Gibbs sampler.
</p>


<h3>Usage</h3>

<pre><code class="language-R">BRL(
  df1,
  df2,
  flds = NULL,
  flds1 = NULL,
  flds2 = NULL,
  types = NULL,
  breaks = c(0, 0.25, 0.5),
  nIter = 1000,
  burn = round(nIter * 0.1),
  a = 1,
  b = 1,
  aBM = 1,
  bBM = 1,
  seed = 0,
  lFNM = 1,
  lFM1 = 1,
  lFM2 = 2,
  lR = Inf
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>df1, df2</code></td>
<td>
<p>two datasets to be linked, of class <code>data.frame</code>, with rows representing records and columns
representing fields.  Without loss of generality, 
<code>df1</code> is assumed to have no less records than <code>df2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>flds</code></td>
<td>
<p>a vector indicating the fields to be used in the linkage.  Either a <code>character</code> vector, in which case
all entries need to be names of columns of <code>df1</code> and <code>df2</code>, or a <code>numeric</code> vector
indicating the columns in <code>df1</code> and <code>df2</code> to be used in the linkage.  If provided as a 
<code>numeric</code> vector it is assumed that the columns of <code>df1</code> and <code>df2</code> are organized such that 
it makes sense to compare the columns
<code>df1[,flds]</code> and <code>df2[,flds]</code> in that order.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>flds1, flds2</code></td>
<td>
<p>vectors indicating the fields of <code>df1</code> and <code>df2</code> to be used in the linkage.
Either <code>character</code> vectors, in which case  
all entries need to be names of columns of <code>df1</code> and <code>df2</code>, respectively, or <code>numeric</code> vectors
indicating the columns in <code>df1</code> and <code>df2</code> to be used in the linkage.  It is assumed that
it makes sense to compare the columns
<code>df1[,flds1]</code> and <code>df2[,flds2]</code> in that order.  These arguments are ignored if <code>flds</code> is specified.
If none of <code>flds,flds1,flds2</code> are specified, the columns with the same names in <code>df1</code> and <code>df2</code> 
are compared, if any.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>types</code></td>
<td>
<p>a vector of characters indicating the comparison type per comparison field.  The options
are: <code>"lv"</code> for comparisons based on the Levenshtein edit distance normalized to <code class="reqn">[0,1]</code>, with <code class="reqn">0</code>  
indicating no disagreement and <code class="reqn">1</code> indicating maximum disagreement;  
<code>"bi"</code> for binary comparisons (agreement/disagreement); <code>"nu"</code> for numeric comparisons computed as 
the absolute difference. 
The default is <code>"lv"</code>.  Fields compared with the <code>"lv"</code> option are first transformed to <code>character</code>
class.  Factors with different levels compared using the <code>"bi"</code> option are transformed to factors with the union 
of the levels.  Fields compared with the <code>"nu"</code> option need to be of class <code>numeric</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>breaks</code></td>
<td>
<p>break points for the comparisons to obtain levels of disagreement.
It can be a list of length equal to the number of comparison fields, containing one numeric vector with the break 
points for each comparison field, where entries corresponding to comparison type <code>"bi"</code> are ignored.  
It can also be a named list of length two with elements 'lv' and 'nu' 
containing numeric vectors with the break 
points for all Levenshtein-based and numeric comparisons, respectively.  
Finally, it can be a numeric vector with the break points for all comparison fields of type <code>"lv"</code> and <code>"nu"</code>,
which might be meaningful only if all the non-binary comparisons are of a single type, either <code>"lv"</code> or <code>"nu"</code>.  
For comparisons based on the normalized Levenshtein distance, a vector of length <code class="reqn">L</code> of break 
points for the interval <code class="reqn">[0,1]</code> leads to <code class="reqn">L+1</code> levels of disagreement.  Similarly, for comparisons based on the absolute 
difference, the break points are for the interval <code class="reqn">[0,\infty)</code>.  
The default is <code>breaks=c(0,.25,.5)</code>, which might be meaningful only for comparisons of type <code>"lv"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nIter</code></td>
<td>
<p>number of iterations of Gibbs sampler.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burn</code></td>
<td>
<p>number of iterations to discard as part of the burn-in period.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>a, b</code></td>
<td>
<p>hyper-parameters of the Dirichlet priors for the <code class="reqn">m</code> and <code class="reqn">u</code> parameters
in the model for the comparison data among matches and non-matches, respectively.
These can be vectors with as many 
entries as disagreement levels among all comparison fields.  If specified as positive constants, they 
get recycled to the required length.  If not specified, flat priors are taken.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>aBM, bBM</code></td>
<td>
<p>hyper-parameters of beta prior on bipartite matchings. Default is <code>aBM=bBM=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>seed to be used for pseudo-random number generation.  By default it sets <code>seed=0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lFNM</code></td>
<td>
<p>individual loss of a false non-match in the loss functions of Sadinle (2017), default <code>lFNM=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lFM1</code></td>
<td>
<p>individual loss of a false match of type 1 in the loss functions of Sadinle (2017), default <code>lFM1=1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lFM2</code></td>
<td>
<p>individual loss of a false match of type 2 in the loss functions of Sadinle (2017), default <code>lFM2=2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lR</code></td>
<td>
<p>individual loss of 'rejecting' to make a decision in the loss functions of Sadinle (2017), default <code>lR=Inf</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Beta record linkage (BRL, Sadinle, 2017) is a methodology for probabilistic bipartite record linkage, that is, the task of merging two
duplicate-free datafiles that lack unique identifiers.  This is accomplished by using the common partially identifying information 
of the entities contained in the datafiles.  The duplicate-free requirement means that we expect each entity to be represented maximum once in 
each datafile.  This methodology should not be used with datafiles that contain duplicates nor should it be used for deduplicating a single datafile. 
</p>
<p>The first step of BRL, accomplished by the function <code>compareRecords</code>, consists of constructing comparison vectors for each pair of records from the two datafiles.  
The current implementation allows binary comparisons (agree/disagree), numerical comparisons based on the absolute difference, 
and Levenshtein-based comparisons.  
This can be easily extended to other comparison types, so a resourceful user should be able to construct an object that recreates 
the output of <code>compareRecords</code> for other types of comparisons (so long as they get transformed to levels of disagreement), and still be able to run the next step outside 
the function <code>BRL</code>.
</p>
<p>The second step of BRL, accomplished by the function <code>bipartiteGibbs</code>, consists of running a Gibbs sampler that explores the space of bipartite matchings 
representing the plausible ways of linking the datafiles.  This sampler is derived from a model for the comparison data and a <em>beta</em> prior 
distribution on the space of bipartite matchings.  See Sadinle (2017) for details. 
</p>
<p>The third step of BRL, accomplished by the function <code>linkRecords</code>, consists of deriving a point estimate of the bipartite matching 
(which gives us the optimal way of linking the datafiles) 
by minimizing the expected value of 
a loss function that uses different penalties for different types of linkage errors.  The current implementation only supports the 
Bayes point estimates of bipartite matchings that can be obtained in closed form according to Theorems 1, 2 and 3 of Sadinle (2017).
The losses have to be positive numbers and satisfy one of three conditions:
</p>

<ol>
<li>
<p> Conditions of Theorem 1 of Sadinle (2017):
<code>(lR == Inf) &amp; (lFNM &lt;= lFM1) &amp; (lFNM + lFM1 &lt;= lFM2)</code>
</p>
</li>
<li>
<p> Conditions of Theorem 2 of Sadinle (2017):
<code>((lFM2 &gt;= lFM1) &amp; (lFM1 &gt;= 2*lR)) | ((lFM1 &gt;= lFNM) &amp; (lFM2 &gt;= lFM1 + lFNM))</code>
</p>
</li>
<li>
<p> Conditions of Theorem 3 of Sadinle (2017):
<code>(lFM2 &gt;= lFM1) &amp; (lFM1 &gt;= 2*lR) &amp; (lFNM &gt;= 2*lR)</code>
</p>
</li>
</ol>
<p>If one of the last two conditions is satisfied, the point estimate might be partial, meaning that there
might be some records in datafile 2 for which the point estimate does not include a linkage decision.
For combinations of losses not supported here, the linear sum assignment problem outlined by Sadinle (2017)
needs to be solved.
</p>


<h3>Value</h3>

<p>A vector containing the point estimate of the bipartite matching, as in the output of <code>linkRecords</code>.  If <code>lR != Inf</code> the output might be a partial estimate.
A number smaller or equal to <code>n1</code> in entry <code>j</code> indicates the record in datafile 1 to which record <code>j</code> in datafile 2 
gets linked, a number <code>n1+j</code> indicates that record <code>j</code> does not get linked to any record in datafile 1, and the value <code>-1</code> 
indicates a 'rejection' to link, meaning that the correct linkage decision is not clear.
</p>


<h3>References</h3>

<p>Mauricio Sadinle (2017). Bayesian Estimation of Bipartite Matchings for Record Linkage. <em>Journal of the
American Statistical Association</em> 112(518), 600-612. [<a href="https://doi.org/10.1080/01621459.2016.1148612">Published</a>] [<a href="https://arxiv.org/abs/1601.06630">arXiv</a>]
</p>


<h3>See Also</h3>

<p><code>compareRecords</code> for examples on how to work with different types of comparison data, 
<code>bipartiteGibbs</code> for Gibbs sampler on bipartite matchings, and <code>linkRecords</code> for examples 
on full and partial point estimates of the true bipartite matching that indicates which records to link.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(twoFiles)

(Zhat &lt;- BRL(df1, df2, flds=c("gname", "fname", "age", "occup"), 
				types=c("lv","lv","bi","bi")))

n1 &lt;- nrow(df1)

Ztrue &lt;- df2ID

## number of links (estimated matches)
nLinks &lt;- sum(Zhat &lt;= n1) 

## number of actual matches according to the ground truth
nMatches &lt;- sum(Ztrue &lt;= n1) 

## number of links that are actual matches
nCorrectLinks &lt;- sum(Zhat[Zhat&lt;=n1]==Ztrue[Zhat&lt;=n1])

## compute measures of performance 

## precision 
nCorrectLinks/nLinks

## recall
nCorrectLinks/nMatches

## the linked record pairs
cbind( df1[Zhat[Zhat&lt;=n1],], df2[Zhat&lt;=n1,] )

## finally, note that we could run BRL step by step as follows

## create comparison data 
myCompData &lt;- compareRecords(df1, df2, 
                             flds=c("gname", "fname", "age", "occup"), 
                             types=c("lv","lv","bi","bi"))

## Gibbs sampling from posterior of bipartite matchings
chain &lt;- bipartiteGibbs(myCompData)

## bipartite matching Bayes estimate derived from the loss functions of Sadinle (2017)
Zhat2 &lt;- linkRecords(chain$Z, n1=n1)

identical(Zhat, Zhat2)

</code></pre>


</div>