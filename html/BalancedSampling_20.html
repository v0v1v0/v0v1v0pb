<div class="container">

<table style="width: 100%;"><tr>
<td>lpm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>The (Local) Pivotal Methods</h2>

<h3>Description</h3>

<p>Selects spatially balanced samples with prescribed inclusion probabilities
from a finite population using the Local Pivotal Method 1 (LPM1).
</p>


<h3>Usage</h3>

<pre><code class="language-R">lpm(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm1(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm2(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

lpm1s(prob, x, type = "kdtree2", bucketSize = 50, eps = 1e-12)

spm(prob, eps = 1e-12)

rpm(prob, eps = 1e-12)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prob</code></td>
<td>
<p>A vector of length N with inclusion probabilities, or an integer &gt; 1. If an integer n, then the sample will be drawn with equal probabilities n / N.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>An N by p matrix of (standardized) auxiliary variables. Squared euclidean distance is used in the <code>x</code> space.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>type</code></td>
<td>
<p>The method used in finding nearest neighbours.
Must be one of <code>"kdtree0"</code>, <code>"kdtree1"</code>, <code>"kdtree2"</code>, and
<code>"notree"</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bucketSize</code></td>
<td>
<p>The maximum size of the terminal nodes in the k-d-trees.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>eps</code></td>
<td>
<p>A small value used to determine when an updated probability is
close enough to 0.0 or 1.0.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>If <code>prob</code> sum to an integer n, a fixed sized sample (n) will be produced.
For <code>spm</code> and <code>rpm</code>, <code>prob</code> must be a vector of inclusion probabilities.
If equal inclusion probabilities is wanted, this can be produced by
<code>rep(n / N, N)</code>.
</p>
<p>The available pivotal methods are:
</p>

<ul>
<li> <p><code>lpm1</code>: The Local Pivotal Mehtod 1 (Grafström et al., 2012).
Updates only units which are mutual nearest neighbours.
Selects such a pair at random.
</p>
</li>
<li> <p><code>lpm2</code>, <code>lpm</code>: The Local Pivotal Method 2 (Grafström et al., 2012).
Selects a unit at random, which competes with this units nearest neighbour.
</p>
</li>
<li> <p><code>lpm1s</code>: The Local Pivotal Method 1 search: (Prentius, 2023).
Updates only units which are mutual nearest neighbours.
Selects such a pair by branching the remaining units, giving higher
probabilities to update a pair with a long branch.
This changes the algorithm of lpm1, but makes it faster.
</p>
</li>
<li> <p><code>spm</code>: The Sequential Pivotal Method.
Selects the two units with smallest indices to compete against each other.
If the list is ordered, the algorithm is similar to systematic sampling.
</p>
</li>
<li> <p><code>rpm</code>: The Random Pivotal Method.
Selects two units at random to compete against each other.
Produces a design with high entropy.
</p>
</li>
</ul>
<h3>Value</h3>

<p>A vector of selected indices in 1,2,...,N.
</p>


<h3>Functions</h3>


<ul>
<li> <p><code>lpm1()</code>: 
</p>
</li>
<li> <p><code>lpm2()</code>: 
</p>
</li>
<li> <p><code>lpm1s()</code>: 
</p>
</li>
<li> <p><code>spm()</code>: 
</p>
</li>
<li> <p><code>rpm()</code>: 
</p>
</li>
</ul>
<h3>k-d-trees</h3>

<p>The <code>type</code>s "kdtree" creates k-d-trees with terminal node bucket sizes
according to <code>bucketSize</code>.
</p>

<ul>
<li>
<p>"kdtree0" creates a k-d-tree using a median split on alternating variables.
</p>
</li>
<li>
<p>"kdtree1" creates a k-d-tree using a median split on the largest range.
</p>
</li>
<li>
<p>"kdtree2" creates a k-d-tree using a sliding-midpoint split.
</p>
</li>
<li>
<p>"notree" does a naive search for the nearest neighbour.
</p>
</li>
</ul>
<h3>References</h3>

<p>Friedman, J. H., Bentley, J. L., &amp; Finkel, R. A. (1977).
An algorithm for finding best matches in logarithmic expected time.
ACM Transactions on Mathematical Software (TOMS), 3(3), 209-226.
</p>
<p>Deville, J.-C., &amp;  Tillé, Y. (1998).
Unequal probability sampling without replacement through a splitting method.
Biometrika 85, 89-101.
</p>
<p>Maneewongvatana, S., &amp; Mount, D. M. (1999, December).
It’s okay to be skinny, if your friends are fat.
In Center for geometric computing 4th annual workshop on computational geometry (Vol. 2, pp. 1-8).
</p>
<p>Chauvet, G. (2012).
On a characterization of ordered pivotal sampling.
Bernoulli, 18(4), 1320-1340.
</p>
<p>Grafström, A., Lundström, N.L.P. &amp; Schelin, L. (2012).
Spatially balanced sampling through the Pivotal method.
Biometrics 68(2), 514-520.
</p>
<p>Lisic, J. J., &amp; Cruze, N. B. (2016, June).
Local pivotal methods for large surveys.
In Proceedings of the Fifth International Conference on Establishment Surveys.
</p>
<p>Prentius, W. (2023)
Manuscript.
</p>


<h3>See Also</h3>

<p>Other sampling: 
<code>cube()</code>,
<code>hlpm2()</code>,
<code>lcube()</code>,
<code>scps()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
s = lpm2(prob, x);
plot(x[, 1], x[, 2]);
points(x[s, 1], x[s, 2], pch = 19);

set.seed(12345);
prob = c(0.2, 0.25, 0.35, 0.4, 0.5, 0.5, 0.55, 0.65, 0.7, 0.9);
N = length(prob);
x = matrix(runif(N * 2), ncol = 2);
ep = rep(0L, N);
r = 10000L;
for (i in seq_len(r)) {
  s = lpm2(prob, x);
  ep[s] = ep[s] + 1L;
}
print(ep / r);

set.seed(12345);
N = 1000;
n = 100;
prob = rep(n/N, N);
x = matrix(runif(N * 2), ncol = 2);
lpm1(prob, x);
lpm2(prob, x);
lpm1s(prob, x);
spm(prob);
rpm(prob);

## End(Not run)
</code></pre>


</div>