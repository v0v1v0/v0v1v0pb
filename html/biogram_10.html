<div class="container">

<table style="width: 100%;"><tr>
<td>calc_ig</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculate IG for single feature</h2>

<h3>Description</h3>

<p>Computes information gain of single feature and target vector.
</p>


<h3>Usage</h3>

<pre><code class="language-R">calc_ig(feature, target, len_target, pos_target)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>feature</code></td>
<td>
<p>feature vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>target</code></td>
<td>
<p>target.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>len_target</code></td>
<td>
<p>length of the target vector.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pos_target</code></td>
<td>
<p>number of positive cases in the target vector.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The information gain term is used here (improperly) as a synonym of mutual 
information. It is defined as:
</p>
<p style="text-align: center;"><code class="reqn">IG(X; Y) = \sum_{y \in Y} \sum_{x \in X} p(x, y) \log \left(\frac{p(x, y)}{p(x) p(y)}  \right)</code>
</p>

<p>In biogram package information gain is computed using following relationship: 
<code class="reqn">IG = E(S) - E(S|F)</code>
</p>


<h3>Value</h3>

<p>A <code>numeric</code> vector of length 1 representing information gain in nats.
</p>


<h3>Note</h3>

<p>During calculations <code class="reqn">0 \log 0  = 0</code>. For a justification see References. 
</p>
<p>The function was designed to be afast subroutine of 
<code>calc_criterion</code> and might be cumbersome if directly called by a user.
</p>


<h3>References</h3>

<p>Cover TM, Thomas JA <em>Elements of Information Theory, 2nd Edition</em>
Wiley, 2006.
</p>


<h3>Examples</h3>

<pre><code class="language-R">tar &lt;- sample(0L:1, 100, replace = TRUE)
feat &lt;- sample(0L:1, 100, replace = TRUE)
calc_ig(feat, tar, 100, sum(tar))
</code></pre>


</div>