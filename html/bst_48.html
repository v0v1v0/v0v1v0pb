<div class="container">

<table style="width: 100%;"><tr>
<td>rbstpath</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Robust Boosting Path for Nonconvex Loss Functions</h2>

<h3>Description</h3>

<p>Gradient boosting path for optimizing robust loss functions with componentwise
linear, smoothing splines, tree models as base learners. See details below before use.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rbstpath(x, y, rmstop=seq(40, 400, by=20), ctrl=bst_control(), del=1e-16, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p> a data frame containing the variables in the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> vector of responses. <code>y</code> must be in {1, -1}. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rmstop</code></td>
<td>
<p> vector of boosting iterations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ctrl</code></td>
<td>
<p> an object of class <code>bst_control</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>del</code></td>
<td>
<p>convergency criteria</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>arguments passed to <code>rbst</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function invokes <code>rbst</code> with <code>mstop</code> being each element of vector <code>rmstop</code>. It can provide different paths. Thus <code>rmstop</code> serves as another hyper-parameter. However, the most important hyper-parameter is the loss truncation point or the point determines the level of nonconvexity. This is an experimental function and may not be needed in practice. 
</p>


<h3>Value</h3>

<p>A length <code>rmstop</code> vector of lists with each element being an object of class <code>rbst</code>.
</p>


<h3>Author(s)</h3>

<p> Zhu Wang </p>


<h3>See Also</h3>

<p><code>rbst</code></p>


<h3>Examples</h3>

<pre><code class="language-R">x &lt;- matrix(rnorm(100*5),ncol=5)
c &lt;- 2*x[,1]
p &lt;- exp(c)/(exp(c)+exp(-c))
y &lt;- rbinom(100,1,p)
y[y != 1] &lt;- -1
y[1:10] &lt;- -y[1:10]
x &lt;- as.data.frame(x)
dat.m &lt;- bst(x, y, ctrl = bst_control(mstop=50), family = "hinge", learner = "ls")
predict(dat.m)
dat.m1 &lt;- bst(x, y, ctrl = bst_control(twinboost=TRUE, 
coefir=coef(dat.m), xselect.init = dat.m$xselect, mstop=50))
dat.m2 &lt;- rbst(x, y, ctrl = bst_control(mstop=50, s=0, trace=TRUE), 
rfamily = "thinge", learner = "ls")
predict(dat.m2)
rmstop &lt;- seq(10, 40, by=10)
dat.m3 &lt;- rbstpath(x, y, rmstop, ctrl=bst_control(s=0), rfamily = "thinge", learner = "ls")
</code></pre>


</div>