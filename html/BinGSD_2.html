<div class="container">

<table style="width: 100%;"><tr>
<td>asymdesign</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Boundary and sample size computation using asymptotic test.</h2>

<h3>Description</h3>

<p>Calculate boundaries and sample sizes of single-arm group sequential design
with binary endpoint based on asymptotic test.
</p>


<h3>Usage</h3>

<pre><code class="language-R">asymdesign(I, beta = 0.3, betaspend, alpha = 0.05, p_0, p_1, K, tol = 1e-06)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>I</code></td>
<td>
<p>The information fractions at each analysis. For binary endpoints, the
information fraction for anaysis k is equal to n_k/n_K, where n_k is the
sample size available at analysis k and n_K is the sample size available at
the last analysis or the maximum sample size. Should be a positive
increasing vector of length K or K-1. If I has K elements among which the
last one is not 1, then I will be standardized so that the last information
fraction is 1. If I has K-1 elements, the last element in I must be less
than 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>The desired overall type II error level. Should be a scalar within
the interval (0,0.5]. Default value is 0.3, that is, power=0.7.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betaspend</code></td>
<td>
<p>The proportions of beta spent at each analysis. Should be a
vector of length K with all elements belong to [0,1]. If the sum of all
elements in betaspend is not equal to 1, betaspend will be standardized.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha</code></td>
<td>
<p>The desired overall type I error level. Should be a scalar within
the interval (0,0.3]. Default is 0.05.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_0</code></td>
<td>
<p>The response rate or the probability of success under null
hypothesis. Should be a scalar within (0,1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p_1</code></td>
<td>
<p>The response rate or the probability of success under alternative
hypothesis. Should be a scalar within (p_0,1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>The maximum number of analyses, including the interim and the final.
Should be an integer within (1,20]. K will be rounded to its nearest whole
number if it is not an integer.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tol</code></td>
<td>
<p>The tolerance level which is essentially the maximum acceptable difference between
the desired type II error spending and the actual type II error spending, when
computing the boundaries using asymptotic test. Should be a positive scalar no
more than 0.01. The default value is 1e-6.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Suppose <code class="reqn">X_{1}, X_{2}, \ldots</code> are binary outcomes following Bernoulli
distribution <code class="reqn">b(1,p)</code>, in which 1 stands for the case that the subject
responds to the treatment and 0 otherwise. Consider a group sequential test
with <code class="reqn">K</code> planned analyses, where the null and alternative hypotheses are
<code class="reqn">H_0: p=p_0</code> and <code class="reqn">H_1: p=p_1</code> respectively. Note that generally
<code class="reqn">p_1</code> is greater than <code class="reqn">p_0</code>. For <code class="reqn">k&lt;K</code>, the trial stops if and
only if the test statistic <code class="reqn">Z_k</code> crosses the futility boundary, that is,
<code class="reqn">Z_k&lt;=l_k</code>. The lower bound for the last analysis <code class="reqn">l_K</code> is set to be
equal to the last and only upper bound <code class="reqn">u_K</code> to make a decision. At the
last analysis, the null hypothesis will be rejected if <code class="reqn">Z_K&gt;=u_K</code>.
</p>
<p>The computation of lower bounds except for the last one is implemented with
<code class="reqn">u_K</code> fixed, thus the derived lower bounds are non-binding. Furthermore,
the overall type I error will not be inflated if the trial continues after
crossing any of the interim lower bounds, which is convenient for the purpose
of monitoring. Let the sequence of sample sizes required at each analysis be
<code class="reqn">n_{1}, n_{2}, \ldots, n_{K}</code>. For binomial endpoint, the Fisher
information equals <code class="reqn">n_k/p/(1-p)</code> which is proportional to <code class="reqn">n_k</code>.
Accordingly, the information fraction available at each analysis is equivalent
to <code class="reqn">n_k/n_K</code>.
</p>
<p>For a <code class="reqn">p_0</code> not close to 1 or 0, with a large sample size, the test
statistic at analysis <code class="reqn">k</code> is
<code class="reqn">Z_k=\hat{\theta}_k\sqrt{n_k/p/(1-p)}=(\sum_{s=1}^{n_k}X_s/n_k-p_0)\sqrt{n_k/p/(1-p)}</code>,
which follows the normal distribution <code class="reqn">N(\theta \sqrt{n_k/p/(1-p)},1)</code>
with <code class="reqn">\theta=p-p_0</code>. In practice, <code class="reqn">p</code> in <code class="reqn">Z_k</code> can be substituted
with the sample response rate <code class="reqn">\sum_{s=1}^{n_k}X_s/n_k</code>.
</p>
<p>Under the null hypothesis, <code class="reqn">\theta=0</code> and <code class="reqn">Z_k</code> follows a standard
normal distribution. During the calculation, the only upper bound <code class="reqn">u_K</code> is
firstly derived under <code class="reqn">H_0</code>, without given <code class="reqn">n_K</code>. Thus, there is no
need to adjust <code class="reqn">u_K</code> for different levels of <code class="reqn">n_K</code>. Following East,
given <code class="reqn">u_K</code>, compute the maximum sample size <code class="reqn">n_K</code> under <code class="reqn">H_1</code>.
The rest sample sizes can be obtained by multipling information fractions
and <code class="reqn">n_K</code>. The lower boundaries for the first <code class="reqn">K-1</code> analyses are
sequentially determined by a search method. The whole searching procedure
stops if the overall type II error does not excess the desired level or the
times of iteration excess 30. Otherwise, increase the sample sizes until
the type II error meets user's requirement.
</p>
<p>The multiple integrals of multivariate normal density functions are conducted with
<code>pmvnorm</code> in R package mvtnorm. Through a few transformations of the integral variables,
<code>pmvnorm</code> turns the multiple integral to the product of several
univariate integrals, which greatly reduces the computational burden of sequentially searching for
appropriate boundaries.
</p>


<h3>Value</h3>

<p>An object of the class asymdesign. This class contains:
</p>

<ul>
<li>
<p>I: I used in computation.
</p>
</li>
<li>
<p>beta: As input.
</p>
</li>
<li>
<p>betaspend: The desired type II error spent at each analysis used in computation.
</p>
</li>
<li>
<p>alpha: As input.
</p>
</li>
<li>
<p>p_0: As input.
</p>
</li>
<li>
<p>p_1: As input.
</p>
</li>
<li>
<p>K: K used in computation.
</p>
</li>
<li>
<p>tol: As input.
</p>
</li>
<li>
<p>n.I: A vector of length
K which contains sample sizes required at each analysis to achieve desired
type I and type II error requirements. n.I equals sample size for the last
analysis times the vector of information fractions.
</p>
</li>
<li>
<p>u_K: The upper boundary for the last analysis.
</p>
</li>
<li>
<p>lowerbounds: A vector of length K
which contains lower boundaries for each analysis. Note that the lower
boundaries are non-binding.
</p>
</li>
<li>
<p>problow: Probabilities of crossing the
lower bounds under <code class="reqn">H_1</code> or the actual type II error at each analysis.
</p>
</li>
<li>
<p>probhi: Probability of crossing the last upper bound under <code class="reqn">H_0</code> or the
actual type I error. </p>
</li>
<li>
<p>power: power of the group sequential test with
the value equals 1-sum(problow). </p>
</li>
</ul>
<h3>Reference</h3>

 <ul>
<li>
<p>Cytel Inc. East Version 6.4.1 Manual.
2017.
</p>
</li>
<li>
<p>Alan Genz et al. (2018). mvtnorm: Multivariate Normal and t Distributions. R package version 1.0-11.</p>
</li>
</ul>
<h3>See Also</h3>

<p><code>asymprob</code>, <code>asymcp</code>,
<code>exactdesign</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">I=c(0.2,0.4,0.6,0.8,0.99)
beta=0.2
betaspend=c(0.1,0.2,0.3,0.3,0.2)
alpha=0.05
p_0=0.3
p_1=0.5
K=4.6
tol=1e-6
tt1=asymdesign(I,beta,betaspend,alpha,p_0,p_1,K,tol)

</code></pre>


</div>