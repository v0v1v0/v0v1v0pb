<div class="container">

<table style="width: 100%;"><tr>
<td>GibbsBvs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian Variable Selection for linear regression models using Gibbs
sampling.</h2>

<h3>Description</h3>

<p>Approximate computation of summaries of the posterior distribution using a
Gibbs sampling algorithm to explore the model space and frequency of
"visits" to construct the estimates.
</p>


<h3>Usage</h3>

<pre><code class="language-R">GibbsBvs(
  formula,
  data,
  null.model = paste(as.formula(formula)[[2]], " ~ 1", sep = ""),
  prior.betas = "Robust",
  prior.models = "ScottBerger",
  n.iter = 10000,
  init.model = "Full",
  n.burnin = 500,
  n.thin = 1,
  time.test = TRUE,
  priorprobs = NULL,
  seed = runif(1, 0, 16091956)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>Formula defining the most complex regression model in the
analysis. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.model</code></td>
<td>
<p>A formula defining which is the simplest (null) model.
It should be nested in the full model. By default, the null model is defined
to be the one with just the intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.betas</code></td>
<td>
<p>Prior distribution for regression parameters within each
model (to be literally specified). Possible choices include "Robust", "Robust.G", "Liangetal", "gZellner",
"ZellnerSiow", "FLS", "intrinsic.MGC" and "IHG" (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.models</code></td>
<td>
<p>Prior distribution over the model space (to be literally specified). Possible
choices are "Constant", "ScottBerger" and "User" (see details).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.iter</code></td>
<td>
<p>The total number of iterations performed after the burn in
process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init.model</code></td>
<td>
<p>The model at which the simulation process starts. Options
include "Null" (the model only with the covariates specified in
<code>fixed.cov</code>), "Full" (the model defined by <code>formula</code>), "Random" (a
randomly selected model) and a vector with p (the number of covariates to
select from) zeros and ones defining a model. When p&gt;n the dimension of the
init.model must be smaller than n. Otherwise the function produces
an error.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.burnin</code></td>
<td>
<p>Length of burn in, i.e. number of iterations to discard at
the beginning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.thin</code></td>
<td>
<p>Thinning rate. Must be a positive integer.  Set 'n.thin' &gt; 1
to save memory and computation time if 'n.iter' is large. Default is 1. This
parameter jointly with <code>n.iter</code> sets the number of simulations kept and
used to construct the estimates so is important to keep in mind that a large
value for 'n.thin' can reduce the precision of the results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time.test</code></td>
<td>
<p>If TRUE and the number of variables is large (&gt;=21) a
preliminary test to estimate computational time is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priorprobs</code></td>
<td>
<p>A p+1 dimensional vector defining the prior probabilities
Pr(M_i) (should be used in the case where <code>prior.models</code>="User"; see
the details in <code>Bvs</code>.)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>A seed to initialize the random number generator</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is a heuristic approximation to the function
<code>Bvs</code> so the details there apply also here.
</p>
<p>The algorithm implemented is a Gibbs sampling-based searching algorithm
originally proposed by George and McCulloch (1997). Garcia-Donato and
Martinez-Beneito (2013) have shown that this simple sampling strategy in
combination with estimates based on frequency of visits (the one here
implemented) provides very reliable results.
</p>


<h3>Value</h3>

<p><code>GibbsBvs</code> returns an object of class <code>Bvs</code> with the
following elements: </p>
<table>
<tr style="vertical-align: top;">
<td><code>time </code></td>
<td>
<p>The internal time consumed in solving the
problem</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmfull </code></td>
<td>
<p>The <code>lm</code> class object that results when the
model defined by <code>formula</code> is fitted by <code>lm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmnull </code></td>
<td>
<p>The
<code>lm</code> class object that results when the model defined by
<code>fixed.cov</code> is fitted by <code>lm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variables </code></td>
<td>
<p>The name of all
the potential explanatory variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n </code></td>
<td>
<p>Number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p </code></td>
<td>
<p>Number of explanatory variables to select from</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k </code></td>
<td>
<p>Number
of fixed variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>HPMbin </code></td>
<td>
<p>The binary expression of the most
probable model found.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inclprob </code></td>
<td>
<p>A named vector with the
estimates of the inclusion probabilities of all the variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jointinclprob </code></td>
<td>
<p>A <code>data.frame</code> with the estimates of the joint
inclusion probabilities of all the variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>postprobdim </code></td>
<td>
<p>Estimates
of posterior probabilities of the dimension of the true model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelslogBF</code></td>
<td>
<p>A matrix with both the binary representation of the
visited models after the burning period and the Bayes factor (log scale) of
that model to the null model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priorprobs</code></td>
<td>
<p>If <code>prior.models</code>="User" then this vector is stored here. Else, the #' type of prior as defined in <code>prior.models</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call </code></td>
<td>
<p>The <code>call</code> to the
function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C</code></td>
<td>
<p>An estimation of the normalizing constant (C=sum Bi Pr(Mi), for Mi in the model space) using the method in George and McCulloch (1997).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method </code></td>
<td>
<p><code>gibbs</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.betas</code></td>
<td>
<p>prior.betas</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.models</code></td>
<td>
<p>prior.models</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priorprobs</code></td>
<td>
<p>priorprobs</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Gonzalo Garcia-Donato and Anabel Forte
</p>


<h3>References</h3>

<p>Garcia-Donato, G. and Martinez-Beneito, M.A.
(2013)&lt;DOI:10.1080/01621459.2012.742443&gt; On sampling strategies in Bayesian
variable selection problems with large model spaces. Journal of the American
Statistical Association, 108: 340-352.
</p>
<p>George E. and McCulloch R. (1997) Approaches for Bayesian variable
selection. Statistica Sinica, 7, 339:372.
</p>


<h3>See Also</h3>

<p><code>plot.Bvs</code> for several plots of the result,
<code>BMAcoeff</code> for obtaining model averaged simulations
of regression coefficients and <code>predict.Bvs</code> for
predictions. 
</p>
<p>See <code>GibbsBvsF</code> if there are factors among the explanatory variables.
</p>
<p>See <code>pltltn</code> for corrections on estimations for the
situation where p&gt;&gt;n. See the help in  <code>pltltn</code> for an application
in this situation.
</p>
<p>Consider <code>Bvs</code> for exact
version obtained enumerating all entertained models (recommended when
p&lt;20).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
#Analysis of Ozone35 data

data(Ozone35)

#We use here the (Zellner) g-prior for
#regression parameters and constant prior
#over the model space
#In this Gibbs sampling scheme, we perform 10100 iterations,
#of which the first 100 are discharged (burnin) and of the remaining
#only one each 10 is kept.
#as initial model we use the Full model
Oz35.GibbsBvs&lt;- GibbsBvs(formula= y ~ ., data=Ozone35, prior.betas="gZellner",
prior.models="Constant", n.iter=10000, init.model="Full", n.burnin=100,
time.test = FALSE)

#Note: this is a heuristic approach and results are estimates
#of the exact answer.

#with the print we can see which is the most probable model
#among the visited
Oz35.GibbsBvs

#The estimation of inclusion probabilities and
#the model-averaged estimation of parameters:
summary(Oz35.GibbsBvs)

#Plots:
plot(Oz35.GibbsBvs, option="conditional")

## End(Not run)

</code></pre>


</div>