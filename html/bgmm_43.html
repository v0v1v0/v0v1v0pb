<div class="container">

<table style="width: 100%;"><tr>
<td>mModel</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Fitting Gaussian Mixture Model 
</h2>

<h3>Description</h3>

<p>These functions fit different variants of Gaussian mixture models. These variants 
differ in the fraction of knowledge utilized into the the fitting procedure.
</p>


<h3>Usage</h3>

<pre><code class="language-R">belief(X, knowns, B = NULL, k = ifelse(!is.null(B), ncol(B), 
    ifelse(!is.null(P), ncol(P), length(unique(class)))), P = NULL, 
    class = map(B), init.params = init.model.params(X, knowns, 
        B = B, P = P, class = class, k = k), model.structure = getModelStructure(), 
    stop.likelihood.change = 10^-5, stop.max.nsteps = 100, trace = FALSE, 
    b.min = 0.025, 
    all.possible.permutations=FALSE, pca.dim.reduction = NA)
    
soft(X, knowns, P = NULL, k = ifelse(!is.null(P), ncol(P), 
    ifelse(!is.null(B), ncol(B), length(unique(class)))), B = NULL, 
    class = NULL, init.params = init.model.params(X, knowns, 
        class = class, B = P, k = k), 
    model.structure = getModelStructure(), stop.likelihood.change = 10^-5, 
    stop.max.nsteps = 100, trace = FALSE, b.min = 0.025, 
	all.possible.permutations=FALSE, pca.dim.reduction = NA, ...)    
    
semisupervised(X, knowns, class = NULL, k = ifelse(!is.null(class), 
    length(unique(class)), ifelse(!is.null(B), ncol(B), ncol(P))), 
    B = NULL, P = NULL, ..., init.params = NULL,
	all.possible.permutations=FALSE, pca.dim.reduction = NA)    
    
supervised(knowns, class = NULL, k = length(unique(class)), B = NULL, P = NULL, 
    model.structure = getModelStructure(), ...)

unsupervised(X, k, init.params=init.model.params(X, knowns=NULL, k=k), 
      model.structure=getModelStructure(), stop.likelihood.change=10^-5, 
      stop.max.nsteps=100, trace=FALSE, ...) 
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>a data.frame with the unlabeled observations. The rows correspond to the observations while the columns to variables/dimensions of the data. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knowns</code></td>
<td>
<p>a data.frame with the labeled observations. The rows correspond to the observations while the columns to variables/dimensions of the data. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>a beliefs matrix which specifies the distribution of beliefs for the labeled observations. The number of rows in B should equal the number of rows in the  data.frame <code>knowns</code>. It is assumed that both the observations in <code>B</code> and in <code>knowns</code> are given in the same order. Columns correspond to the model components. If matrix B is provided, the number of columns has to be less or equal <code>k</code>. Internally, the matrix <code>B</code> is completed to <code>k</code> columns.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>P</code></td>
<td>
<p>a  matrix of plausibilities, i.e., weights of the prior probabilities for the labeled observations. If matrix <code>P</code> is provided, the number of columns has to be less or equal <code>k</code>. The came conditions as for <code>B</code> apply. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>class</code></td>
<td>
<p>a vector of classes/labels for the labeled observations. The number of its unique values has to be less or equal <code>k</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>a number of components, by default equal to the number of columns of <code>B</code>. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init.params</code></td>
<td>
<p>initial values for the estimates of the model parameters (means, variances and mixing proportions), by default derived with the
use of the <code>init.model.params</code> function. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stop.likelihood.change, stop.max.nsteps</code></td>
<td>
<p> the parameters for the EM algorithms defining the stop criteria, i.e., the minimum required improvement of loglikelihood and the maximum number of steps. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>trace</code></td>
<td>
<p>if <code>trace=TRUE</code> the loglikelihoods for every step of EM algorithm are printed out.   </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model.structure</code></td>
<td>
<p>an object returned by the <code>getModelStructure</code> function, which specifies constraints for the parameters of the model to be fitted. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>b.min</code></td>
<td>
<p>this argument is passed to the <code>init.model.params</code> function.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>these arguments will be passed tothe <code>init.model.params</code> function.   </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>all.possible.permutations</code></td>
<td>
<p>If equal <code>TRUE</code>, all possible initial parameters' permutations of components are considered. Since there is kList! permutations,  model fitting is repeated kList! times. As a result, only the model with the highest likelihood is returned.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pca.dim.reduction</code></td>
<td>
<p>Since the fitting for high dimensional space is numerically a bad idea an attempt to PCA will be performed if <code>pca.dim.reduction !- FALSE</code>. If equal <code>NA</code> then the target dimension is data driven, if it's a number then this will be the target dimension.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In the <code>belief()</code> function, if the argument <code>B</code> is not provided, it is
by default initialized from the argument <code>P</code>. If the argument <code>P</code> is not
provided, <code>B</code> is derived from the <code>class</code> argument with the use of the function <code>get.simple.beliefs()</code> 
which assigns <code>1-(k-1)*b.min</code> to the component given by <code>class</code>  and 
<code>b.min</code> to all remaining components.
</p>
<p>In the <code>soft()</code> function, if the argument <code>P</code> is not provided, it is
by default initialized from the argument <code>B</code>. If the argument <code>B</code> is not
provided, <code>P</code> is derived from the <code>class</code> argument as in the <code>belief()</code>
function.
</p>
<p>In the <code>supervised()</code> function,  if the argument <code>class</code> is not provided,
it is by default initialized from argument <code>B</code> or <code>P</code>, taking the label of each
observation as its most believed or plausible component (by the MAP rule).
</p>
<p>The number of columns in the beliefs matrix <code>B</code> or in the matrix of
plausibilities <code>P</code> may be smaller than the number of model components
defined by the argument <code>k</code>.  Such situation corresponds to the scenario
when the user does not know any examples for some   component. In other words, this component is not used as a label for
any observation, and thus can be omitted from the beliefs matrix. An
equivalent would be to include a column for this component and fill it
with beliefs/plausibilities equal 0.
</p>
<p>Slots in the returned object are listed in section Value.
The returned object differs slighty with respect to the used function. Namely, the <code>belief()</code> function returns an object with the slot <code>B</code>. The function <code>soft()</code> returns an object with a slot <code>P</code>, while the functions <code>supervised()</code> and <code>semisupervised()</code> return objects with a slot <code>class</code> instead. 
</p>
<p>The object returned by the function <code>supervised()</code> does not have the slot <code>X</code>.
</p>


<h3>Value</h3>

<p>An object of the class <code>mModel</code>, with the following slots:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>pi</code></td>
<td>
<p> a vector with the fitted mixing proportions</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mu</code></td>
<td>
<p> a matrix with the means' vectors, fitted for all components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cvar</code></td>
<td>
<p> a three-dimensional matrix with the covariance matrices, fitted for all components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p> the unlabeled observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knowns</code></td>
<td>
<p>the labeled observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>B</code></td>
<td>
<p>the beliefs matrix</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p> the number of all observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>m</code></td>
<td>
<p> the number of the unlabeled observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k</code></td>
<td>
<p>the number of fitted model components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>d</code></td>
<td>
<p>the data dimension</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>likelihood</code></td>
<td>
<p>the log-likelihood of the fitted model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.steps</code></td>
<td>
<p>the number of steps performed by the EM algorithm</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model.structure</code></td>
<td>
<p>the set of constraints kept during the fitting process.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Przemyslaw Biecek
</p>


<h3>References</h3>

<p>Przemyslaw Biecek, Ewa Szczurek, Martin Vingron, Jerzy Tiuryn (2012), The R Package bgmm: Mixture Modeling with Uncertain Knowledge, Journal of Statistical Software.
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(genotypes)

modelSupervised = supervised(knowns=genotypes$knowns, 
            class=genotypes$labels)
plot(modelSupervised)

modelSemiSupervised = semisupervised(X=genotypes$X, 
            knowns=genotypes$knowns, class = genotypes$labels)
plot(modelSemiSupervised)

modelBelief = belief(X=genotypes$X, 
            knowns=genotypes$knowns, B=genotypes$B)
plot(modelBelief)

modelSoft = soft(X=genotypes$X, 
            knowns=genotypes$knowns, P=genotypes$B)
plot(modelSoft)

modelUnSupervised = unsupervised(X=genotypes$X, k=3)
plot(modelUnSupervised)
</code></pre>


</div>