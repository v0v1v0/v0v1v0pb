<div class="container">

<table style="width: 100%;"><tr>
<td>.BT_cv_errors</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Cross-validation errors.</h2>

<h3>Description</h3>

<p>Function to compute the cross-validation error.
</p>


<h3>Usage</h3>

<pre><code class="language-R">.BT_cv_errors(BT_cv_fit, cv.folds, folds)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>BT_cv_fit</code></td>
<td>
<p>a <code>BTCVFit</code> object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.folds</code></td>
<td>
<p>a numeric corresponding to the number of folds.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>a numerical vector containing the different <code>folds.id</code>. Note that if the latter was not defined by the user, those are randomly generated based on the <code>cv.folds</code> input.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function computes the global cross-validation error as a function of the boosting iteration. Differently said, this measure is obtained by
computing the average of out-of-fold errors.
</p>


<h3>Value</h3>

<p>Vector containing the cross-validation errors w.r.t. the boosting iteration.
</p>


<h3>Author(s)</h3>

<p>Gireg Willame <a href="mailto:gireg.willame@gmail.com">gireg.willame@gmail.com</a>
</p>
<p><em>This package is inspired by the <code>gbm3</code> package. For more details, see <a href="https://github.com/gbm-developers/gbm3/">https://github.com/gbm-developers/gbm3/</a></em>.
</p>


<h3>References</h3>

<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries |: GLMs and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries ||: Tree-Based Methods and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries |||: Neural Networks and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2022). <strong>Response versus gradient boosting trees, GLMs and neural networks under Tweedie loss and log-link</strong>.
Accepted for publication in <em>Scandinavian Actuarial Journal</em>.
</p>
<p>M. Denuit, J. Huyghe and J. Trufin (2022). <strong>Boosting cost-complexity pruned trees on Tweedie responses: The ABT machine for insurance ratemaking</strong>.
Paper submitted for publication.
</p>
<p>M. Denuit, J. Trufin and T. Verdebout (2022). <strong>Boosting on the responses with Tweedie loss functions</strong>. Paper submitted for publication.
</p>


<h3>See Also</h3>

<p><code>BT</code>.
</p>


</div>