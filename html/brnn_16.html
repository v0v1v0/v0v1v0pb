<div class="container">

<table style="width: 100%;"><tr>
<td>initnw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Initialize networks weights and biases</h2>

<h3>Description</h3>

<p>Function to initialize the weights and biases in a neural network. It uses the Nguyen-Widrow (1990) algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">     initnw(neurons,p,n,npar)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>neurons</code></td>
<td>
<p>Number of neurons.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Number of predictors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n</code></td>
<td>
<p>Number of cases.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>npar</code></td>
<td>
<p>Number of parameters to be estimate including only weights and biases, and should be equal to <code class="reqn">neurons \times (1+1+p)+1</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The algorithm is described in Nguyen-Widrow (1990) and in other books, see for example Sivanandam and Sumathi (2005). The algorithm is briefly described below.
</p>

<ul>
<li>
<p>1.-Compute the scaling factor <code class="reqn">\theta=0.7 p^{1/n}</code>.
</p>
</li>
<li>
<p>2.- Initialize the weight and biases for each neuron at random, for example generating random numbers from <code class="reqn">U(-0.5,0.5)</code>.
</p>
</li>
<li>
<p>3.- For each neuron:
</p>

<ul>
<li>
<p>compute <code class="reqn">\eta_k=\sqrt{\sum_{j=1}^p (\beta_j^{(k)})^2}</code>,
</p>
</li>
<li>
<p>update <code class="reqn">(\beta_1^{(k)},...,\beta_p^{(k)})'</code>,
</p>
<p style="text-align: center;"><code class="reqn">\beta_j^{(k)}=\frac{\theta \beta_j^{(k)}}{\eta_k}, j=1,...,p,</code>
</p>

</li>
<li>
<p>Update the bias <code class="reqn">(b_k)</code> generating a random number from <code class="reqn">U(-\theta,\theta)</code>.
</p>
</li>
</ul>
</li>
</ul>
<h3>Value</h3>

<p>A list containing initial values for weights and biases. The first <code class="reqn">s</code> components of the list contains vectors with the initial values for 
the weights and biases of the <code class="reqn">k</code>-th neuron, i.e. <code class="reqn">(\omega_k, b_k, \beta_1^{(k)},...,\beta_p^{(k)})'</code>.
</p>


<h3>References</h3>

<p>Nguyen, D. and Widrow, B. 1990. "Improving the learning speed of 2-layer neural networks by choosing initial values of the adaptive weights",
<em>Proceedings of the IJCNN</em>, <b>3</b>, 21-26.
</p>
<p>Sivanandam, S.N. and Sumathi, S. 2005. Introduction to Neural Networks Using MATLAB 6.0. Ed. McGraw Hill, First edition. 
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
#Load the library
library(brnn)

#Set parameters
neurons=3
p=4
n=10
npar=neurons*(1+1+p)+1
initnw(neurons=neurons,p=p,n=n,npar=npar)


## End(Not run)
</code></pre>


</div>