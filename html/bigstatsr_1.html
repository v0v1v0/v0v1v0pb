<div class="container">

<table style="width: 100%;"><tr>
<td>bigstatsr-package</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>bigstatsr: Statistical Tools for Filebacked Big Matrices</h2>

<h3>Description</h3>

<p>Easy-to-use, efficient, flexible and scalable statistical tools. Package bigstatsr provides and uses Filebacked Big Matrices via memory-mapping. It provides for instance matrix operations, Principal Component Analysis, sparse linear supervised models, utility functions and more <a href="https://doi.org/10.1093/bioinformatics/bty185">doi:10.1093/bioinformatics/bty185</a>.
</p>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>An object of class FBM.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X.code</code></td>
<td>
<p>An object of class FBM.code256.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y01.train</code></td>
<td>
<p>Vector of responses, corresponding to <code>ind.train</code>.
<strong>Must be only 0s and 1s.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.train</code></td>
<td>
<p>An optional vector of the row indices that are used,
for the training part. If not specified, all rows are used.
<strong>Don't use negative indices.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.row</code></td>
<td>
<p>An optional vector of the row indices that are used.
If not specified, all rows are used. <strong>Don't use negative indices.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.col</code></td>
<td>
<p>An optional vector of the column indices that are used.
If not specified, all columns are used. <strong>Don't use negative indices.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses block_size.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ncores</code></td>
<td>
<p>Number of cores used. Default doesn't use parallelism.
You may use nb_cores.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code>, <code>ind.row</code> and <code>ind.col</code>,
and that returns a data.frame with <code style="white-space: pre;">⁠$center⁠</code> and <code style="white-space: pre;">⁠$scale⁠</code> for the columns
corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default doesn't use any scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code>as_scaling_fun()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covar.train</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.train</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code>covar_from_df()</code> to convert from a data frame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>covar.row</code></td>
<td>
<p>Matrix of covariables to be added in each model to correct
for confounders (e.g. the scores of PCA), corresponding to <code>ind.row</code>.
Default is <code>NULL</code> and corresponds to only adding an intercept to each model.
You can use <code>covar_from_df()</code> to convert from a data frame.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>center</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to subtract from columns of <code>X</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale</code></td>
<td>
<p>Vector of same length of <code>ind.col</code> to divide from columns of <code>X</code>.</p>
</td>
</tr>
</table>
<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks. Instead, you can use
the <a href="https://forum.posit.co/t/intel-mkl-integration-to-r-on-windows/176071">MKL</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can control the number of cores used by these optimized matrix libraries
with <code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Author(s)</h3>

<p><strong>Maintainer</strong>: Florian Privé <a href="mailto:florian.prive.21@gmail.com">florian.prive.21@gmail.com</a>
</p>
<p>Other contributors:
</p>

<ul>
<li>
<p> Michael Blum [thesis advisor]
</p>
</li>
<li>
<p> Hugues Aschard <a href="mailto:hugues.aschard@pasteur.fr">hugues.aschard@pasteur.fr</a> [thesis advisor]
</p>
</li>
</ul>
<h3>See Also</h3>

<p>Useful links:
</p>

<ul>
<li> <p><a href="https://privefl.github.io/bigstatsr/">https://privefl.github.io/bigstatsr/</a>
</p>
</li>
<li>
<p> Report bugs at <a href="https://github.com/privefl/bigstatsr/issues">https://github.com/privefl/bigstatsr/issues</a>
</p>
</li>
</ul>
</div>