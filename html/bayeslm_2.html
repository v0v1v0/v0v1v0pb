<div class="container">

<table style="width: 100%;"><tr>
<td>bayeslm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Efficient sampling for Gaussian linear model with arbitrary priors
</h2>

<h3>Description</h3>

<p>This package implements an efficient sampler for Gaussian Bayesian linear regression. The package uses elliptical slice sampler instead of regular Gibbs sampler. The function has several built-in priors and user can also provide their own prior function (written as a R function).
</p>


<h3>Usage</h3>

<pre><code class="language-R">## Default S3 method:
bayeslm(Y, X = FALSE, prior = "horseshoe", penalize = NULL, 
block_vec = NULL, sigma = NULL, s2 = 1, kap2 = 1, N = 20000L, burnin = 0L, 
thinning = 1L, vglobal = 1, sampling_vglobal = TRUE, verb = FALSE, icept = TRUE, 
standardize = TRUE, singular = FALSE, scale_sigma_prior = TRUE, prior_mean = NULL, 
prob_vec = NULL, cc = NULL, lambda = NULL, ...)

## S3 method for class 'formula'
bayeslm(formula, data = list(), Y = FALSE, X = FALSE, 
prior = "horseshoe", penalize = NULL, block_vec = NULL, sigma = NULL, 
s2 = 1, kap2 = 1, N = 20000L, burnin = 0L, thinning = 1L, vglobal = 1, 
sampling_vglobal = TRUE, verb = FALSE, standardize = TRUE, singular = FALSE, 
scale_sigma_prior = TRUE, prior_mean = NULL, 
prob_vec = NULL, cc = NULL, lambda = NULL, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p><code>formula</code> of the model to fit.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>an optional data frame containing the variables in the model.
By default the variables are taken from the environment which
<code>bayeslm</code> is called from.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Y</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or <code>vector</code> of inputs <code>Y</code>. Response variable. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p><code>data.frame</code>, <code>matrix</code>, or <code>vector</code> of inputs <code>X</code>. Regressors. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior</code></td>
<td>
<p>Indicating shrinkage prior to use. <code>"horseshoe"</code> for approximate horseshoe prior (default), <code>"laplace"</code> for laplace prior, <code>"ridge"</code> for ridge prior, <code>"sharkfin"</code> for "sharkfin" prior and <code>"nonlocal"</code> for nonlocal prior.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>block_vec</code></td>
<td>
<p>A vector indicating number of regressors in each block. Sum of all entries should be the same as number of regressors. The default value is <code>block_vec = rep(1, p)</code>, put every regressor in its own block (slice-within-Gibbs sampler)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>penalize</code></td>
<td>
<p>A vector indicating shrink regressors or not. It's length should be the same as number of regressors. <code>1</code> indicates shrink corresponding coefficient, <code>0</code> indicates no shrinkage. The default value is <code>rep(1, p)</code>, shrink all coefficients</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>Initial value of residual standard error. The default value is half of standard error of <code>Y</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>s2, kap2</code></td>
<td>
<p>Parameter of prior over sigma, an inverse gamma prior with rate s2 and shape s2.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>Number of posterior samples (after burn-in).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>burnin</code></td>
<td>
<p>Number of burn-in samples. If burnin &gt; 0, the function will draw N + burnin samples and return the last N samples only.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thinning</code></td>
<td>
<p>Number of thinnings. <code>thinning = 1</code> means no thinning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vglobal</code></td>
<td>
<p>Initial value of global shrinkage parameter. Default value is 1</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sampling_vglobal</code></td>
<td>
<p><code>Bool</code>, if <code>TRUE</code>, sampling the global shrinkage parameter by random walk Metropolis Hastings on log scale, otherwise always stay at the initial value <code>vglobal</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verb</code></td>
<td>
<p>Bool, if <code>TRUE</code>, print out sampling progress.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>icept</code></td>
<td>
<p>Bool, if the inputs are matrix <code>X</code> and <code>Y</code>, and <code>icept = TRUE</code>, the function will estimate intercept. Default value is <code>TRUE</code>. If the input is formula <code>Y ~ X</code>, option <code>icept</code> is useless, control intercept by formular <code>Y ~ X</code> or <code>Y ~ X - 1</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>standardize</code></td>
<td>
<p>Bool, if <code>TRUE</code>, standardize X and Y before sampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>singular</code></td>
<td>
<p>Bool, if <code>TRUE</code>, take it as a rank-deficient case such as n &lt; p or X'X is singular. See section 2.3.2 of the paper for details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>scale_sigma_prior</code></td>
<td>
<p>Bool, if <code>TRUE</code>, the prior of regression coefficient <code class="reqn">\beta</code> is scaled by residual standard error <code class="reqn">\sigma</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior_mean</code></td>
<td>
<p><code>vector</code>, specify prior mean of nonlocal prior for each regressor. It should have length <code>p</code> (no intercept) or <code>p + 1</code> (intercept). The default value is 1.5 for all regressors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prob_vec</code></td>
<td>
<p><code>vector</code>, specify prior mean of sharkfin prior for each regressor. It should have length <code>p</code> (no intercept) or <code>p + 1</code> (intercept). The default value is 0.25 for all regressors.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cc</code></td>
<td>
<p>Only works when <code>singular == TRUE</code>, precision parameter of ridge adjustment. It should be a vector with length $p$. If it is <code>NULL</code>, it will be set as <code>rep(10, p)</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lambda</code></td>
<td>
<p>The shrinkage parameter for Laplace prior only.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>optional parameters to be passed to the low level function <code>bayeslm.default</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>For details of the approach, please see Hahn, He and Lopes (2017)
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>loops</code></td>
<td>
<p>A <code>vector</code> of number of elliptical slice sampler loops for each posterior sample.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sigma</code></td>
<td>
<p>A <code>vector</code> of posterior samples of residual standard error.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vglobal</code></td>
<td>
<p>A <code>vector</code> of posterior samples of the global shrinkage parameter.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>A <code>matrix</code> of posterior samples of coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>Fitted values of the regression model. Take posterior mean of coefficients with 20% burnin samples.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>residuals</code></td>
<td>
<p>Residuals of the regression model, equals <code>y - fitted.values</code>.</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p><code>horseshoe</code> is essentially call function <code>bayeslm</code> with <code>prior = "horseshoe"</code>. Same for <code>sharkfin</code>, <code>ridge</code>, <code>blasso</code>, <code>nonlocal</code>.
</p>


<h3>Author(s)</h3>

<p> Jingyu He <a href="mailto:jingyu.he@chicagobooth.edu">jingyu.he@chicagobooth.edu</a> </p>


<h3>References</h3>

<p>Hahn, P. Richard, Jingyu He, and Hedibert Lopes. <em>Efficient sampling for Gaussian linear regression with arbitrary priors.</em> (2017).
</p>


<h3>Examples</h3>

<pre><code class="language-R">
p = 20
n = 100

kappa = 1.25
beta_true = c(c(1,2,3),rnorm(p-3,0,0.01))
sig_true = kappa*sqrt(sum(beta_true^2))


x = matrix(rnorm(p*n),n,p)
y = x %*% beta_true + sig_true * rnorm(n)


x = as.matrix(x)
y = as.matrix(y)
data = data.frame(x = x, y = y)

block_vec = rep(1, p) # slice-within-Gibbs sampler, put every coefficient in its own block

fitOLS = lm(y~x-1)

# call the function using formulas
fita = bayeslm(y ~ x, prior = 'horseshoe', 
        block_vec = block_vec, N = 10000, burnin = 2000)
# summary the results
summary(fita)
summary(fita$beta)


# put the first two coefficients in one elliptical sampling block
block_vec2 = c(2, rep(1, p-2))
fitb = bayeslm(y ~ x, data = data, prior = 'horseshoe', 
        block_vec = block_vec2, N = 10000, burnin = 2000)

# comparing several different priors

fit1 = bayeslm(y,x,prior = 'horseshoe', icept = FALSE, 
          block_vec = block_vec, N = 10000, burnin=2000)
beta_est1 = colMeans(fit1$beta)

fit2 = bayeslm(y,x,prior = 'laplace', icept = FALSE, 
          block_vec = block_vec, N = 10000, burnin=2000)
beta_est2 = colMeans(fit2$beta)

fit3 = bayeslm(y,x,prior = 'ridge', icept = FALSE, 
          block_vec = block_vec, N = 10000, burnin=2000)
beta_est3 = colMeans(fit3$beta)

fit4 = bayeslm(y,x,prior = 'sharkfin', icept = FALSE, 
          block_vec = block_vec, N = 10000, burnin=2000)
beta_est4 = colMeans(fit4$beta)

fit5 = bayeslm(y,x,prior = 'nonlocal', icept = FALSE, 
          block_vec = block_vec, N = 10000, burnin=2000)
beta_est5 = colMeans(fit5$beta)

plot(NULL,xlim=range(beta_true),ylim=range(beta_true), 
  xlab = "beta true", ylab = "estimation")
points(beta_true,beta_est1,pch=20)
points(beta_true,fitOLS$coef,col='red')
points(beta_true,beta_est2,pch=20,col='cyan')
points(beta_true,beta_est3,pch=20,col='orange')
points(beta_true,beta_est4,pch=20,col='pink')
points(beta_true,beta_est5,pch=20,col='lightgreen')

legend("topleft", c("OLS", "horseshoe", "laplace", "ridge", "sharkfin", 
  "nonlocal"), col = c("red", "black", "cyan", "orange", 
    "pink", "lightgreen"), pch = rep(1, 6))

abline(0,1,col='red')

rmseOLS = sqrt(sum((fitOLS$coef-beta_true)^2))
rmse1 = sqrt(sum((beta_est1-beta_true)^2))
rmse2 = sqrt(sum((beta_est2-beta_true)^2))
rmse3 = sqrt(sum((beta_est3-beta_true)^2))
rmse4 = sqrt(sum((beta_est4-beta_true)^2))
rmse5 = sqrt(sum((beta_est5-beta_true)^2))

print(cbind(ols = rmseOLS, hs = rmse1,laplace = rmse2,
ridge = rmse3,sharkfin = rmse4,nonlocal = rmse5))



</code></pre>


</div>