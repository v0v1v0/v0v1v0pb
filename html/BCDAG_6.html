<div class="container">

<table style="width: 100%;"><tr>
<td>get_edgeprobs</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Compute posterior probabilities of edge inclusion from the MCMC output</h2>

<h3>Description</h3>

<p>This function computes the posterior probability of inclusion for each edge <code class="reqn">u -&gt; v</code> given the MCMC output of <code>learn_DAG</code>;
</p>


<h3>Usage</h3>

<pre><code class="language-R">get_edgeprobs(learnDAG_output)
</code></pre>


<h3>Arguments</h3>

<table><tr style="vertical-align: top;">
<td><code>learnDAG_output</code></td>
<td>
<p>object of class <code>bcdag</code></p>
</td>
</tr></table>
<h3>Details</h3>

<p>Output of <code>learn_dag</code> function consists of <code class="reqn">S</code> draws from the joint posterior of DAGs and DAG-parameters in a zero-mean Gaussian DAG-model;
see the documentation of <code>learn_DAG</code> for more details.
</p>
<p>The posterior probability of inclusion of <code class="reqn">u -&gt; v</code> is estimated as the frequency of DAGs visited by the MCMC which contain the directed edge <code class="reqn">u -&gt; v</code>.
Posterior probabilities are collected in a <code class="reqn">(q,q)</code> matrix with <code class="reqn">(u,v)</code>-element representing the estimated posterior probability
of edge <code class="reqn">u -&gt; v</code>.
</p>


<h3>Value</h3>

<p>A <code class="reqn">(q,q)</code> matrix with posterior probabilities of edge inclusion
</p>


<h3>Author(s)</h3>

<p>Federico Castelletti and Alessandro Mascaro
</p>


<h3>References</h3>

<p>F. Castelletti and A. Mascaro (2021). Structural learning and estimation of joint causal effects among network-dependent variables. <em>Statistical Methods and Applications</em>, Advance publication.
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Randomly generate a DAG and the DAG-parameters
q = 8
w = 0.2
set.seed(123)
DAG = rDAG(q = q, w = w)
outDL = rDAGWishart(n = 1, DAG = DAG, a = q, U = diag(1, q))
L = outDL$L; D = outDL$D
Sigma = solve(t(L))%*%D%*%solve(L)
# Generate observations from a Gaussian DAG-model
n = 200
X = mvtnorm::rmvnorm(n = n, sigma = Sigma)
# Run the MCMC (Set S = 5000 and burn = 1000 for better results)
out_mcmc = learn_DAG(S = 500, burn = 100, a = q, U = diag(1,q)/n, data = X, w = 0.1,
                     fast = TRUE, save.memory = FALSE)
# Compute posterior probabilities of edge inclusion
get_edgeprobs(out_mcmc)

</code></pre>


</div>