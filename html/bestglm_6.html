<div class="container">

<table style="width: 100%;"><tr>
<td>CVHTF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> K-fold Cross-Validation </h2>

<h3>Description</h3>

<p>K-fold cross-validation. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">CVHTF(X, y, K = 10, REP = 1, family = gaussian, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p> training inputs </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> training output </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p> size of validation sample </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>REP</code></td>
<td>
<p> number of replications </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>glm family</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p> optional arguments passed to <code>glm</code> or <code>lm</code></p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>HTF (2009) describe K-fold cross-validation. 
The observations are partitioned into K non-overlapping subsets of approximately
equal size. Each subset is used as the validation sample while the remaining
K-1 subsets are used as training data. When <code class="reqn">K=n</code>, 
where n is the number of observations
the algorithm is equivalent to leave-one-out CV.
Normally <code class="reqn">K=10</code> or <code class="reqn">K=5</code> are used.
When <code class="reqn">K&lt;n-1</code>, their are may be many possible partitions and so the results 
of K-fold CV may vary somewhat depending on the partitions used.
In our implementation, random partitions are used and we allow for many
replications. Note that in the Shao's delete-d method, random samples are
used to select the valiation data whereas in this method the whole partition
is selected as random. This is acomplished using,
<code>fold &lt;- sample(rep(1:K,length=n))</code>. 
Then <code>fold</code> indicates each validation sample in the partition.
</p>


<h3>Value</h3>

<p>Vector of two components comprising the cross-validation MSE and its sd based 
on the MSE in each validation sample.
</p>


<h3>Author(s)</h3>

<p>A.I. McLeod and C. Xu</p>


<h3>References</h3>

<p>Hastie, T., Tibshirani, R. and Friedman, J. (2009). 
The Elements of Statistical Learning. 2nd Ed. Springer-Verlag.
</p>


<h3>See Also</h3>

 
<p><code>bestglm</code>, 
<code>CVd</code>, 
<code>CVDH</code>, 
<code>LOOCV</code> 
</p>


<h3>Examples</h3>

<pre><code class="language-R">#Example 1. 10-fold CV
data(zprostate)
train&lt;-(zprostate[zprostate[,10],])[,-10]
X&lt;-train[,1:2]
y&lt;-train[,9]
CVHTF(X,y,K=10,REP=1)[1]
</code></pre>


</div>