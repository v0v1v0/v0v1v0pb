<div class="container">

<table style="width: 100%;"><tr>
<td>TTEST</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>One-sample, independent-samples, and paired-samples t-test.</h2>

<h3>Description</h3>

<p>One-sample, independent-samples, and paired-samples <em>t</em>-test,
with both Frequentist and Bayesian approaches.
The output includes descriptives, <em>t</em> statistics,
mean difference with 95% CI, Cohen's <em>d</em> with 95% CI,
and Bayes factor (BF10; <code>BayesFactor</code> package needs to be installed).
It also tests the assumption of homogeneity of variance
and allows users to determine whether variances are equal or not.
</p>
<p>Users can simultaneously test multiple dependent and/or independent variables.
The results of one pair of Y-X would be summarized in one row in the output.
Key results can be saved in APA format to MS Word.
</p>


<h3>Usage</h3>

<pre><code class="language-R">TTEST(
  data,
  y,
  x = NULL,
  paired = FALSE,
  paired.d.type = "dz",
  var.equal = TRUE,
  mean.diff = TRUE,
  test.value = 0,
  test.sided = c("=", "&lt;", "&gt;"),
  factor.rev = TRUE,
  bayes.prior = "medium",
  digits = 2,
  file = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>Data frame (wide-format only, i.e., one case in one row).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Dependent variable(s).
Multiple variables should be included in a character vector <code>c()</code>.
</p>
<p>For paired-samples <em>t</em>-test, the number of variables should be 2, 4, 6, etc.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>Independent variable(s).
Multiple variables should be included in a character vector <code>c()</code>.
</p>
<p>Only necessary for independent-samples <em>t</em>-test.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paired</code></td>
<td>
<p>For paired-samples <em>t</em>-test, set it as <code>TRUE</code>. Defaults to <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>paired.d.type</code></td>
<td>
<p>Type of Cohen's <em>d</em> for paired-samples <em>t</em>-test (see Lakens, 2013).
</p>
<p>Defaults to <code>"dz"</code>. Options include:
</p>

<dl>
<dt>
<code>"dz"</code> (<em>d</em> for standardized difference)</dt>
<dd>
<p>Cohen's <code class="reqn">d_{z} = \frac{M_{diff}}{SD_{diff}}</code>
</p>
</dd>
<dt>
<code>"dav"</code> (<em>d</em> for average standard deviation)</dt>
<dd>
<p>Cohen's <code class="reqn">d_{av} = \frac{M_{diff}}{ \frac{SD_{1} + SD_{2}}{2} }</code>
</p>
</dd>
<dt>
<code>"drm"</code> (<em>d</em> for repeated measures, corrected for correlation)</dt>
<dd>
<p>Cohen's <code class="reqn">d_{rm} = \frac{M_{diff} \times \sqrt{2(1 - r_{1,2})}}{
      \sqrt{SD_{1}^2 + SD_{2}^2 - 2 \times r_{1,2} \times SD_{1} \times SD_{2}} }</code>
</p>
</dd>
</dl>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.equal</code></td>
<td>
<p>If Levene's test indicates a violation of the homogeneity of variance,
then you should better set this argument as <code>FALSE</code>. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mean.diff</code></td>
<td>
<p>Whether to display results of mean difference and its 95% CI. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test.value</code></td>
<td>
<p>The true value of the mean (or difference in means for a two-samples test). Defaults to <code>0</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>test.sided</code></td>
<td>
<p>Any of <code>"="</code> (two-sided, the default), <code>"&lt;"</code> (one-sided), or <code>"&gt;"</code> (one-sided).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>factor.rev</code></td>
<td>
<p>Whether to reverse the levels of factor (X)
such that the test compares higher vs. lower level. Defaults to <code>TRUE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bayes.prior</code></td>
<td>
<p>Prior scale in Bayesian <em>t</em>-test. Defaults to 0.707.
See details in <code>BayesFactor::ttestBF()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>Number of decimal places of output. Defaults to <code>2</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>file</code></td>
<td>
<p>File name of MS Word (<code>.doc</code>).</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Note that the point estimate of Cohen's <em>d</em> is computed using
the common method "Cohen's <em>d</em> = mean difference / (pooled) standard deviation", which is
consistent with results from other R packages (e.g., <code>effectsize</code>) and software (e.g., <code>jamovi</code>).
The 95% CI of Cohen's <em>d</em> is estimated based on the 95% CI of mean difference
(i.e., also divided by the pooled standard deviation).
</p>
<p>However, different packages and software diverge greatly on the estimate of the 95% CI of Cohen's <em>d</em>.
R packages such as <code>psych</code> and <code>effectsize</code>, R software <code>jamovi</code>,
and several online statistical tools for estimating effect sizes
indeed produce surprisingly inconsistent results on the 95% CI of Cohen's <em>d</em>.
</p>
<p>See an illustration of this issue in the section "Examples".
</p>


<h3>References</h3>

<p>Lakens, D. (2013). Calculating and reporting effect sizes to facilitate cumulative science:
A practical primer for <em>t</em>-tests and ANOVAs. <em>Frontiers in Psychology, 4</em>, Article 863.
</p>


<h3>See Also</h3>

<p><code>MANOVA</code>, <code>EMMEANS</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Demo data ##
d1 = between.3
d1$Y1 = d1$SCORE  # shorter name for convenience
d1$Y2 = rnorm(32)  # random variable
d1$B = factor(d1$B, levels=1:2, labels=c("Low", "High"))
d1$C = factor(d1$C, levels=1:2, labels=c("M", "F"))
d2 = within.1

## One-sample t-test ##
TTEST(d1, "SCORE")
TTEST(d1, "SCORE", test.value=5)

## Independent-samples t-test ##
TTEST(d1, "SCORE", x="A")
TTEST(d1, "SCORE", x="A", var.equal=FALSE)
TTEST(d1, y="Y1", x=c("A", "B", "C"))
TTEST(d1, y=c("Y1", "Y2"), x=c("A", "B", "C"),
      mean.diff=FALSE,  # remove to save space
      file="t-result.doc")
unlink("t-result.doc")  # delete file for code check

## Paired-samples t-test ##
TTEST(d2, y=c("A1", "A2"), paired=TRUE)
TTEST(d2, y=c("A1", "A2", "A3", "A4"), paired=TRUE)


## Not run: 

  ## Illustration for the issue stated in "Details"

  # Inconsistency in the 95% CI of Cohen's d between R packages:
  # In this example, the true point estimate of Cohen's d = 3.00
  # and its 95% CI should be equal to 95% CI of mean difference.

  data = data.frame(X=rep(1:2, each=3), Y=1:6)
  data  # simple demo data

  TTEST(data, y="Y", x="X")
  # d = 3.00 [0.73, 5.27] (estimated based on 95% CI of mean difference)

  MANOVA(data, dv="Y", between="X") %&gt;%
    EMMEANS("X")
  # d = 3.00 [0.73, 5.27] (the same as TTEST)

  psych::cohen.d(x=data, group="X")
  # d = 3.67 [0.04, 7.35] (strange)

  psych::d.ci(d=3.00, n1=3, n2=3)
  # d = 3.00 [-0.15, 6.12] (significance inconsistent with t-test)

  # jamovi uses psych::d.ci() to compute 95% CI
  # so its results are also: 3.00 [-0.15, 6.12]

  effectsize::cohens_d(Y ~ rev(X), data=data)
  # d = 3.00 [0.38, 5.50] (using the noncentrality parameter method)

  effectsize::t_to_d(t=t.test(Y ~ rev(X), data=data, var.equal=TRUE)$statistic,
                     df_error=4)
  # d = 3.67 [0.47, 6.74] (merely an approximate estimate, often overestimated)
  # see ?effectsize::t_to_d

  # https://www.psychometrica.de/effect_size.html
  # d = 3.00 [0.67, 5.33] (slightly different from TTEST)

  # https://www.campbellcollaboration.org/escalc/
  # d = 3.00 [0.67, 5.33] (slightly different from TTEST)

  # Conclusion:
  # TTEST() provides a reasonable estimate of Cohen's d and its 95% CI,
  # and effectsize::cohens_d() offers another method to compute the CI.

## End(Not run)

</code></pre>


</div>