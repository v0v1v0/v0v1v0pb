<div class="container">

<table style="width: 100%;"><tr>
<td>zero_one_loss</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Calculating the 0-1 loss incurred in prediction</h2>

<h3>Description</h3>

<p>Compute the 0-1 loss, i.e., the proportion of incorrectly predicted values,
incurred in BCT prediction with memory length D. Given an initial context
(x<sub>-D+1</sub>, ..., x<sub>0</sub>)  and training data (x<sub>1</sub>, ..., x<sub>n</sub>), the 0-1 loss is computed in sequentially predicting
the test data (x<sub>n+1</sub>, ..., x<sub>n+T</sub>). The function outputs the cummulative, normalized (per-sample) 0-1 loss, at each prediction step; for more information see <a href="https://arxiv.org/pdf/2007.14900.pdf">Kontoyiannis et al. (2020)</a>.
</p>


<h3>Usage</h3>

<pre><code class="language-R">zero_one_loss(input_data, depth, train_size, beta = NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>input_data</code></td>
<td>
<p>the sequence to be analysed. 
The sequence needs to be a "character" object. See the examples section of kBCT/BCT functions on how to transform any dataset to a "character" object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>depth</code></td>
<td>
<p>maximum memory length.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>train_size</code></td>
<td>
<p>number of samples used in the training set. The training set size should be at least equal to the depth.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta</code></td>
<td>
<p>hyper-parameter of the model prior. 
Takes values between 0 and 1. If not initialised in the call function, the default value is 1-2<sup>-m+1</sup>, 
where m is the size of the alphabet; for more information see <a href="https://arxiv.org/pdf/2007.14900.pdf">Kontoyiannis et al. (2020)</a></p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>returns a vector containing the averaged number of errors at each timestep.
</p>


<h3>See Also</h3>

<p><code>log_loss</code>, <code>prediction</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Use the pewee dataset and look at the last 8 elements:
  substring(pewee, nchar(pewee)-7, nchar(pewee)) 
# [1] "10001001"

# Predict last 8 elements using the prediction function
pred &lt;- prediction(pewee, 10, nchar(pewee)-8)[["Prediction"]] 
# Taking only the "Prediction" vector:

pred
# [1] "1" "0" "0" "1" "1" "0" "0" "1"

# To transform the result of the prediction function into a "character" object:
paste(pred, collapse = "")
# [1] "10011001"

# As observed, there is only 1 error (the sixth predicted element is 1 instead of a 0). 
# Thus, up to the 4th place, the averaged error is 0 
# and the sixth averaged error is expected to be 1/4. 
# Indeed, the zero_one_loss function yields the expected answer: 

zero_one_loss(pewee, 10, nchar(pewee)-8) 
# [1] 0.0000000 0.0000000 0.0000000 0.2500000 0.2000000 0.1666667 0.1428571 0.1250000

</code></pre>


</div>