<div class="container">

<table style="width: 100%;"><tr>
<td>pQF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Tail probabilities for quadratic forms
</h2>

<h3>Description</h3>

<p>Computes the upper tail probability for quadratic forms in standard Normal variables, using a leading-eigenvalue approximation that is feasible even for large matrices. Can take advantage of sparse matrices. 
</p>


<h3>Usage</h3>

<pre><code class="language-R">pQF(x, M, method = c("ssvd", "lanczos", "satterthwaite"), neig = 100,
  tr2.sample.size = 500, q = NULL,
  convolution.method = c("saddlepoint", "integration"),
  remainder.underflow=c("warn","missing","error"))
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>

<p>Vector of quantiles to compute tail probabilities
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>

<p>If <code>M</code> is square, it is the matrix in the quadratic form and is assumed to be symmetric. If it is not square, <code>crossprod(M)</code> is the matrix in the quadratic form, although this matrix is never formed explicitly. It can also be an object of class <code>"matrixfree"</code> to allow matrix-free multiplication for, eg, sparse matrices; see <code>SKAT.matrixfree</code> for an example.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p> Use stochastic SVD ("ssvd") or a thick-restarted Lanczos algorithm ("lanczos") to extract the leading eigenvalues, or use the naive Satterthwaite approximation ("satterthwaite")</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>neig</code></td>
<td>

<p>Number of leading eigenvalues to use
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tr2.sample.size</code></td>
<td>

<p>When <code>M</code> is not square, a randomised estimator for the trace of <code>crossprod(M)^2</code> is used. This is the sample size. When <code>M</code> is of <code>"matrixfree"</code> and does not include the trace of crossprod(M) as a component, this sample size will also be used to compute that. See Hutchinson reference. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>q</code></td>
<td>

<p>Power iteration parameter for the stochastic SVD (see the Halko et al reference)
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>convolution.method</code></td>
<td>

<p>For either the "ssvd" or "lanczos" methods, how the convolution of the leading-eigenvalue terms is performed: by Kuonen's saddlepoint approximation or Davies' algorithm inverting the characteristic function
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>remainder.underflow</code></td>
<td>

<p>How should underflow of the remainder term (see Details) be handled? The default is a warning, with <code>"error"</code> an error is thrown, and with <code>"miss"</code> the return value will be <code>NaN</code>.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Increasing <code>neig</code> or <code>q</code> will improve the accuracy of approximation. In simulated human sequence data, <code>neig=100</code> is satisfactory for 5000 samples and markers. Increasing <code>q</code> should help when the singular values of <code>M</code> decrease slowly.  The default sample size for the randomized trace estimator seems to be large enough.
</p>
<p>If the remainder term in the approximation has less than 1 degree of freedom it will be dropped, and <code>remainder.underflow</code> controls how this is handled. The approximation will then be anticonservative, but usually not seriously so. 
</p>
<p>In earlier versions, <code>method="satterthwaite"</code> rounded the number of
degrees of freedom up to the next integer; it now does not round.
</p>
<p>In the current version when <code>M</code> is of class <code>"matrix-free"</code>
and <code>method="ssvd"</code>, an improved estimator of the remainder term is
used. Instead of using Hutchinson's randomised trace estimator and
subtracting the known eigenvalues, we apply the randomised trace
estimator after projecting orthogonal to the known eigenvectors. After
more evaluation, the improvement is likely to be extended to the other
methods for rectangular matrices.
</p>
<p>By default, Davies's algorithm is run with a tolerance of <code>1e-9</code>. This can be changed by setting, eg,  <code>options(bigQF.davies.threshold=1e-12)</code>
</p>


<h3>Value</h3>

<p>Vector of upper tail probabilities
</p>


<h3>Author(s)</h3>

<p>Thomas Lumley
</p>


<h3>References</h3>

<p>Lumley et al. (2018) "Sequence kernel association tests for large sets of markers: tail probabilities for large quadratic forms" Genet Epidemiol. 2018 Sep;42(6):516-527. doi: 10.1002/gepi.22136
</p>
<p>Tong Chen, Thomas Lumley (2019) Numerical evaluation of methods approximating the distribution of a large quadratic form in normal variables. Computational Statistics &amp; Data Analysis.  139: 75-81,
</p>
<p>Thomas Lumley (2017) "How to add chi-squareds" <a href="https://notstatschat.rbind.io/2017/12/06/how-to-add-chi-squareds/">https://notstatschat.rbind.io/2017/12/06/how-to-add-chi-squareds/</a>
</p>
<p>Thomas Lumley (2016) "Large quadratic forms" <a href="https://notstatschat.rbind.io/2016/09/27/large-quadratic-forms/">https://notstatschat.rbind.io/2016/09/27/large-quadratic-forms/</a>
</p>
<p>Nathan Halko, Per-Gunnar Martinsson, Joel A. Tropp (2010) "Finding structure with randomness: Probabilistic algorithms for constructing approximate matrix decompositions" <a href="https://arxiv.org/abs/0909.4061">https://arxiv.org/abs/0909.4061</a>.
</p>
<p>Hutchinson, M. F. (1990). A stochastic estimator of the trace of the influence matrix for Laplacian smoothing splines. Communications in Statistics - Simulation and Computation, 19(2):433-450.
</p>


<h3>See Also</h3>

<p><code>ssvd</code>,<code>SKAT.matrixfree</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(sequence)
dim(sequence)

skat&lt;-SKAT.matrixfree(sequence)
skat$trace
pQF(c(33782471,7e7,1e8),skat, n=100)


# Don't run these; they take a few minutes
G&lt;-sequence
wuweights&lt;-function(maf) dbeta(maf,1,25)
tmp&lt;-wuweights(colMeans(G)/2)*t(G)
tildeGt&lt;-t(tmp-rowMeans(tmp))/sqrt(2)
sum(tildeGt^2)

pQF(c(33782471,7e7,1e8), tildeGt, n=100)

H&lt;-crossprod(tildeGt)
pQF(c(33782471,7e7,1e8), H, n=100)



</code></pre>


</div>