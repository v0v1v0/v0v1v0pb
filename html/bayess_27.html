<div class="container">

<table style="width: 100%;"><tr>
<td>hmhmm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Estimation of a hidden Markov model with 2 hidden and 4 observed states
</h2>

<h3>Description</h3>

<p>This function implements a Metropolis within Gibbs algorithm that produces
a sample on the parameters <code class="reqn">p_{ij}</code> and <code class="reqn">q^i_j</code> of the hidden Markov
model (Chapter 7). It includes a function <code>likej</code> that computes the likelihood of
the times series using a forward-backward algorithm.
</p>


<h3>Usage</h3>

<pre><code class="language-R">hmhmm(M = 100, y)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>M</code></td>
<td>

<p>Number of Gibbs iterations
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>times series to be modelled by a hidden Markov model
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>The Metropolis-within-Gibbs step involves Dirichlet proposals with
a random choice of the scale between 1 and 1e5.
</p>


<h3>Value</h3>



<table>
<tr style="vertical-align: top;">
<td><code>BigR </code></td>
<td>
<p>matrix of the iterated values returned by the MCMC algorithm containing
<code class="reqn">p_{11}</code> and <code class="reqn">p_{22}</code>, transition probabilities, and 
<code class="reqn">q^1</code> and <code class="reqn">q^2</code>, vector of probabilities for both latent states</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>olike </code></td>
<td>
<p>sequence of the log-likelihoods produced by the MCMC sequence</p>
</td>
</tr>
</table>
<h3>Examples</h3>

<pre><code class="language-R">res=hmhmm(M=500,y=sample(1:4,10,rep=TRUE))
plot(res$olike,type="l",main="log-likelihood",xlab="iterations",ylab="")
</code></pre>


</div>