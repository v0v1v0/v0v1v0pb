<div class="container">

<table style="width: 100%;"><tr>
<td>summary.normaliw</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Summarizing Bayesian Multivariate Time Series Model</h2>

<h3>Description</h3>

<p><code>summary</code> method for <code>normaliw</code> class.
</p>


<h3>Usage</h3>

<pre><code class="language-R">## S3 method for class 'normaliw'
summary(
  object,
  num_chains = 1,
  num_iter = 1000,
  num_burn = floor(num_iter/2),
  thinning = 1,
  verbose = FALSE,
  num_thread = 1,
  ...
)

## S3 method for class 'summary.normaliw'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'summary.normaliw'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A <code>normaliw</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_chains</code></td>
<td>
<p>Number of MCMC chains</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_iter</code></td>
<td>
<p>MCMC iteration number</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_burn</code></td>
<td>
<p>Number of burn-in (warm-up). Half of the iteration is the default choice.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>thinning</code></td>
<td>
<p>Thinning every thinning-th iteration</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>Print the progress bar in the console. By default, <code>FALSE</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_thread</code></td>
<td>
<p>Number of threads</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>not used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p><code>summary.normaliw</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>digit option to print</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>From Minnesota prior, set of coefficient matrices and residual covariance matrix have matrix Normal Inverse-Wishart distribution.
</p>
<p>BVAR:
</p>
<p style="text-align: center;"><code class="reqn">(A, \Sigma_e) \sim MNIW(\hat{A}, \hat{V}^{-1}, \hat\Sigma_e, \alpha_0 + n)</code>
</p>

<p>where <code class="reqn">\hat{V} = X_\ast^T X_\ast</code> is the posterior precision of MN.
</p>
<p>BVHAR:
</p>
<p style="text-align: center;"><code class="reqn">(\Phi, \Sigma_e) \sim MNIW(\hat\Phi, \hat{V}_H^{-1}, \hat\Sigma_e, \nu + n)</code>
</p>

<p>where <code class="reqn">\hat{V}_H = X_{+}^T X_{+}</code> is the posterior precision of MN.
</p>


<h3>Value</h3>

<p><code>summary.normaliw</code> class has the following components:
</p>

<dl>
<dt>names</dt>
<dd>
<p>Variable names</p>
</dd>
<dt>totobs</dt>
<dd>
<p>Total number of the observation</p>
</dd>
<dt>obs</dt>
<dd>
<p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>p</dt>
<dd>
<p>Lag of VAR</p>
</dd>
<dt>m</dt>
<dd>
<p>Dimension of the data</p>
</dd>
<dt>call</dt>
<dd>
<p>Matched call</p>
</dd>
<dt>spec</dt>
<dd>
<p>Model specification (<code>bvharspec</code>)</p>
</dd>
<dt>mn_mean</dt>
<dd>
<p>MN Mean of posterior distribution (MN-IW)</p>
</dd>
<dt>mn_prec</dt>
<dd>
<p>MN Precision of posterior distribution (MN-IW)</p>
</dd>
<dt>iw_scale</dt>
<dd>
<p>IW scale of posterior distribution (MN-IW)</p>
</dd>
<dt>iw_shape</dt>
<dd>
<p>IW df of posterior distribution (MN-IW)</p>
</dd>
<dt>iter</dt>
<dd>
<p>Number of MCMC iterations</p>
</dd>
<dt>burn</dt>
<dd>
<p>Number of MCMC burn-in</p>
</dd>
<dt>thin</dt>
<dd>
<p>MCMC thinning</p>
</dd>
<dt>alpha_record (BVAR) and phi_record (BVHAR)</dt>
<dd>
<p>MCMC record of coefficients vector</p>
</dd>
<dt>psi_record</dt>
<dd>
<p>MCMC record of upper cholesky factor</p>
</dd>
<dt>omega_record</dt>
<dd>
<p>MCMC record of diagonal of cholesky factor</p>
</dd>
<dt>eta_record</dt>
<dd>
<p>MCMC record of upper part of cholesky factor</p>
</dd>
<dt>param</dt>
<dd>
<p>MCMC record of every parameter</p>
</dd>
<dt>coefficients</dt>
<dd>
<p>Posterior mean of coefficients</p>
</dd>
<dt>covmat</dt>
<dd>
<p>Posterior mean of covariance</p>
</dd>
</dl>
<h3>References</h3>

<p>Litterman, R. B. (1986). <em>Forecasting with Bayesian Vector Autoregressions: Five Years of Experience</em>. Journal of Business &amp; Economic Statistics, 4(1), 25.
</p>
<p>Ba≈Ñbura, M., Giannone, D., &amp; Reichlin, L. (2010). <em>Large Bayesian vector auto regressions</em>. Journal of Applied Econometrics, 25(1).
</p>


</div>