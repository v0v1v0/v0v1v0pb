<div class="container">

<table style="width: 100%;"><tr>
<td>PlotCGBN</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Plot the Bayesian network</h2>

<h3>Description</h3>

<p>Plot and compare two Bayesian networks with different evidence(s) absorbed and propagated.
</p>


<h3>Usage</h3>

<pre><code class="language-R">PlotCGBN(
  tree.1,
  tree.2,
  fontsize = NULL,
  pbar = FALSE,
  plotting = TRUE,
  epsilon = 10^-6
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>tree.1</code></td>
<td>
<p>a <code>ClusterTree</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tree.2</code></td>
<td>
<p>a <code>ClusterTree</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fontsize</code></td>
<td>
<p>font size for the node labels</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pbar</code></td>
<td>
<p><code>logical(1)</code> whether to show progress bar</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>plotting</code></td>
<td>
<p><code>logical(1)</code> whether to output plot</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>epsilon</code></td>
<td>
<p><code>numeric(1)</code> the KL divergence is undefined if certain states of a discrete variable 
have probabilities of 0. In this case, a small positive number epsilon is assigned as their probabilities for calculating
the divergence. The probabilities of other states are shrunked proportionally to ensure they sum up to 1.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Network visualization of the node-specific differences between Bayesian Networks
with the same topology, but evidence that has been absorbed and propagated.  The change of
marginal distribution of each node is measured by signed and symmetric Kullback-Leibler
divergence.  The sign indicates the direction of change, with <code>tree.1</code> considered as the baseline.
The magnitude of the change is reflected by the value.  Nodes that are white are d-separated
from the evidence. This function requires <code>Rgraphviz</code> package.
</p>


<h3>Value</h3>

<p>a plot of Bayesian network
</p>
<p>a <code>vector</code> of signed symmetric Kullback-Leibler divergence
</p>


<h3>Author(s)</h3>

<p>Han Yu
</p>


<h3>References</h3>

<p>Cowell, R. G. (2005). Local propagation in conditional Gaussian Bayesian networks.
Journal of Machine Learning Research, 6(Sep), 1517-1550. <br><br>
Yu H, Moharil J, Blair RH (2020). BayesNetBP: An R Package for Probabilistic Reasoning in Bayesian
Networks. Journal of Statistical Software, 94(3), 1-31. &lt;doi:10.18637/jss.v094.i03&gt;.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library("Rgraphviz")
data(toytree)
tree.post &lt;- AbsorbEvidence(toytree, c("Nr1i3"), list(1))
PlotCGBN(tree.1=toytree, tree.2=tree.post)

## End(Not run)
</code></pre>


</div>