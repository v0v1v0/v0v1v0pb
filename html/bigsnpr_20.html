<div class="container">

<table style="width: 100%;"><tr>
<td>bed_tcrossprodSelf</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>tcrossprod / GRM</h2>

<h3>Description</h3>

<p>Compute <code class="reqn">G G^T</code> from a bed object, with possible filtering and scaling
of <code>G</code>. For example, this can be used to compute GRMs.
</p>


<h3>Usage</h3>

<pre><code class="language-R">bed_tcrossprodSelf(
  obj.bed,
  fun.scaling = bed_scaleBinom,
  ind.row = rows_along(obj.bed),
  ind.col = cols_along(obj.bed),
  block.size = block_size(length(ind.row))
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>obj.bed</code></td>
<td>
<p>Object of type bed, which is the mapping of some bed file.
Use <code>obj.bed &lt;- bed(bedfile)</code> to get this object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fun.scaling</code></td>
<td>
<p>A function with parameters <code>X</code> (or <code>obj.bed</code>), <code>ind.row</code> and
<code>ind.col</code>, and that returns a data.frame with <code style="white-space: pre;">⁠$center⁠</code> and <code style="white-space: pre;">⁠$scale⁠</code> for the
columns corresponding to <code>ind.col</code>, to scale each of their elements such as followed:
</p>
<p style="text-align: center;"><code class="reqn">\frac{X_{i,j} - center_j}{scale_j}.</code>
</p>
<p> Default uses binomial scaling.
You can also provide your own <code>center</code> and <code>scale</code> by using <code>bigstatsr::as_scaling_fun()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.row</code></td>
<td>
<p>An optional vector of the row indices (individuals) that
are used. If not specified, all rows are used.<br><strong>Don't use negative indices.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind.col</code></td>
<td>
<p>An optional vector of the column indices (SNPs) that are used.
If not specified, all columns are used.<br><strong>Don't use negative indices.</strong></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>block.size</code></td>
<td>
<p>Maximum number of columns read at once.
Default uses block_size.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A temporary FBM, with the following two attributes:
</p>

<ul>
<li>
<p> a numeric vector <code>center</code> of column scaling,
</p>
</li>
<li>
<p> a numeric vector <code>scale</code> of column scaling.
</p>
</li>
</ul>
<h3>Matrix parallelization</h3>

<p>Large matrix computations are made block-wise and won't be parallelized
in order to not have to reduce the size of these blocks. Instead, you can use
the <a href="https://forum.posit.co/t/intel-mkl-integration-to-r-on-windows/176071">MKL</a>
or OpenBLAS in order to accelerate these block matrix computations.
You can control the number of cores used by these optimized matrix libraries
with <code>bigparallelr::set_blas_ncores()</code>.
</p>


<h3>Examples</h3>

<pre><code class="language-R">bedfile &lt;- system.file("extdata", "example.bed", package = "bigsnpr")
obj.bed &lt;- bed(bedfile)

K &lt;- bed_tcrossprodSelf(obj.bed)
K[1:4, 1:6] / ncol(obj.bed)

</code></pre>


</div>