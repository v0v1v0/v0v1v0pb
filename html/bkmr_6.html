<div class="container">

<table style="width: 100%;"><tr>
<td>kmbayes</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fit Bayesian kernel machine regression</h2>

<h3>Description</h3>

<p>Fits the Bayesian kernel machine regression (BKMR) model using Markov chain Monte Carlo (MCMC) methods.
</p>


<h3>Usage</h3>

<pre><code class="language-R">kmbayes(
  y,
  Z,
  X = NULL,
  iter = 1000,
  family = "gaussian",
  id = NULL,
  verbose = TRUE,
  Znew = NULL,
  starting.values = NULL,
  control.params = NULL,
  varsel = FALSE,
  groups = NULL,
  knots = NULL,
  ztest = NULL,
  rmethod = "varying",
  est.h = FALSE
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>a vector of outcome data of length <code>n</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Z</code></td>
<td>
<p>an <code>n</code>-by-<code>M</code> matrix of predictor variables to be included in the <code>h</code> function. Each row represents an observation and each column represents an predictor.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>an <code>n</code>-by-<code>K</code> matrix of covariate data where each row represents an observation and each column represents a covariate. Should not contain an intercept column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>number of iterations to run the sampler</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>family</code></td>
<td>
<p>a description of the error distribution and link function to be used in the model. Currently implemented for <code>gaussian</code> and <code>binomial</code> families.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>optional vector (of length <code>n</code>) of grouping factors for fitting a model with a random intercept. If NULL then no random intercept will be included.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>TRUE or FALSE: flag indicating whether to print intermediate diagnostic information during the model fitting.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Znew</code></td>
<td>
<p>optional matrix of new predictor values at which to predict <code>h</code>, where each row represents a new observation. This will slow down the model fitting, and can be done as a post-processing step using <code>SamplePred</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>starting.values</code></td>
<td>
<p>list of starting values for each parameter. If not specified default values will be chosen.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>control.params</code></td>
<td>
<p>list of parameters specifying the prior distributions and tuning parameters for the MCMC algorithm. If not specified default values will be chosen.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>varsel</code></td>
<td>
<p>TRUE or FALSE: indicator for whether to conduct variable selection on the Z variables in <code>h</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>groups</code></td>
<td>
<p>optional vector (of length <code>M</code>) of group indicators for fitting hierarchical variable selection if varsel=TRUE. If varsel=TRUE without group specification, component-wise variable selections will be performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>knots</code></td>
<td>
<p>optional matrix of knot locations for implementing the Gaussian predictive process of Banerjee et al. (2008). Currently only implemented for models without a random intercept.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ztest</code></td>
<td>
<p>optional vector indicating on which variables in Z to conduct variable selection (the remaining variables will be forced into the model).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>rmethod</code></td>
<td>
<p>for those predictors being forced into the <code>h</code> function, the method for sampling the <code>r[m]</code> values. Takes the value of 'varying' to allow separate <code>r[m]</code> for each predictor; 'equal' to force the same <code>r[m]</code> for each predictor; or 'fixed' to fix the <code>r[m]</code> to their starting values</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>est.h</code></td>
<td>
<p>TRUE or FALSE: indicator for whether to sample from the posterior distribution of the subject-specific effects h_i within the main sampler. This will slow down the model fitting.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>an object of class "bkmrfit" (containing the posterior samples from the model fit), which has the associated methods:
</p>

<ul>
<li> <p><code>print</code> (i.e., <code>print.bkmrfit</code>) 
</p>
</li>
<li> <p><code>summary</code> (i.e., <code>summary.bkmrfit</code>)
</p>
</li>
</ul>
<h3>References</h3>

<p>Bobb, JF, Valeri L, Claus Henn B, Christiani DC, Wright RO, Mazumdar M, Godleski JJ, Coull BA (2015). Bayesian Kernel Machine Regression for Estimating the Health Effects of Multi-Pollutant Mixtures. Biostatistics 16, no. 3: 493-508.
</p>
<p>Banerjee S, Gelfand AE, Finley AO, Sang H (2008). Gaussian predictive process models for large spatial data sets. Journal of the Royal Statistical Society: Series B (Statistical Methodology), 70(4), 825-848.
</p>


<h3>See Also</h3>

<p>For guided examples, go to <a href="https://jenfb.github.io/bkmr/overview.html">https://jenfb.github.io/bkmr/overview.html</a>
</p>


<h3>Examples</h3>

<pre><code class="language-R">## First generate dataset
set.seed(111)
dat &lt;- SimData(n = 50, M = 4)
y &lt;- dat$y
Z &lt;- dat$Z
X &lt;- dat$X

## Fit model with component-wise variable selection
## Using only 100 iterations to make example run quickly
## Typically should use a large number of iterations for inference
set.seed(111)
fitkm &lt;- kmbayes(y = y, Z = Z, X = X, iter = 100, verbose = FALSE, varsel = TRUE)
</code></pre>


</div>