<div class="container">

<table style="width: 100%;"><tr>
<td>ss.power.reg.all</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Necessary sample size to reach desired power for a test of model R2 in a
multiple regression using an uncertainty and publication bias correction
procedure</h2>

<h3>Description</h3>

<p><code>ss.power.reg.all</code> returns the necessary total sample size
to achieve a desired level of statistical power for a test of model R2
in a planned study using multiple regression, based on information
obtained from a previous study.The effect from the previous study
can be corrected for publication bias and/or uncertainty to provide
a sample size that will achieve more accurate statistical power for a
planned study, when compared to approaches that use a sample effect size at
face value or rely on sample size only. The bias and uncertainty adjusted
previous study noncentrality parameter is also returned, which can be
transformed to various effect size metrics.
</p>


<h3>Usage</h3>

<pre><code class="language-R">ss.power.reg.all(F.observed, N, p, alpha.prior = 0.05,
  alpha.planned = 0.05, assurance = 0.8, power = 0.8, step = 0.001)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>F.observed</code></td>
<td>
<p>Observed <code class="reqn">F</code>-value from a previous study used to plan
sample size for a planned study</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>
<p>Total sample size of the previous study</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Number of predictors; be sure to include any product terms or
polynomials that are in the model</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.prior</code></td>
<td>
<p>Alpha-level <code class="reqn">\alpha</code> for the previous study or the
assumed statistical significance necessary for publishing in the field; to
assume no publication bias, a value of 1 can be entered</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alpha.planned</code></td>
<td>
<p>Alpha-level (<code class="reqn">\alpha</code>) assumed for the planned study</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>assurance</code></td>
<td>
<p>Desired level of assurance, or the long run proportion of
times that the planned study power will reach or surpass desired level
(assurance &gt; .5 corrects for uncertainty; assurance &lt; .5 not recommended)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>power</code></td>
<td>
<p>Desired level of statistical power for the planned study</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>step</code></td>
<td>
<p>Value used in the iterative scheme to determine the noncentrality
parameter necessary for sample size planning (0 &lt; step &lt; .01) (users should
not generally need to change this value; smaller values lead to more
accurate sample size planning results, but unnecessarily small values will
add unnecessary computational time)</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Researchers often use the sample effect size from a prior study as
an estimate of the likely size of an expected future effect in sample size
planning. However, sample effect size estimates should not usually be used
at face value to plan sample size, due to both publication bias and
uncertainty.
</p>
<p>The approach implemented in <code>ss.power.reg.all</code> uses the observed
<code class="reqn">F</code>-value and sample size from a previous study to correct the
noncentrality parameter associated with the effect of interest for
publication bias and/or uncertainty. This new estimated noncentrality
parameter is then used to calculate the necessary total sample size to
achieve the desired level of power in the planned study.
</p>
<p>The approach uses a likelihood function of a truncated non-central F
distribution, where the truncation occurs due to small effect sizes being
unobserved due to publication bias. The numerator of the likelihood
function is simply the density of a noncentral F distribution. The
denominator is the power of the test, which serves to truncate the
distribution. In the single predictor case, this formula reduces to the density
of a truncated noncentral <code class="reqn">t</code>-distribution.(See Taylor &amp; Muller, 1996,
Equation 2.1. and Anderson &amp; Maxwell, 2017, for more details.)
</p>
<p>Assurance is the proportion of times that power will be at or above the
desired level, if the experiment were to be reproduced many times. For
example, assurance = .5 means that power will be above the desired level
half of the time, but below the desired level the other half of the time.
Selecting assurance = .5 (selecting the noncentrality parameter at the 50th
percentile of the likelihood distribution) results in a median-unbiased
estimate of the population noncentrality parameter and does not correct for
uncertainty. In order to correct for uncertainty, assurance &gt; .5
can be selected, which corresponds to selecting the noncentrality parameter
associated with the (1 - assurance) quantile of the likelihood
distribution.
</p>
<p>If the previous study of interest has not been subjected to publication
bias (e.g., a pilot study), <code>alpha.prior</code> can be set to 1 to indicate
no publication bias. Alternative <code class="reqn">\alpha</code>-levels can also be
accommodated to represent differing amounts of publication bias. For
example, setting <code>alpha.prior</code>=.20 would reflect less severe
publication bias than the default of .05. In essence, setting
<code>alpha.prior</code> at .20 assumes that studies with <code class="reqn">p</code>-values less
than .20 are published, whereas those with larger <code class="reqn">p</code>-values are not.
</p>
<p>In some cases, the corrected noncentrality parameter for a given level of
assurance will be estimated to be zero. This is an indication that, at the
desired level of assurance, the previous study's effect cannot be
accurately estimated due to high levels of uncertainty and bias. When this
happens, subsequent sample size planning is not possible with the chosen
specifications. Two alternatives are recommended. First, users can select a
lower value of assurance (e.g. .8 instead of .95). Second, users can reduce
the influence of publciation bias by setting <code>alpha.prior</code> at a value
greater than .05. It is possible to correct for uncertainty only by setting
<code>alpha.prior</code>=1 and choosing the desired level of assurance. We
encourage users to make the adjustments as minimal as possible.
</p>


<h3>Value</h3>

<p>Suggested total sample size for planned study
</p>
<p>Publication bias and uncertainty- adjusted prior study noncentrality parameter
</p>


<h3>Author(s)</h3>

<p>Samantha F. Anderson <a href="mailto:samantha.f.anderson@asu.edu">samantha.f.anderson@asu.edu</a>,
Ken Kelley <a href="mailto:kkelley@nd.edu">kkelley@nd.edu</a>
</p>


<h3>References</h3>

<p>Anderson, S. F., &amp; Maxwell, S. E. (2017).
Addressing the 'replication crisis': Using original studies to design
replication studies with appropriate statistical power. <em>Multivariate
Behavioral Research, 52,</em> 305-322.
</p>
<p>Anderson, S. F., Kelley, K., &amp; Maxwell, S. E. (2017). Sample size
planning for more accurate statistical power: A method correcting sample
effect sizes for uncertainty and publication bias. <em>Psychological
Science, 28,</em> 1547-1562.
</p>
<p>Taylor, D. J., &amp; Muller, K. E. (1996). Bias in linear model power and
sample size calculation due to estimating noncentrality.
<em>Communications in Statistics: Theory and Methods, 25,</em> 1595-1610.
</p>


<h3>Examples</h3>

<pre><code class="language-R">ss.power.reg.all(F.observed=5, N=150, p=4, alpha.prior=.05, alpha.planned=.05,
assurance=.80, power=.80, step=.001)

</code></pre>


</div>