<div class="container">

<table style="width: 100%;"><tr>
<td>train_lightgbm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Boosted trees with lightgbm</h2>

<h3>Description</h3>

<p><code>train_lightgbm</code> is a wrapper for <code>lightgbm</code> tree-based models
where all of the model arguments are in the main function.
</p>


<h3>Usage</h3>

<pre><code class="language-R">train_lightgbm(
  x,
  y,
  weights = NULL,
  max_depth = -1,
  num_iterations = 100,
  learning_rate = 0.1,
  feature_fraction_bynode = 1,
  min_data_in_leaf = 20,
  min_gain_to_split = 0,
  bagging_fraction = 1,
  early_stopping_round = NULL,
  validation = 0,
  counts = TRUE,
  quiet = FALSE,
  ...
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A data frame or matrix of predictors</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>A vector (factor or numeric) or matrix (numeric) of outcome data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>weights</code></td>
<td>
<p>A numeric vector of sample weights.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_depth</code></td>
<td>
<p>An integer for the maximum depth of the tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_iterations</code></td>
<td>
<p>An integer for the number of boosting iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>learning_rate</code></td>
<td>
<p>A numeric value between zero and one to control the learning rate.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>feature_fraction_bynode</code></td>
<td>
<p>Fraction of predictors that will be randomly sampled
at each split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_data_in_leaf</code></td>
<td>
<p>A numeric value for the minimum sum of instances needed
in a child to continue to split.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>min_gain_to_split</code></td>
<td>
<p>A number for the minimum loss reduction required to make a
further partition on a leaf node of the tree.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>bagging_fraction</code></td>
<td>
<p>Subsampling proportion of rows. Setting this argument
to a non-default value will also set <code>bagging_freq = 1</code>. See the Bagging
section in <code>?details_boost_tree_lightgbm</code> for more details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>early_stopping_round</code></td>
<td>
<p>Number of iterations without an improvement in
the objective function occur before training should be halted.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>validation</code></td>
<td>
<p>The <em>proportion</em> of the training data that are used for
performance assessment and potential early stopping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>counts</code></td>
<td>
<p>A logical; should <code>feature_fraction_bynode</code> be interpreted as the
<em>number</em> of predictors that will be randomly sampled at each split?
<code>TRUE</code> indicates that <code>mtry</code> will be interpreted in its sense as a <em>count</em>,
<code>FALSE</code> indicates that the argument will be interpreted in its sense as a
<em>proportion</em>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>quiet</code></td>
<td>
<p>A logical; should logging by <code>lightgbm::lgb.train()</code> be muted?</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>Other options to pass to <code>lightgbm::lgb.train()</code>. Arguments
will be correctly routed to the <code>param</code> argument, or as a main argument,
depending on their name.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This is an internal function, not meant to be directly called by the user.
</p>


<h3>Value</h3>

<p>A fitted <code>lightgbm.Model</code> object.
</p>


</div>