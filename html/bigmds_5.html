<div class="container">

<table style="width: 100%;"><tr>
<td>pivot_mds</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Pivot MDS</h2>

<h3>Description</h3>

<p>Pivot MDS, introduced in the literature of graph layout algorithms, is similar to
Landmark MDS (<code>landmark_mds()</code>) but it uses the distance information between landmark and non-landmark
points to improve the initial low dimensional configuration,
as more relations than just those between landmark points are taken into account.
</p>


<h3>Usage</h3>

<pre><code class="language-R">pivot_mds(x, num_pivots, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> individuals (rows) and <code class="reqn">k</code> variables (columns).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_pivots</code></td>
<td>
<p>Number of pivot points to obtain an initial MDS configuration. It is
equivalent to <code>l</code> parameter used in <code>interpolation_mds()</code>, <code>divide_conquer_mds()</code> and
<code>fast_mds()</code>. Therefore, it is the size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt>
<dd>
<p>A matrix that consists of <code class="reqn">n</code> individuals (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
we are performing a dimensionality reduction, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt>
<dd>
<p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>
<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Brandes U. and C. Pich (2007). <em>Eigensolver Methods for Progressive Multidimensional Scaling of Large Data</em>. Graph Drawing.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- pivot_mds(x = x, num_pivots = 200, r = 2)
head(mds$points)
mds$eigen

</code></pre>


</div>