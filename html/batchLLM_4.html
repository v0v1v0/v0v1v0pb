<div class="container">

<table style="width: 100%;"><tr>
<td>claudeR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Interact with Anthropic's Claude API</h2>

<h3>Description</h3>

<p>This function provides an interface to interact with Claude AI models via Anthropic's API, allowing for flexible text generation based on user inputs.
This function was adapted from the <a href="https://github.com/yrvelez/claudeR">claudeR</a> repository by <a href="https://github.com/yrvelez">yrvelez</a> on GitHub (MIT License).
</p>


<h3>Usage</h3>

<pre><code class="language-R">claudeR(
  prompt,
  model = "claude-3-5-sonnet-20240620",
  max_tokens = 500,
  stop_sequences = NULL,
  temperature = 0.7,
  top_k = -1,
  top_p = -1,
  api_key = NULL,
  system_prompt = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>prompt</code></td>
<td>
<p>A string vector for Claude-2, or a list for Claude-3 specifying the input for the model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>The model to use for the request. Default is the latest Claude-3 model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>max_tokens</code></td>
<td>
<p>A maximum number of tokens to generate before stopping.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>stop_sequences</code></td>
<td>
<p>Optional. A list of strings upon which to stop generating.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>temperature</code></td>
<td>
<p>Optional. Amount of randomness injected into the response.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top_k</code></td>
<td>
<p>Optional. Only sample from the top K options for each subsequent token.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>top_p</code></td>
<td>
<p>Optional. Does nucleus sampling.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>api_key</code></td>
<td>
<p>Your API key for authentication.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>system_prompt</code></td>
<td>
<p>Optional. An optional system role specification.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The resulting completion up to and excluding the stop sequences.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(batchLLM)

# Set API in the env or use api_key parameter in the claudeR call
Sys.setenv(ANTHROPIC_API_KEY = "your_anthropic_api_key")

# Using Claude-2
response &lt;- claudeR(
  prompt = "What is the capital of France?",
  model = "claude-2.1",
  max_tokens = 50
)
cat(response)

# Using Claude-3
response &lt;- claudeR(
  prompt = list(
    list(role = "user", content = "What is the capital of France?")
  ),
  model = "claude-3-5-sonnet-20240620",
  max_tokens = 50,
  temperature = 0.8
)
cat(response)

# Using a system prompt
response &lt;- claudeR(
  prompt = list(
    list(role = "user", content = "Summarize the history of France in one paragraph.")
  ),
  system_prompt = "You are a concise summarization assistant.",
  max_tokens = 500
)
cat(response)

## End(Not run)
</code></pre>


</div>