<div class="container">

<table style="width: 100%;"><tr>
<td>GibbsBvsF</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Bayesian Variable Selection with Factors for linear regression models using Gibbs
sampling.</h2>

<h3>Description</h3>

<p>Numerical and factor variable selection from a Bayesian perspective. The posterior distribution is approximated
with Gibbs sampling
</p>


<h3>Usage</h3>

<pre><code class="language-R">GibbsBvsF(
  formula,
  data,
  null.model = paste(as.formula(formula)[[2]], " ~ 1", sep = ""),
  prior.betas = "Robust",
  prior.models = "SBSB",
  n.iter = 10000,
  init.model = "Full",
  n.burnin = 500,
  n.thin = 1,
  time.test = TRUE,
  seed = runif(1, 0, 16091956)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>formula</code></td>
<td>
<p>Formula defining the most complex linear model in the
analysis. See details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>data frame containing the data.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>null.model</code></td>
<td>
<p>A formula defining which is the simplest (null) model.
It should be nested in the full model. It is compulsory that the null model
contains the intercept and by default, the null model is defined
to be the one with just the intercept</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.betas</code></td>
<td>
<p>Prior distribution for regression parameters within each
model (to be literally specified). Possible choices include "Robust", "Robust.G", "Liangetal", "gZellner",
"ZellnerSiow" (see details in <code>Bvs</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.models</code></td>
<td>
<p>Prior distribution over the model space (to be literally specified). Possible
choices (see details) are "Const", "SB", "ConstConst", "SBConst" and "SBSB" (the default).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.iter</code></td>
<td>
<p>The total number of iterations performed after the burn in
process.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>init.model</code></td>
<td>
<p>The model at which the simulation process starts. Options
include "Null" (the model only with the covariates specified in
<code>fixed.cov</code>), "Full" (the model defined by <code>formula</code>), "Random" (a
randomly selected model) and a vector with (pnum+sum_j L_j) zeros and ones defining a model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.burnin</code></td>
<td>
<p>Length of burn in, i.e. number of iterations to discard at
the beginning.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n.thin</code></td>
<td>
<p>Thinning rate. Must be a positive integer.  Set 'n.thin' &gt; 1
to save memory and computation time if 'n.iter' is large. Default is 1. This
parameter jointly with <code>n.iter</code> sets the number of simulations kept and
used to construct the estimates so is important to keep in mind that a large
value for 'n.thin' can reduce the precision of the results</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>time.test</code></td>
<td>
<p>If TRUE and the number of variables is large (&gt;=21) a
preliminary test to estimate computational time is performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>A seed to initialize the random number generator</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>In practical terms, <code>GibbsBvsF</code> can be understood as a version of <code>GibbsBvs</code> in the presence of factors.
The methodology implemented in <code>GibbsBvsF</code> to handle variable selection problems with factors
has been proposed in Garcia-Donato and Paulo (2018) leading to a method
for which results  do not depend on how the factors are
coded (eg. via <code>contrast</code>).
</p>
<p>Internally, a rank defficient representation
of factors using dummies is used and the number of competing models considered is
</p>
<p>2^(pnum+sum_j L_j),
</p>
<p>where pnum is the number of numerical variables and L_j is the number of levels in factor j.
</p>
<p>A main difference with <code>Bvs</code> and <code>GibbsBvs</code> (due to the presence of factors) concerns the prior
probabilities on the model space:
</p>
<p>The options <code>prior.models="SBSB"</code>, <code>prior.models="ConstConst"</code> and <code>prior.models="SBConst"</code>
acknowledge the "grouped" nature of the dummy variables representing
factors through the use of two stage
priors described in Garcia-Donato and Paulo (2021). In the first stage probabilities over factors and numerical
variables are specified and (conditional on these) within the second stage
the probablities are apportioned over the different submodels defined
by the dummies. The default (and recommended, for the reasons argued in Garcia-Donato and Paulo,2021) 
option is "SBSB" which uses in both stages an assignment
of the type Scott-Berger so inversely proportional to the number of models of the same dimension. The
option "ConstConst" implements a uniform prior for both stages while "SBConst" uses a Scott-Berger prior
in the first stage and it is uniform in the second stage. Within all these priors, the prior inclusion probabilities
of factors and numerical variables are 1/2.
</p>
<p>The options <code>prior.models="Const"</code> and
<code>prior.models="SB"</code> do not have a staged structure and "Const" apportions the prior probabilities
uniformly over all possible models (2^(pnum+sum_j L_j)) and in "SB" the probability
is inversely proportional to the number of any model of the same dimension. In these cases, prior inclusion probabilities
of factors and numerical variables depend on the number of levels of factors and, in general, are not 1/2.
</p>


<h3>Value</h3>

<p><code>GibbsBvsF</code> returns an object of class <code>Bvs</code> with the
following elements: </p>
<table>
<tr style="vertical-align: top;">
<td><code>time </code></td>
<td>
<p>The internal time consumed in solving the
problem</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmfull </code></td>
<td>
<p>The <code>lm</code> class object that results when the
model defined by <code>formula</code> is fitted by <code>lm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>lmnull </code></td>
<td>
<p>The
<code>lm </code> class object that results when the model defined by
<code>fixed.cov</code> is fitted by <code>lm</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>variables </code></td>
<td>
<p>The name of all the potential explanatory variables (numerical or factors)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>n </code></td>
<td>
<p>Number of observations</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p </code></td>
<td>
<p>Number of explanatory variables (both numerical and factors) to select from</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>k </code></td>
<td>
<p>Number of fixed variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>HPMbin </code></td>
<td>
<p>The binary expression of the most
probable model found.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>inclprob </code></td>
<td>
<p>A named vector with the
estimates of the inclusion probabilities of all the variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>jointinclprob </code></td>
<td>
<p>A <code>data.frame</code> with the estimates of the joint
inclusion probabilities of all the variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>postprobdim </code></td>
<td>
<p>Estimates
of posterior probabilities of the number of active variables in the true model (hence ranking from
<code>k </code> to <code>k+p</code>).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelslogBF </code></td>
<td>
<p>A matrix with both the binary representation of the
active variables in the MCMC after the burning period and the Bayes factor (log scale) of
that model to the null model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>modelswllogBF </code></td>
<td>
<p>A matrix with both the binary representation of the
active variables (at the level of the levels in the factors) in the MCMC after the burning period and the Bayes factor (log scale) of
that model to the null model.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call </code></td>
<td>
<p>The <code>call</code> to the
function.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C </code></td>
<td>
<p>An estimation of the normalizing constant (C=sum Bi Pr(Mi), for Mi in the model space) using the method in George and McCulloch (1997).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positions </code></td>
<td>
<p>A binary matrix with <code>p</code> rows and (pnum+sum_j L_j) columns. The 1's identify, for each variable (row) the position (column)
of dummies (in case of factor) or of the numerical variable grouped on that variable. (Its use is conceived for internal purposes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>positionsx </code></td>
<td>
<p>A <code>p</code> dimensional binary vector, stating which of the competing variables is a numerical variable. (Its use is conceived for internal purposes).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.betas</code></td>
<td>
<p>prior.betas</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>prior.models</code></td>
<td>
<p>prior.models</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method </code></td>
<td>
<p><code>gibbsWithFactors</code></p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Gonzalo Garcia-Donato and Anabel Forte
</p>


<h3>References</h3>

<p>Garcia-Donato, G. and Martinez-Beneito, M.A.
(2013)&lt;DOI:10.1080/01621459.2012.742443&gt; On sampling strategies in Bayesian
variable selection problems with large model spaces. Journal of the American
Statistical Association, 108: 340-352.
</p>
<p>Garcia-Donato, G. and Paulo, R. (2021) Variable selection in the presence of factors: 
a model selection perspective. Journal of American Statistical Association, Ahead-of- print(1-11).
</p>
<p>George E. and McCulloch R. (1997) Approaches for Bayesian variable
selection. Statistica Sinica, 7, 339:372.
</p>


<h3>See Also</h3>

<p><code>plot.Bvs</code> for several plots of the result.
</p>
<p>Under construction: <code>BMAcoeff</code> for obtaining model averaged simulations
of regression coefficients and <code>predict.Bvs</code> for
predictions.
</p>
<p>See <code>GibbsBvs</code> and <code>Bvs</code> when no factors are involved.
</p>


<h3>Examples</h3>

<pre><code class="language-R">
## Not run: 
data(diabetes, package="faraway")

#remove NA's and the column with the id of samples:
diabetes2&lt;- na.omit(diabetes)[,-1]

#For reproducibility:
set.seed(16091956)
#Now run the main instruction
diabetesVS&lt;- GibbsBvsF(formula= glyhb ~ ., data=diabetes2, n.iter=100000, n.burnin=5000)

summary(diabetesVS)

#A plot of the dimension of the true model,
plot(diabetesVS, option="dimension")

#A joint inclusion plot
plot(diabetesVS, option="joint")

#Now a similar exercise but with fixed variables:
diabetesVS2&lt;- GibbsBvsF(formula= glyhb ~ ., null.model= glyhb ~ chol+stab.glu,
		                   data=diabetes2, n.iter=100000, n.burnin=5000)


#and with fixed factors:
diabetesVS3&lt;- GibbsBvsF(formula= glyhb ~ ., null.model= glyhb ~ chol+stab.glu+location,
		                   data=diabetes2, n.iter=100000, n.burnin=5000)



## End(Not run)

</code></pre>


</div>