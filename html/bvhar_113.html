<div class="container">

<table style="width: 100%;"><tr>
<td>var_lm</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Fitting Vector Autoregressive Model of Order p Model</h2>

<h3>Description</h3>

<p>This function fits VAR(p) using OLS method.
</p>


<h3>Usage</h3>

<pre><code class="language-R">var_lm(y, p = 1, include_mean = TRUE, method = c("nor", "chol", "qr"))

## S3 method for class 'varlse'
print(x, digits = max(3L, getOption("digits") - 3L), ...)

## S3 method for class 'varlse'
logLik(object, ...)

## S3 method for class 'varlse'
AIC(object, ...)

## S3 method for class 'varlse'
BIC(object, ...)

is.varlse(x)

is.bvharmod(x)

## S3 method for class 'varlse'
knit_print(x, ...)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>Time series data of which columns indicate the variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>p</code></td>
<td>
<p>Lag of VAR (Default: 1)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>include_mean</code></td>
<td>
<p>Add constant term (Default: <code>TRUE</code>) or not (<code>FALSE</code>)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>method</code></td>
<td>
<p>Method to solve linear equation system.
(<code>nor</code>: normal equation (default), <code>chol</code>: Cholesky, and <code>qr</code>: HouseholderQR)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A <code>varlse</code> object</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>digits</code></td>
<td>
<p>digit option to print</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>...</code></td>
<td>
<p>not used</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>object</code></td>
<td>
<p>A <code>varlse</code> object</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This package specifies VAR(p) model as
</p>
<p style="text-align: center;"><code class="reqn">Y_{t} = A_1 Y_{t - 1} + \cdots + A_p Y_{t - p} + c + \epsilon_t</code>
</p>

<p>If <code>include_type = TRUE</code>, there is constant term.
The function estimates every coefficient matrix.
</p>
<p>Consider the response matrix <code class="reqn">Y_0</code>.
Let <code class="reqn">T</code> be the total number of sample,
let <code class="reqn">m</code> be the dimension of the time series,
let <code class="reqn">p</code> be the order of the model,
and let <code class="reqn">n = T - p</code>.
Likelihood of VAR(p) has
</p>
<p style="text-align: center;"><code class="reqn">Y_0 \mid B, \Sigma_e \sim MN(X_0 B, I_s, \Sigma_e)</code>
</p>

<p>where <code class="reqn">X_0</code> is the design matrix,
and MN is <a href="https://en.wikipedia.org/wiki/Matrix_normal_distribution">matrix normal distribution</a>.
</p>
<p>Then log-likelihood of vector autoregressive model family is specified by
</p>
<p style="text-align: center;"><code class="reqn">\log p(Y_0 \mid B, \Sigma_e) = - \frac{nm}{2} \log 2\pi - \frac{n}{2} \log \det \Sigma_e - \frac{1}{2} tr( (Y_0 - X_0 B) \Sigma_e^{-1} (Y_0 - X_0 B)^T )</code>
</p>

<p>In addition, recall that the OLS estimator for the matrix coefficient matrix is the same as MLE under the Gaussian assumption.
MLE for <code class="reqn">\Sigma_e</code> has different denominator, <code class="reqn">n</code>.
</p>
<p style="text-align: center;"><code class="reqn">\hat{B} = \hat{B}^{LS} = \hat{B}^{ML} = (X_0^T X_0)^{-1} X_0^T Y_0</code>
</p>

<p style="text-align: center;"><code class="reqn">\hat\Sigma_e = \frac{1}{s - k} (Y_0 - X_0 \hat{B})^T (Y_0 - X_0 \hat{B})</code>
</p>

<p style="text-align: center;"><code class="reqn">\tilde\Sigma_e = \frac{1}{s} (Y_0 - X_0 \hat{B})^T (Y_0 - X_0 \hat{B}) = \frac{s - k}{s} \hat\Sigma_e</code>
</p>

<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{n - k}{n} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">AIC(p) = \log \det \Sigma_e + \frac{2}{n}(\text{number of freely estimated parameters})</code>
</p>

<p>where the number of freely estimated parameters is <code class="reqn">mk</code>, i.e. <code class="reqn">pm^2</code> or <code class="reqn">pm^2 + m</code>.
</p>
<p>Let <code class="reqn">\tilde{\Sigma}_e</code> be the MLE
and let <code class="reqn">\hat{\Sigma}_e</code> be the unbiased estimator (<code>covmat</code>) for <code class="reqn">\Sigma_e</code>.
Note that
</p>
<p style="text-align: center;"><code class="reqn">\tilde{\Sigma}_e = \frac{n - k}{T} \hat{\Sigma}_e</code>
</p>

<p>Then
</p>
<p style="text-align: center;"><code class="reqn">BIC(p) = \log \det \Sigma_e + \frac{\log n}{n}(\text{number of freely estimated parameters})</code>
</p>

<p>where the number of freely estimated parameters is <code class="reqn">pm^2</code>.
</p>


<h3>Value</h3>

<p><code>var_lm()</code> returns an object named <code>varlse</code> class.
It is a list with the following components:
</p>

<dl>
<dt>coefficients</dt>
<dd>
<p>Coefficient Matrix</p>
</dd>
<dt>fitted.values</dt>
<dd>
<p>Fitted response values</p>
</dd>
<dt>residuals</dt>
<dd>
<p>Residuals</p>
</dd>
<dt>covmat</dt>
<dd>
<p>LS estimate for covariance matrix</p>
</dd>
<dt>df</dt>
<dd>
<p>Numer of Coefficients</p>
</dd>
<dt>p</dt>
<dd>
<p>Lag of VAR</p>
</dd>
<dt>m</dt>
<dd>
<p>Dimension of the data</p>
</dd>
<dt>obs</dt>
<dd>
<p>Sample size used when training = <code>totobs</code> - <code>p</code></p>
</dd>
<dt>totobs</dt>
<dd>
<p>Total number of the observation</p>
</dd>
<dt>call</dt>
<dd>
<p>Matched call</p>
</dd>
<dt>process</dt>
<dd>
<p>Process: VAR</p>
</dd>
<dt>type</dt>
<dd>
<p>include constant term (<code>const</code>) or not (<code>none</code>)</p>
</dd>
<dt>design</dt>
<dd>
<p>Design matrix</p>
</dd>
<dt>y</dt>
<dd>
<p>Raw input</p>
</dd>
<dt>y0</dt>
<dd>
<p>Multivariate response matrix</p>
</dd>
<dt>method</dt>
<dd>
<p>Solving method</p>
</dd>
<dt>call</dt>
<dd>
<p>Matched call</p>
</dd>
</dl>
<p>It is also a <code>bvharmod</code> class.
</p>


<h3>References</h3>

<p>LÃ¼tkepohl, H. (2007). <em>New Introduction to Multiple Time Series Analysis</em>. Springer Publishing.
</p>
<p>Akaike, H. (1969). <em>Fitting autoregressive models for prediction</em>. Ann Inst Stat Math 21, 243-247.
</p>
<p>Akaike, H. (1971). <em>Autoregressive model fitting for control</em>. Ann Inst Stat Math 23, 163-180.
</p>
<p>Akaike H. (1974). <em>A new look at the statistical model identification</em>. IEEE Transactions on Automatic Control, vol. 19, no. 6, pp. 716-723.
</p>
<p>Akaike H. (1998). <em>Information Theory and an Extension of the Maximum Likelihood Principle</em>. In: Parzen E., Tanabe K., Kitagawa G. (eds) Selected Papers of Hirotugu Akaike. Springer Series in Statistics (Perspectives in Statistics). Springer, New York, NY.
</p>
<p>Gideon Schwarz. (1978). <em>Estimating the Dimension of a Model</em>. Ann. Statist. 6 (2) 461 - 464.
</p>


<h3>See Also</h3>


<ul><li> <p><code>summary.varlse()</code> to summarize VAR model
</p>
</li></ul>
<h3>Examples</h3>

<pre><code class="language-R"># Perform the function using etf_vix dataset
fit &lt;- var_lm(y = etf_vix, p = 2)
class(fit)
str(fit)

# Extract coef, fitted values, and residuals
coef(fit)
head(residuals(fit))
head(fitted(fit))
</code></pre>


</div>