<div class="container">

<table style="width: 100%;"><tr>
<td>result_est_MAP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Posterior inference results from the object of S5
</h2>

<h3>Description</h3>

<p>Using the object of S5, the maximum a posteriori (MAP) estimator  and Bayesian Model Averaged (BMA) estimators of the regression coefficients are provided.
</p>


<h3>Usage</h3>

<pre><code class="language-R">result_est_MAP(res,X,y,obj_fun,verbose = TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>res</code></td>
<td>

<p>an object of the 'S5' function.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>
<p>the covariates.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p>the response varaible.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>obj_fun</code></td>
<td>
<p>the negative log (unnormalized) posterior density when a model is given.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>
<p>logical; default is TRUE.</p>
</td>
</tr>
</table>
<h3>Value</h3>



<table>
<tr style="vertical-align: top;">
<td><code>intercept.MAP</code></td>
<td>
<p>the MAP estimator of the intercept. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.MAP</code></td>
<td>
<p>the MAP estimator of the regression coefficients.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>sig.MAP</code></td>
<td>
<p>the MAP estimator of the regression variance.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>intercept.BMA</code></td>
<td>
<p>the Baeysian model averaged estimator of the intercept. </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>beta.BMA</code></td>
<td>
<p>the Bayesian model averaged estimator of the regression coefficients.</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Shin Minsuk and Ruoxuan Tian
</p>


<h3>References</h3>

<p>Shin, M., Bhattacharya, A., Johnson V. E. (2018) A Scalable Bayesian Variable Selection Using Nonlocal Prior Densities in Ultrahigh-dimensional Settings, Statistica Sinica. 
</p>
<p>Hans, C., Dobra, A., and West, M. (2007). Shotgun stochastic search for large p regression. Journal of the American Statistical Association, 102, 507-516.
</p>
<p>Nikooienejad,A., Wang, W., and Johnson V.E. (2016). Bayesian variable selection for binary outcomes in high dimensional genomic studies using non-local priors. Bioinformatics, 32(9), 1338-45.
</p>


<h3>Examples</h3>

<pre><code class="language-R">p=5000
n = 100

indx.beta = 1:5
xd0 = rep(0,p);xd0[indx.beta]=1
bt0 = rep(0,p); 
bt0[1:5]=c(1,1.25,1.5,1.75,2)*sample(c(1,-1),5,replace=TRUE)
xd=xd0
bt=bt0
X = matrix(rnorm(n*p),n,p)
y = X%*%bt0 + rnorm(n)*sqrt(1.5)
X = scale(X)
y = y-mean(y)
y = as.vector(y)

### piMoM  
#C0 = 2 # the number of repetitions of S5 algorithms to explore the model space
#tuning = 10 # tuning parameter
#tuning = hyper_par(type="pimom",X,y,thre = p^-0.5)
#print(tuning)
#ind_fun = ind_fun_pimom # choose the prior on the regression coefficients (pimom in this case)
#model = Bernoulli_Uniform # choose the model prior 
#tem =  seq(0.4,1,length.out=20)^2 # the sequence of the temperatures

#fit_pimom = S5(X,y,ind_fun=ind_fun,model = model,tuning=tuning,tem=tem,C0=C0)
#fit_pimom$GAM # the searched models by S5
#fit_pimom$OBJ # the corresponding log (unnormalized) posterior probability

#res_pimom = result(fit_pimom)
#est.MAP = result_est_MAP(res_pimom,X,y,obj_fun_pimom,verbose=TRUE)
#plot(est.MAP$beta.MAP,est.MAP$beta.BMA)
#abline(0,1,col="red")
</code></pre>


</div>