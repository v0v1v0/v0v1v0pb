<div class="container">

<table style="width: 100%;"><tr>
<td>elo</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Elo Method to Calculate Aggregate Best-Worst Scores</h2>

<h3>Description</h3>

<p>Calculate aggregate best-worst scores using Elo scoring. This specific
application comes from Hollis (2018). It makes each individual/block 
pairwise comparisons and updates Elo scores based on who won and lost those
comparisons. No ties are considered, which occurs between all of the items
that have not been selected as either best or worst. Hollis (2018) also
recommends adding two "dummy items": one that defeats every other item,
and one that loses to every other item. This is employed here. The default 
K is 30, per Hollis (2018). Since Elo is temporal in nature, Hollis also
recommends running various iterations, each with a different randomization
of the order of matchups. The default is the 100 used by Hollis. These are 
averaged together to calculate individual Elo best-worst scores. Elo scores
are all initialized at 1000.
</p>


<h3>Usage</h3>

<pre><code class="language-R">elo(data, id, block, item, choice, K = 30, iter = 100)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data.frame of the type described in details.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>id</code></td>
<td>
<p>A string of the name of the id column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>block</code></td>
<td>
<p>A string of the name of the block column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>item</code></td>
<td>
<p>A string of the name of the item column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>choice</code></td>
<td>
<p>A string of the name of the choice column.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>K</code></td>
<td>
<p>The Elo K-factor. The default is 30, per Hollis (2018).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>iter</code></td>
<td>
<p>Number of different randomizations of the "matchup" order to 
iterate through. The default is Hollis's (2018, 2019) recommendation.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function requires data to be in a specified format. Each row must
represent a respondent-block-label combination. That is, it indicates
the person, the block (or trial), the item that was judged, and a column
indicating whether it was chosen as best (+1), worst (-1), or wasn't 
selected as either (0).
</p>


<h3>Value</h3>

<p>A data.frame containing the item column as well as an "elo" column that 
indicates the Elo score.
</p>


<h3>References</h3>

<p>Hollis, G. (2018). Scoring best-worst data in unbalanced many-item designs,
with applications to crowdsourcing semantic judgments. Behavior Research
Methods, 50(2), 711-729. doi: 10.3758/s13428-017-0898-2
</p>
<p>Hollis, G. (2019). The role of number of items per trial in best-worst
scaling experiments. Behavior Research Methods. doi: 
10.3758/s13428-019-01270-w
</p>


<h3>Examples</h3>

<pre><code class="language-R">data(agg)
head(agg)
# run more than 1 iter; just doing 1 here for speed
elo(agg, "pid", "trial", "character", "decision", iter = 1)

</code></pre>


</div>