<div class="container">

<table style="width: 100%;"><tr>
<td>BTFit</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>BTFit</h2>

<h3>Description</h3>

<p>These are objects representing fitted boosting trees.
</p>


<h3>Details</h3>

<p>Boosting Tree Model Object.
</p>


<h3>Value</h3>

<table>
<tr style="vertical-align: top;">
<td><code>BTInit</code></td>
<td>
<p>an object of class <code>BTInit</code> containing the initial fitted value <code>initFit</code>, the initial <code>training.error</code> and the initial <code>validation.error</code> if any.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BTErrors</code></td>
<td>
<p>an object of class <code>BTErrors</code> containing the vectors of errors for each iteration performed (excl. the initialization). More precisely, it contains the <code>training.error</code>,
<code>validation.error</code> if <code>train.fraction</code>&lt;1 and the <code>oob.improvement</code> if <code>bag.fraction</code> &lt; 1.
Moreover, if a cross-validation approach was performed, a vector of cross-validation errors <code>cv.error</code> as a function of boosting iteration is also stored in this object.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BTIndivFits</code></td>
<td>
<p>an object of class <code>BTIndivFits</code> containing the list of each individual tree fitted at each boosting iteration.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>distribution</code></td>
<td>
<p>the Tweedie power (and so the distribution) that has been used to perform the algorithm. It will currently always output 1.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.names</code></td>
<td>
<p>a vector containing the names of the explanatory variables.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>response</code></td>
<td>
<p>the name of the target/response variable.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>w</code></td>
<td>
<p>a vector containing the weights used.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>the used seed, if any.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BTData</code></td>
<td>
<p>if <code>keep.data=TRUE</code>, an object of class <code>BTData</code> containing the <code>training.set</code> and <code>validation.set</code> (can be NULL if not used). These data frames are reduced
to the used variables, that are the response and explanatory variables. Note that in case of cross-validation, even if <code>keep.data=TRUE</code> the folds will not be kept. In fact, only the data
frames related to the original fit (i.e. on the whole training set) will be saved.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>BTParams</code></td>
<td>
<p>an object of class <code>BTParams</code> containing all the (Adaptive) boosting tree parameters. More precisely, it contains the <code>ABT</code>, <code>train.fraction</code>,
<code>shrinkage</code>, <code>interaction.depth</code>, <code>bag.fraction</code>, <code>n.iter</code>, <code>colsample.bytree</code> and <code>tree.control</code> parameter values.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>keep.data</code></td>
<td>
<p>the <code>keep.data</code> parameter value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is.verbose</code></td>
<td>
<p>the <code>is.verbose</code> parameter value.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>fitted.values</code></td>
<td>
<p>the training set fitted values on the score scale using all the <code>n.iter</code> (and initialization) iterations.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.folds</code></td>
<td>
<p>the number of cross-validation folds. Set to 1 if no cross-validation performed.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>call</code></td>
<td>
<p>the original call to the <code>BT</code> algorithm.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Terms</code></td>
<td>
<p>the <code>model.frame</code> terms argument.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>folds</code></td>
<td>
<p>a vector of values identifying to which fold each observation is in. This argument is not present if there is no cross-validation. On the other hand, it corresponds
to <code>folds.id</code> if it was initially defined by the user.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cv.fitted</code></td>
<td>
<p>a vector containing the cross-validation fitted values, if a cross-validation was performed. More precisely, for a given observation, the prediction will be furnished by the cv-model
for which this specific observation was out-of-fold. See <code>predict.BTCVFit</code> for more details.</p>
</td>
</tr>
</table>
<h3>Structure </h3>

<p>The following components must be included in a legitimate <code>BTFit</code> object.
</p>


<h3>Author(s)</h3>

<p>Gireg Willame <a href="mailto:gireg.willame@gmail.com">gireg.willame@gmail.com</a>
</p>
<p><em>This package is inspired by the <code>gbm3</code> package. For more details, see <a href="https://github.com/gbm-developers/gbm3/">https://github.com/gbm-developers/gbm3/</a></em>.
</p>


<h3>References</h3>

<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries |: GLMs and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries ||: Tree-Based Methods and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2019). <strong>Effective Statistical Learning Methods for Actuaries |||: Neural Networks and Extensions</strong>, <em>Springer Actuarial</em>.
</p>
<p>M. Denuit, D. Hainaut and J. Trufin (2022). <strong>Response versus gradient boosting trees, GLMs and neural networks under Tweedie loss and log-link</strong>.
Accepted for publication in <em>Scandinavian Actuarial Journal</em>.
</p>
<p>M. Denuit, J. Huyghe and J. Trufin (2022). <strong>Boosting cost-complexity pruned trees on Tweedie responses: The ABT machine for insurance ratemaking</strong>.
Paper submitted for publication.
</p>
<p>M. Denuit, J. Trufin and T. Verdebout (2022). <strong>Boosting on the responses with Tweedie loss functions</strong>. Paper submitted for publication.
</p>


<h3>See Also</h3>

<p><code>BT</code>.
</p>


</div>