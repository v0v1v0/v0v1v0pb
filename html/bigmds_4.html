<div class="container">

<table style="width: 100%;"><tr>
<td>landmark_mds</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Landmark MDS</h2>

<h3>Description</h3>

<p>Landmark MDS (LMDS) algorithm applies first classical MDS to a
subset of the data (<em>landmark points</em>) and then the remaining individuals are
projected onto the landmark low dimensional configuration using a
distance-based triangulation procedure.
</p>


<h3>Usage</h3>

<pre><code class="language-R">landmark_mds(x, num_landmarks, r)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>x</code></td>
<td>
<p>A matrix with <code class="reqn">n</code> points (rows) and <code class="reqn">k</code> variables (columns).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>num_landmarks</code></td>
<td>
<p>Number of landmark points to obtain an initial MDS configuration. It is
equivalent to <code>l</code> parameter used in <code>interpolation_mds()</code>, <code>divide_conquer_mds()</code> and
<code>fast_mds()</code>. Therefore, it is the size for which classical MDS can be computed efficiently
(using <code>cmdscale</code> function). It means that if <code class="reqn">\bar{l}</code> is the limit
size for which classical MDS is applicable, then <code>l</code><code class="reqn">\leq \bar{l}</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>r</code></td>
<td>
<p>Number of principal coordinates to be extracted.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>LMDS applies first classical MDS to a subset of the data (<em>landmark points</em>). Then,
it uses a distance-based triangulation procedure to project the non-landmark individuals. This
distance-based triangulation procedure coincides with  <em>Gower's interpolation formula</em>.
</p>
<p>This method is similar to <code>interpolation_mds()</code> and <code>reduced_mds()</code>.
</p>


<h3>Value</h3>

<p>Returns a list containing the following elements:
</p>

<dl>
<dt>points</dt>
<dd>
<p>A matrix that consists of <code class="reqn">n</code> points (rows)
and <code>r</code> variables (columns) corresponding to the principal coordinates. Since
a dimensionality reduction is performed, <code>r</code><code class="reqn">&lt;&lt;k</code></p>
</dd>
<dt>eigen</dt>
<dd>
<p>The first <code>r</code> largest eigenvalues:
<code class="reqn">\lambda_i, i \in  \{1, \dots, r\} </code>, where each <code class="reqn">\lambda_i</code> is obtained
from applying classical MDS to the first data subset.</p>
</dd>
</dl>
<h3>References</h3>

<p>Delicado P. and C. Pachón-García (2021). <em>Multidimensional Scaling for Big Data</em>.
<a href="https://arxiv.org/abs/2007.11919">https://arxiv.org/abs/2007.11919</a>.
</p>
<p>Borg, I. and P. Groenen (2005). <em>Modern Multidimensional Scaling: Theory and Applications</em>. Springer.
</p>
<p>De Silva V. and JB. Tenenbaum (2004). <em>Sparse multidimensional scaling using landmark points</em>. Technical Report, Stanford University.
</p>
<p>Gower JC. (1968). <em>Adding a point to vector diagrams in multivariate analysis</em>. Biometrika.
</p>


<h3>Examples</h3>

<pre><code class="language-R">set.seed(42)
x &lt;- matrix(data = rnorm(4 * 10000), nrow = 10000) %*% diag(c(9, 4, 1, 1))
mds &lt;- landmark_mds(x = x, num_landmarks = 200, r = 2)
head(mds$points)
mds$eigen

</code></pre>


</div>