<div class="container">

<table style="width: 100%;"><tr>
<td>manualOutlierFindeR</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Finds outliers, and their duplicates, as determined by experts</h2>

<h3>Description</h3>

<p>Uses expert-identified outliers with source spreadsheets that may be edited by users. The function
will also use the duplicates file made using <code>dupeSummary()</code> to identify duplicates of the
expert-identified outliers and flag those as well.
The function will add a flagging column called <code>.expertOutlier</code> where records that are FALSE are
the expert outliers.
</p>


<h3>Usage</h3>

<pre><code class="language-R">manualOutlierFindeR(
  data = NULL,
  DataPath = NULL,
  PaigeOutliersName = "removedBecauseDeterminedOutlier.csv",
  newOutliersName = "All_outliers_ANB.xlsx",
  ColombiaOutliers_all = "All_Colombian_OutlierIDs.csv",
  duplicates = NULL,
  NearTRUE = NULL,
  NearTRUE_threshold = 5
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A data frame or tibble. Occurrence records as input.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>DataPath</code></td>
<td>
<p>A character path to the directory that contains the outlier spreadsheets.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>PaigeOutliersName</code></td>
<td>
<p>A character patch. Should lead to outlier spreadsheet from Paige Chesshire (csv file).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>newOutliersName</code></td>
<td>
<p>A character path. Should lead to appropriate outlier spreadsheet (xlsx file).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ColombiaOutliers_all</code></td>
<td>
<p>A character path. Should lead to spreadsheet of bee outliers from Colombia (csv file).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>duplicates</code></td>
<td>
<p>A data frame or tibble. The duplicate file produced by <code>dupeSummary()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NearTRUE</code></td>
<td>
<p>Optional. A character file name to the csv file. If you want to remove expert
outliers that are too close to TRUE points, use the name of the NearTRUE.csv.
Note: This implementation is only basic for now unless there is a greater need in the future.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>NearTRUE_threshold</code></td>
<td>
<p>Numeric. The threshold (in km) for the distance to TRUE points to
keep expert outliers.</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>Returns the data with a new column, <code>.expertOutlier</code> where records that are FALSE are
the expert outliers.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
  # Read example data
  data(beesFlagged)
# Read in the most-recent duplicates file as well
if(!exists("duplicates")){
  duplicates &lt;- fileFinder(path = DataPath,
                            fileName = "duplicateRun_") %&gt;%
    readr::read_csv()}
# identify the outliers and get a list of their database_ids
beesFlagged_out &lt;- manualOutlierFindeR(
  data = beesFlagged,
  DataPath = DataPath,
  PaigeOutliersName = "removedBecauseDeterminedOutlier.csv",
  newOutliersName = "^All_outliers_ANB_14March.xlsx",
  ColombiaOutliers_all = "All_Colombian_OutlierIDs.csv",
  duplicates = duplicates)

## End(Not run)

</code></pre>


</div>