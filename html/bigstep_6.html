<div class="container">

<table style="width: 100%;"><tr>
<td>bigstep</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Model selection</h2>

<h3>Description</h3>

<p>Model selection using the stepwise procedure and the chosen criterion.
</p>


<h3>Details</h3>

<p>The main goal of the package <code>bigstep</code> is to allow you to select a
regression model using the stepwise procedure when data is very big,
potentially larger than available RAM in your computer. What is more, the
package gives you a lot of control over how this procedure should look like.
At this moment, you can use one of these functions: <code>stepwise</code>,
<code>forward</code>, <code>backward</code>, <code>fast_forward</code>, <code>multi_backward</code>
and combinations of them. They can be treated as blocks from which the whole
procedure of finding the best model is built.
</p>
<p>When your data is larger than RAM you have in your computer, it is
impossible to read it in a normal way. Fortunately, in a process of building
a regression model it is not necessary to have access to all predictors at the
same time. Instead, you can read only a part of the matrix <code>X</code>, check
all variables from that part and then read another one. To do that with this
package, you only need to read the matrix <code>X</code> using
<code>read.big.matrix</code> from <code>bigmemory</code> package. The <code>prepare_data</code>
function has a parameter <code>maxp</code> which represents the maximum size (that
is the number of elements) of one part. If <code>X</code> is bigger, it will be
split. It will be done even if your matrix is big but you have enough RAM
to read it in a normal way. It may seem unnecessary, but it is worth to do
because R is not very efficient in dealing with big matrices.
</p>
<p>Another problem with a large number of predictors is choosing an appropriate
criterion. Classical ones like AIC or BIC are bad choice because they will
almost certainly select a model with two many variables [1]. You can use
modifications of them like mBIC [2], mBIC2 [3], mAIC or mAIC2. In brief,
these criteria have much heavier penalty for the number of parameters, so
they prefer smaller models than their classic versions.
</p>
<p>If you want to read more, type <code>browseVignettes("bigstep")</code>
</p>


<h3>Author(s)</h3>

<p>Piotr Szulc
</p>


<h3>References</h3>

<p>[1] M. Bogdan, J.K. Ghosh, M. Zak-Szatkowska. Selecting explanatory
variables with the modified version of Bayesian Information Criterion.
Quality and Reliability Engineering International, 24:989-999, 2008.
</p>
<p>[2] M. Bogdan, J.K. Ghosh, R.W. Doerge. Modifying the Schwarz Bayesian
Information Criterion to locate multiple interacting quantitative trait loci.
Genetics, 167:989-999, 2004.
</p>
<p>[3] F. Frommlet, A. Chakrabarti, M. Murawska, M. Bogdan. Asymptotic Bayes
optimality under sparsity for general distributions under the alternative,
Technical report, arXiv:1005.4753v2, 2011.
</p>


<h3>Examples</h3>

<pre><code class="language-R">## Not run: 
library(bigstep)

### small data
set.seed(1)
n &lt;- 200
p &lt;- 20
X &lt;- matrix(rnorm(n * p), ncol = p)
colnames(X) &lt;- paste0("X", 1:p)
y &lt;- 1 + 0.4 * rowSums(X[, c(5, 10, 15, 20)]) + rnorm(n)

data &lt;- prepare_data(y, X)
results &lt;- stepwise(data, crit = aic)
results$model
summary(results)

### bigger data
set.seed(1)
n &lt;- 1e3
p &lt;- 1e4
X &lt;- matrix(rnorm(p * n), ncol = p)
colnames(X) &lt;- paste0("X", 1:p)
Xadd &lt;- matrix(rnorm(5 * n), n, 5)  # additional variables
colnames(Xadd) &lt;- paste0("Xadd", 1:5)
y &lt;- 0.2 * rowSums(X[, 1000 * (1:10)]) + Xadd[, 1] - 0.1 * Xadd[, 3] + rnorm(n)

data &lt;- prepare_data(y, X, Xadd = Xadd)
data %&gt;%
  reduce_matrix(minpv = 0.15) %&gt;%
  stepwise(mbic) -&gt;
  results
summary(results)

### big data
Xbig &lt;- read.big.matrix("X.txt", sep = " ", header = TRUE,
                        backingfile = "X.bin", descriptorfile = "X.desc")
# Xbig &lt;- attach.big.matrix("X.desc") # much faster
y &lt;- read.table("y.txt")
# data &lt;- prepare_data(y, Xbig) # slow because of checking NA
data &lt;- prepare_data(y, Xbig, na = FALSE) # set if you know that you do not have NA
m &lt;- data %&gt;%
  reduce_matrix(minpv = 0.001) %&gt;%
  fast_forward(crit = bic, maxf = 50) %&gt;%
  multi_backward(crit = mbic) %&gt;%
  stepwise(crit = mbic)
summary(m)

# more examples: type browseVignettes("bigstep")

## End(Not run)

</code></pre>


</div>