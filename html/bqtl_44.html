<div class="container">

<table style="width: 100%;"><tr>
<td>make.varcov</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2> Create moment matrices</h2>

<h3>Description</h3>

<p>Create a moment matrix of the marker variables and of the regressors by
the phenotype variable.  For use in regression modelling on the markers.
</p>


<h3>Usage</h3>

<pre><code class="language-R">make.varcov(regressor.matrix, y, subset=is.finite(y), casewt=NULL)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>regressor.matrix</code></td>
<td>
<p>The object produced by <code>make.regressor.matrix</code> </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>
<p> A vector of phenotype information with the same number of
elements as there are rows in <code>regressor.matrix</code> </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>subset</code></td>
<td>
<p> Logical vector with the same number of
elements as there are rows in <code>regressor.matrix</code> to indicate
which rows to keep.  </p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>casewt</code></td>
<td>
<p>Optional vector of case weights. </p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>A list with components
</p>
<table>
<tr style="vertical-align: top;">
<td><code>var.x </code></td>
<td>
<p>Moment matrix of the marker regressor variables</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>cov.xy </code></td>
<td>
<p>Moment matrix of the marker regressor variables versus
the phenotype variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>var.y</code></td>
<td>
<p>The Second central moment of the phenotype variable</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>df</code></td>
<td>
 <p><code> sum(subset==TRUE) - 1</code>
</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p> It is generally NOT a good idea to do regressions on
ill-conditioned designs using the moment matrices like this.  The
excuse for doing so here is twofold.  First, calculations using this
method are used to perform importance sampling, so minor numerical
inaccuracies in computing the probabilites used in sampling get
straightened out by the importance weights.  Second, it will typically
be the case that a prior is set on the regression coefficients and
this results in a positive constant (aka a 'ridge' parameter) being
added to diagonal of <code>varcov$var.x</code> and this reduces the
ill-conditioning.  Of course the rational for using the method is to
speed the sampling, and it is very effective at doing so.</p>


<h3>Author(s)</h3>

<p>Charles C. Berry <a href="mailto:cberry@ucsd.edu">cberry@ucsd.edu</a> </p>


</div>