<div class="container">

<table style="width: 100%;"><tr>
<td>compute_mallows_sequentially</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Estimate the Bayesian Mallows Model Sequentially</h2>

<h3>Description</h3>

<p>Compute the posterior distributions of the parameters of the
Bayesian Mallows model using sequential Monte Carlo. This is based on the
algorithms developed in
Stein (2023).
This function differs from <code>update_mallows()</code> in that it takes all the data
at once, and uses SMC to fit the model step-by-step. Used in this way, SMC
is an alternative to Metropolis-Hastings, which may work better in some
settings. In addition, it allows visualization of the learning process.
</p>


<h3>Usage</h3>

<pre><code class="language-R">compute_mallows_sequentially(
  data,
  initial_values,
  model_options = set_model_options(),
  smc_options = set_smc_options(),
  compute_options = set_compute_options(),
  priors = set_priors(),
  pfun_estimate = NULL
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>data</code></td>
<td>
<p>A list of objects of class "BayesMallowsData" returned from
<code>setup_rank_data()</code>. Each list element is interpreted as the data belonging
to a given timepoint.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>initial_values</code></td>
<td>
<p>An object of class "BayesMallowsPriorSamples" returned
from <code>sample_prior()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model_options</code></td>
<td>
<p>An object of class "BayesMallowsModelOptions" returned
from <code>set_model_options()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>smc_options</code></td>
<td>
<p>An object of class "SMCOptions" returned from
<code>set_smc_options()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>compute_options</code></td>
<td>
<p>An object of class "BayesMallowsComputeOptions"
returned from <code>set_compute_options()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>priors</code></td>
<td>
<p>An object of class "BayesMallowsPriors" returned from
<code>set_priors()</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>pfun_estimate</code></td>
<td>
<p>Object returned from <code>estimate_partition_function()</code>.
Defaults to <code>NULL</code>, and will only be used for footrule, Spearman, or
Ulam distances when the cardinalities are not available, cf.
<code>get_cardinalities()</code>.</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>This function is very new, and plotting functions and other tools
for visualizing the posterior distribution do not yet work. See the examples
for some workarounds.
</p>


<h3>Value</h3>

<p>An object of class BayesMallowsSequential.
</p>


<h3>References</h3>

<p>Stein A (2023).
<em>Sequential Inference with the Mallows Model</em>.
Ph.D. thesis, Lancaster University.
</p>


<h3>See Also</h3>

<p>Other modeling: 
<code>burnin()</code>,
<code>burnin&lt;-()</code>,
<code>compute_mallows()</code>,
<code>compute_mallows_mixtures()</code>,
<code>sample_prior()</code>,
<code>update_mallows()</code>
</p>


<h3>Examples</h3>

<pre><code class="language-R"># Observe one ranking at each of 12 timepoints
library(ggplot2)
data &lt;- lapply(seq_len(nrow(potato_visual)), function(i) {
  setup_rank_data(potato_visual[i, ], user_ids = i)
})

initial_values &lt;- sample_prior(
  n = 200, n_items = 20,
  priors = set_priors(gamma = 3, lambda = .1))

mod &lt;- compute_mallows_sequentially(
  data = data,
  initial_values = initial_values,
  smc_options = set_smc_options(n_particles = 500, mcmc_steps = 20))

# We can see the acceptance ratio of the move step for each timepoint:
get_acceptance_ratios(mod)

plot_dat &lt;- data.frame(
  n_obs = seq_along(data),
  alpha_mean = apply(mod$alpha_samples, 2, mean),
  alpha_sd = apply(mod$alpha_samples, 2, sd)
)

# Visualize how the dispersion parameter is being learned as more data arrive
ggplot(plot_dat, aes(x = n_obs, y = alpha_mean, ymin = alpha_mean - alpha_sd,
                     ymax = alpha_mean + alpha_sd)) +
  geom_line() +
  geom_ribbon(alpha = .1) +
  ylab(expression(alpha)) +
  xlab("Observations") +
  theme_classic() +
  scale_x_continuous(
    breaks = seq(min(plot_dat$n_obs), max(plot_dat$n_obs), by = 1))

# Visualize the learning of the rank for a given item (item 1 in this example)
plot_dat &lt;- data.frame(
  n_obs = seq_along(data),
  rank_mean = apply(mod$rho_samples[1, , ], 2, mean),
  rank_sd = apply(mod$rho_samples[1, , ], 2, sd)
)

ggplot(plot_dat, aes(x = n_obs, y = rank_mean, ymin = rank_mean - rank_sd,
                     ymax = rank_mean + rank_sd)) +
  geom_line() +
  geom_ribbon(alpha = .1) +
  xlab("Observations") +
  ylab(expression(rho[1])) +
  theme_classic() +
  scale_x_continuous(
    breaks = seq(min(plot_dat$n_obs), max(plot_dat$n_obs), by = 1))
</code></pre>


</div>