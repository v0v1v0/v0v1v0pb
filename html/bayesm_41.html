<div class="container">

<table style="width: 100%;"><tr>
<td>rhierMnlDP</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>MCMC Algorithm for Hierarchical Multinomial Logit with Dirichlet Process Prior Heterogeneity</h2>

<h3>Description</h3>

<p><code>rhierMnlDP</code> is a MCMC algorithm for a hierarchical multinomial logit with a Dirichlet Process prior for the distribution of heteorogeneity.  A base normal model is used so that the DP can be interpreted as allowing for a mixture of normals with as many components as there are panel units. This is a hybrid Gibbs Sampler with a RW Metropolis step for the MNL coefficients for each panel unit.  This procedure can be interpreted as a Bayesian semi-parameteric method in the sense that the DP prior can accomodate heterogeniety of an unknown form.
</p>


<h3>Usage</h3>

<pre><code class="language-R">rhierMnlDP(Data, Prior, Mcmc)</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>Data </code></td>
<td>
<p>list(lgtdata, Z, p)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Prior</code></td>
<td>
<p>list(deltabar, Ad, Prioralpha, lambda_hyper)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Mcmc </code></td>
<td>
<p>list(R, keep, nprint, s, w, maxunique, gridsize)</p>
</td>
</tr>
</table>
<h3>Details</h3>



<h4>Model and Priors</h4>

<p><code class="reqn">y_i</code> <code class="reqn">\sim</code> <code class="reqn">MNL(X_i, \beta_i)</code> with <code class="reqn">i = 1, \ldots, length(lgtdata)</code> and where <code class="reqn">\theta_i</code> is <code class="reqn">nvar x 1</code>
</p>
<p><code class="reqn">\beta_i = Z\Delta</code>[i,] + <code class="reqn">u_i</code> <br>
Note:  Z<code class="reqn">\Delta</code> is the matrix <code class="reqn">Z * \Delta</code>; [i,] refers to <code class="reqn">i</code>th row of this product <br>
Delta is an <code class="reqn">nz x nvar</code> matrix 
</p>
<p><code class="reqn">\beta_i</code> <code class="reqn">\sim</code> <code class="reqn">N(\mu_i, \Sigma_i)</code>
</p>
<p><code class="reqn">\theta_i = (\mu_i, \Sigma_i)</code> <code class="reqn">\sim</code> <code class="reqn">DP(G_0(\lambda), alpha)</code><br></p>
<p><code class="reqn">G_0(\lambda):</code><br><code class="reqn">\mu_i | \Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">N(0, \Sigma_i (x) a^{-1})</code><br><code class="reqn">\Sigma_i</code> <code class="reqn">\sim</code> <code class="reqn">IW(nu, nu*v*I)</code><br><code class="reqn">delta = vec(\Delta)</code> <code class="reqn">\sim</code> <code class="reqn">N(deltabar, A_d^{-1})</code><br></p>
<p><code class="reqn">\lambda(a, nu, v):</code><br><code class="reqn">a</code> <code class="reqn">\sim</code> uniform[alim[1], alimb[2]]<br><code class="reqn">nu</code> <code class="reqn">\sim</code>  dim(data)-1 + exp(z) <br><code class="reqn">z</code> <code class="reqn">\sim</code>  uniform[dim(data)-1+nulim[1], nulim[2]]<br><code class="reqn">v</code> <code class="reqn">\sim</code> uniform[vlim[1], vlim[2]]
</p>
<p><code class="reqn">alpha</code> <code class="reqn">\sim</code> <code class="reqn">(1-(alpha-alphamin) / (alphamax-alphamin))^{power}</code> <br>
alpha = alphamin then expected number of components = <code>Istarmin</code> <br>
alpha = alphamax then expected number of components = <code>Istarmax</code>
</p>
<p><code class="reqn">Z</code> should NOT include an intercept and is centered for ease of interpretation. The mean of each of the <code>nlgt</code> <code class="reqn">\beta</code>s is the mean of the normal mixture.  Use <code>summary()</code> to compute this mean from the <code>compdraw</code> output.
</p>
<p>We parameterize the prior on <code class="reqn">\Sigma_i</code> such that <code class="reqn">mode(\Sigma) = nu/(nu+2) vI</code>. The support of nu enforces a non-degenerate IW density; <code class="reqn">nulim[1] &gt; 0</code>.
</p>
<p>The default choices of alim, nulim, and vlim determine the location and approximate size of candidate "atoms" or possible normal components. The defaults are sensible given a reasonable scaling of the X variables. You want to insure that alim is set for a wide enough range of values (remember a is a precision parameter) and the v is big enough to propose Sigma matrices wide enough to cover the data range.  
</p>
<p>A careful analyst should look at the posterior distribution of a, nu, v to make sure that the support is set correctly in alim, nulim, vlim.  In other words, if we see the posterior bunched up at one end of these support ranges, we should widen the range and rerun.  
</p>
<p>If you want to force the procedure to use many small atoms, then set nulim to consider only large values and set vlim to consider only small scaling constants.  Set alphamax to a large number.  This will create a very "lumpy" density estimate somewhat like the classical Kernel density estimates. Of course, this is not advised if you have a prior belief that densities are relatively smooth.
</p>



<h4>Argument Details</h4>

<p><em><code>Data  = list(lgtdata, Z, p)</code> [<code>Z</code> optional]</em>
</p>

<table>
<tr>
<td style="text-align: left;">
    <code>lgtdata:        </code> </td>
<td style="text-align: left;"> list of lists with each cross-section unit MNL data </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>lgtdata[[i]]$y: </code> </td>
<td style="text-align: left;"> <code class="reqn">n_i x 1</code> vector of multinomial outcomes (1, ..., m) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>lgtdata[[i]]$X: </code> </td>
<td style="text-align: left;"> <code class="reqn">n_i x nvar</code> design matrix for <code class="reqn">i</code>th unit </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>Z:              </code> </td>
<td style="text-align: left;"> <code class="reqn">nreg x nz</code> matrix of unit characteristics (def: vector of ones) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>p:              </code> </td>
<td style="text-align: left;"> number of choice alternatives
    </td>
</tr>
</table>
<p><em><code>Prior = list(deltabar, Ad, Prioralpha, lambda_hyper)</code> [optional]</em>
</p>

<table>
<tr>
<td style="text-align: left;">
    <code>deltabar:       </code> </td>
<td style="text-align: left;"> <code class="reqn">nz*nvar x 1</code> vector of prior means (def: 0) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>Ad:             </code> </td>
<td style="text-align: left;"> prior precision matrix for vec(D) (def: 0.01*I) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>Prioralpha:     </code> </td>
<td style="text-align: left;"> <code>list(Istarmin, Istarmax, power)</code> </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$Istarmin:    </code> </td>
<td style="text-align: left;"> expected number of components at lower bound of support of alpha def(1) </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$Istarmax:    </code> </td>
<td style="text-align: left;"> expected number of components at upper bound of support of alpha (def: min(50, 0.1*nlgt)) </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$power:       </code> </td>
<td style="text-align: left;"> power parameter for alpha prior (def: 0.8)  </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>lambda_hyper:   </code> </td>
<td style="text-align: left;"> <code>list(alim, nulim, vlim)</code>  </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$alim:        </code> </td>
<td style="text-align: left;"> defines support of a distribution (def: <code>c(0.01, 2)</code>) </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$nulim:       </code> </td>
<td style="text-align: left;"> defines support of nu distribution (def: <code>c(0.001, 3)</code>) </td>
</tr>
<tr>
<td style="text-align: left;">
      <code>$vlim:        </code> </td>
<td style="text-align: left;"> defines support of v distribution (def: <code>c(0.1, 4)</code>) 
      </td>
</tr>
</table>
<p><em><code>Mcmc  = list(R, keep, nprint, s, w, maxunique, gridsize)</code> [only <code>R</code> required]</em>
</p>

<table>
<tr>
<td style="text-align: left;">
    <code>R:              </code> </td>
<td style="text-align: left;"> number of MCMC draws </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>keep:           </code> </td>
<td style="text-align: left;"> MCMC thinning parameter -- keep every <code>keep</code>th draw (def: 1) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>nprint:         </code> </td>
<td style="text-align: left;"> print the estimated time remaining for every <code>nprint</code>'th draw (def: 100, set to 0 for no print) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>s:              </code> </td>
<td style="text-align: left;"> scaling parameter for RW Metropolis (def: 2.93/<code>sqrt(nvar)</code>) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>w:              </code> </td>
<td style="text-align: left;"> fractional likelihood weighting parameter (def: 0.1) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>maxuniq:        </code> </td>
<td style="text-align: left;"> storage constraint on the number of unique components (def: 200) </td>
</tr>
<tr>
<td style="text-align: left;">
    <code>gridsize:       </code> </td>
<td style="text-align: left;"> number of discrete points for hyperparameter priors, (def: 20)
    </td>
</tr>
</table>
<h4>
<code>nmix</code> Details</h4>

<p><code>nmix</code> is a list with 3 components. Several functions in the <code>bayesm</code> package that involve a Dirichlet Process or mixture-of-normals return <code>nmix</code>. Across these functions, a common structure is used for <code>nmix</code> in order to utilize generic summary and plotting functions. 
</p>

<table>
<tr>
<td style="text-align: left;">
  <code>probdraw:</code> </td>
<td style="text-align: left;"> <code class="reqn">ncomp x R/keep</code> matrix that reports the probability that each draw came from a particular component (here, a one-column matrix of 1s) </td>
</tr>
<tr>
<td style="text-align: left;">
  <code>zdraw:   </code> </td>
<td style="text-align: left;"> <code class="reqn">R/keep x nobs</code> matrix that indicates which component each draw is assigned to (here, null) </td>
</tr>
<tr>
<td style="text-align: left;">
  <code>compdraw:</code> </td>
<td style="text-align: left;"> A list of <code class="reqn">R/keep</code> lists of <code class="reqn">ncomp</code> lists. Each of the inner-most lists has 2 elemens: a vector of draws for <code>mu</code> and a matrix of draws for the Cholesky root of <code>Sigma</code>.
  </td>
</tr>
</table>
<h3>Value</h3>

<p>A list containing:
</p>
<table>
<tr style="vertical-align: top;">
<td><code>Deltadraw </code></td>
<td>
 <p><code class="reqn">R/keep x nz*nvar</code> matrix of draws of Delta, first row is initial value</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>betadraw  </code></td>
<td>
 <p><code class="reqn">nlgt x nvar x R/keep</code> array of draws of betas</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nmix      </code></td>
<td>
<p> a list containing: <code>probdraw</code>, <code>zdraw</code>, <code>compdraw</code> (see “<code>nmix</code> Details” section)</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>adraw     </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of hyperparm a</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>vdraw     </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of hyperparm v</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>nudraw    </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of hyperparm nu</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>Istardraw </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of number of unique components</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>alphadraw </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of number of DP tightness parameter</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>loglike   </code></td>
<td>
 <p><code class="reqn">R/keep</code> draws of log-likelihood</p>
</td>
</tr>
</table>
<h3>Note</h3>

<p>As is well known, Bayesian density estimation involves computing the predictive distribution of a "new" unit parameter, <code class="reqn">\theta_{n+1}</code> (here "n"=nlgt). This is done by averaging the normal base distribution over draws from the distribution of <code class="reqn">\theta_{n+1}</code> given <code class="reqn">\theta_1</code>, ..., <code class="reqn">\theta_n</code>, alpha, lambda, data. To facilitate this, we store those draws from the predictive distribution of <code class="reqn">\theta_{n+1}</code> in a list structure compatible with other <code>bayesm</code> routines that implement a finite mixture of normals.
</p>
<p>Large <code>R</code> values may be required (&gt;20,000).
</p>


<h3>Author(s)</h3>

<p>Peter Rossi, Anderson School, UCLA, <a href="mailto:perossichi@gmail.com">perossichi@gmail.com</a>.</p>


<h3>References</h3>

<p>For further discussion, see Chapter 5, <em>Bayesian Statistics and Marketing</em> by Rossi, Allenby, and McCulloch.</p>


<h3>See Also</h3>

 <p><code>rhierMnlRwMixture</code> </p>


<h3>Examples</h3>

<pre><code class="language-R">if(nchar(Sys.getenv("LONG_TEST")) != 0) {R=20000} else {R=10}
set.seed(66)

p = 3                                # num of choice alterns
ncoef = 3  
nlgt = 300                           # num of cross sectional units
nz = 2
Z = matrix(runif(nz*nlgt),ncol=nz)
Z = t(t(Z)-apply(Z,2,mean))          # demean Z
ncomp = 3                            # no of mixture components
Delta=matrix(c(1,0,1,0,1,2),ncol=2)

comps = NULL
comps[[1]] = list(mu=c(0,-1,-2),   rooti=diag(rep(2,3)))
comps[[2]] = list(mu=c(0,-1,-2)*2, rooti=diag(rep(2,3)))
comps[[3]] = list(mu=c(0,-1,-2)*4, rooti=diag(rep(2,3)))
pvec=c(0.4, 0.2, 0.4)

##  simulate from MNL model conditional on X matrix
simmnlwX = function(n,X,beta) {
  k = length(beta)
  Xbeta = X%*%beta
  j = nrow(Xbeta) / n
  Xbeta = matrix(Xbeta, byrow=TRUE, ncol=j)
  Prob = exp(Xbeta)
  iota = c(rep(1,j))
  denom = Prob%*%iota
  Prob = Prob / as.vector(denom)
  y = vector("double", n)
  ind = 1:j
  for (i in 1:n) {
  yvec = rmultinom(1, 1, Prob[i,])
  y[i] = ind%*%yvec}
  return(list(y=y, X=X, beta=beta, prob=Prob))
}

## simulate data with a mixture of 3 normals
simlgtdata = NULL
ni = rep(50,300)
for (i in 1:nlgt) {
  betai = Delta%*%Z[i,] + as.vector(rmixture(1,pvec,comps)$x)
   Xa = matrix(runif(ni[i]*p,min=-1.5,max=0), ncol=p)
   X = createX(p, na=1, nd=NULL, Xa=Xa, Xd=NULL, base=1)
   outa = simmnlwX(ni[i], X, betai)
   simlgtdata[[i]] = list(y=outa$y, X=X, beta=betai)
}

## plot betas
if(0){
  bmat = matrix(0, nlgt, ncoef)
  for(i in 1:nlgt) { bmat[i,] = simlgtdata[[i]]$beta }
  par(mfrow = c(ncoef,1))
  for(i in 1:ncoef) { hist(bmat[,i], breaks=30, col="magenta") }
}

## set Data and Mcmc lists
keep = 5
Mcmc1 = list(R=R, keep=keep)
Data1 = list(p=p, lgtdata=simlgtdata, Z=Z)

out = rhierMnlDP(Data=Data1, Mcmc=Mcmc1)

cat("Summary of Delta draws", fill=TRUE)
summary(out$Deltadraw, tvalues=as.vector(Delta))

## plotting examples
if(0) {
  plot(out$betadraw)
  plot(out$nmix)
}
</code></pre>


</div>