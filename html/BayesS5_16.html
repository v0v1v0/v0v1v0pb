<div class="container">

<table style="width: 100%;"><tr>
<td>SSS</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>
Shotgun stochastic search algorithm (SSS)
</h2>

<h3>Description</h3>

<p>The Shotgun Stochastic Search (SSS) was proposed by Hans et al. (2007), which is a stochastic search algorithm for Bayesian variable selection.
</p>


<h3>Usage</h3>

<pre><code class="language-R">SSS(X,y,ind_fun,model,tuning,N=1000,C0=1,verbose=TRUE)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>X</code></td>
<td>

<p>a covariate matrix (a standardization is recommneded for nonlocal priors).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>y</code></td>
<td>

<p>a response variable. 
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>ind_fun</code></td>
<td>

<p>a log-marginal likelihood function of models, which is resulted from a pred-specified priors on the regression coefficients. The default is piMoM
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>

<p>a model prior; Uniform or Bernoulli_Uniform. The default is Bernoulli_Uniform
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuning</code></td>
<td>

<p>a tuning parameter for the objective function (tau for piMoM and peMoM priors; g for the g-prior).
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>N</code></td>
<td>

<p>a number of iterations of the SSS; default is 1000.
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>C0</code></td>
<td>

<p>a number of repetition of  the S5 algorithm C0 times,default is 1. When the total number of variables is huge and real data sets are considered, using a large number of C0 is recommended, e.g., C0=10.  
</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>verbose</code></td>
<td>

<p>if TRUE, the function prints the currnet status of the S5 in each temperature; the default is TRUE.
</p>
</td>
</tr>
</table>
<h3>Details</h3>

<p>Using the S5 (Shin et al., 2016+), you will get all the models searched by S5 algorithm, and their corresponding log (unnormalized) posterior probabilities, and also this function can receive searched model for g-prior,piMoM,and peMoM. 
</p>
<p>After obtaining the object of the S5 function, by using the 'result' function, you can obtain the posterior probabilities of the searched models including the MAP model and  the marginal inclusion probabilities of each variable.
</p>
<p>By using the procedure of Nikooienejad et al. (2016), the 'hyper_par' function chooses the tuning parameter for nonlocal priors (piMoM or peMoM priors).
</p>


<h3>Value</h3>



<table>
<tr style="vertical-align: top;">
<td><code>GAM</code></td>
<td>
<p> the binary vaiables of searched models by S5</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>OBJ</code></td>
<td>
<p> the corresponding log (unnormalized) posterior probability</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>tuning</code></td>
<td>
<p>the tuning parameter used in the model selection</p>
</td>
</tr>
</table>
<h3>Author(s)</h3>

<p>Shin Minsuk and Ruoxuan Tian
</p>


<h3>References</h3>

<p>Hans, C., Dobra, A., and West, M. (2007). Shotgun stochastic search for large p regression. Journal of the American Statistical Association, 102, 507-516.
</p>


<h3>See Also</h3>

<p><code>result</code>, <code>S5_parallel</code>, <code>S5</code>   

</p>


<h3>Examples</h3>

<pre><code class="language-R">p=100
n = 200

indx.beta = 1:5
xd0 = rep(0,p);xd0[indx.beta]=1
bt0 = rep(0,p); 
bt0[1:5]=c(1,1.25,1.5,1.75,2)*sample(c(1,-1),5,replace=TRUE)
xd=xd0
bt=bt0
X = matrix(rnorm(n*p),n,p)
y = crossprod(t(X),bt0) + rnorm(n)*sqrt(1.5)
X = scale(X)
y = y-mean(y)
y = as.vector(y)

### default setting
#fit_de_SSS = SSS(X,y)

#res_de_SSS = result(fit_de_SSS)
#print(res_de_SSS$hppm) # the MAP model 
#print(res_de_SSS$hppm.prob) # the posterior probability of the hppm 
#plot(res_de_SSS$marg.prob,ylim=c(0,1),ylab="marginal inclusion probability")
 # the marginal inclusion probability 
</code></pre>


</div>