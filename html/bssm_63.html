<div class="container">

<table style="width: 100%;"><tr>
<td>post_correct</td>
<td style="text-align: right;">R Documentation</td>
</tr></table>
<h2>Run Post-correction for Approximate MCMC using <code class="reqn">\psi</code>-APF</h2>

<h3>Description</h3>

<p>Function <code>post_correct</code> updates previously obtained approximate MCMC
output with post-correction weights leading to asymptotically exact
weighted posterior, and returns updated MCMC output where components
<code>weights</code>, <code>posterior</code>, <code>alpha</code>, <code>alphahat</code>, and
<code>Vt</code> are updated (depending on the original output type).
</p>


<h3>Usage</h3>

<pre><code class="language-R">post_correct(
  model,
  mcmc_output,
  particles,
  threads = 1L,
  is_type = "is2",
  seed = sample(.Machine$integer.max, size = 1)
)
</code></pre>


<h3>Arguments</h3>

<table>
<tr style="vertical-align: top;">
<td><code>model</code></td>
<td>
<p>Model of class <code>nongaussian</code> or <code>ssm_nlg</code>.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>mcmc_output</code></td>
<td>
<p>An output from <code>run_mcmc</code> used to compute the MAP
estimate of theta.
While the intended use assumes this is from approximate MCMC, it is not
actually checked, i.e., it is also possible to input previous
(asymptotically) exact output.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>particles</code></td>
<td>
<p>Number of particles for <code class="reqn">\psi</code>-APF (positive integer).
Suitable values depend on the model and the data, but often relatively
small value less than say 50 is enough. See also <code>suggest_N</code></p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>threads</code></td>
<td>
<p>Number of parallel threads (positive integer, default is 1).</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>is_type</code></td>
<td>
<p>Type of IS-correction. Possible choices are
<code>"is3"</code> for simple importance sampling (weight is computed for each
MCMC iteration independently),
<code>"is2"</code> for jump chain importance sampling type weighting (default), or
<code>"is1"</code> for importance sampling type weighting where the number of
particles used forweight computations is proportional to the length of the
jump chain block.</p>
</td>
</tr>
<tr style="vertical-align: top;">
<td><code>seed</code></td>
<td>
<p>Seed for the C++ RNG (positive integer).</p>
</td>
</tr>
</table>
<h3>Value</h3>

<p>The original object of class <code>mcmc_output</code> with updated
weights, log-posterior values and state samples or summaries (depending on
the <code>mcmc_output$mcmc_type</code>).
</p>


<h3>References</h3>

<p>Doucet A, Pitt M K, Deligiannidis G, Kohn R (2018).
Efficient implementation of Markov chain Monte Carlo when using an unbiased
likelihood estimator. Biometrika, 102, 2, 295-313,
https://doi.org/10.1093/biomet/asu075
</p>
<p>Vihola M, Helske J, Franks J (2020). Importance sampling type estimators
based on approximate marginal Markov chain Monte Carlo.
Scand J Statist. 1-38. https://doi.org/10.1111/sjos.12492
</p>


<h3>Examples</h3>

<pre><code class="language-R">
set.seed(1)
n &lt;- 300
x1 &lt;- sin((2 * pi / 12) * 1:n)
x2 &lt;- cos((2 * pi / 12) * 1:n)
alpha &lt;- numeric(n)
alpha[1] &lt;- 0
rho &lt;- 0.7
sigma &lt;- 2
mu &lt;- 1
for(i in 2:n) {
  alpha[i] &lt;- rnorm(1, mu * (1 - rho) + rho * alpha[i-1], sigma)
}
u &lt;- rpois(n, 50)
y &lt;- rbinom(n, size = u, plogis(0.5 * x1 + x2 + alpha))

ts.plot(y / u)

model &lt;- ar1_ng(y, distribution = "binomial", 
  rho = uniform(0.5, -1, 1), sigma = gamma_prior(1, 2, 0.001),
  mu = normal(0, 0, 10),
  xreg = cbind(x1,x2), beta = normal(c(0, 0), 0, 5),
  u = u)

out_approx &lt;- run_mcmc(model, mcmc_type = "approx", 
  local_approx = FALSE, iter = 50000)

out_is2 &lt;- post_correct(model, out_approx, particles = 30,
  threads = 2)
out_is2$time

summary(out_approx, return_se = TRUE)
summary(out_is2, return_se = TRUE)

# latent state
library("dplyr")
library("ggplot2")
state_approx &lt;- as.data.frame(out_approx, variable = "states") |&gt; 
  group_by(time) |&gt;
  summarise(mean = mean(value))
  
state_exact &lt;- as.data.frame(out_is2, variable = "states") |&gt; 
  group_by(time) |&gt;
  summarise(mean = weighted.mean(value, weight))

dplyr::bind_rows(approx = state_approx, 
  exact = state_exact, .id = "method") |&gt;
  filter(time &gt; 200) |&gt;
ggplot(aes(time, mean, colour = method)) + 
  geom_line() + 
  theme_bw()

# posterior means
p_approx &lt;- predict(out_approx, model, type = "mean", 
  nsim = 1000, future = FALSE) |&gt; 
  group_by(time) |&gt;
  summarise(mean = mean(value))
p_exact &lt;- predict(out_is2, model, type = "mean", 
  nsim = 1000, future = FALSE) |&gt; 
  group_by(time) |&gt;
  summarise(mean = mean(value))

dplyr::bind_rows(approx = p_approx, 
  exact = p_exact, .id = "method") |&gt;
  filter(time &gt; 200) |&gt;
ggplot(aes(time, mean, colour = method)) + 
  geom_line() + 
  theme_bw() 

</code></pre>


</div>